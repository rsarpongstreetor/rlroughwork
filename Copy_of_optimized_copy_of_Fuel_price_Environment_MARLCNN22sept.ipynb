{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip3 install torch\n",
        "!pip3 install torchrl\n",
        "!pip3 install tensordict\n",
        "!pip3 install torchview\n",
        "!pip3 install torchvision\n",
        "!pip3 install pydrive\n",
        "!pip3 install ipython-autotime\n",
        "!pip3 install tensorboard"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qGhUh7N730zW",
        "outputId": "5f853247-c5b8-4a3f-f0fd-44647d0135d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: torchrl in /usr/local/lib/python3.10/dist-packages (0.5.0)\n",
            "Requirement already satisfied: torch>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from torchrl) (2.4.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchrl) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from torchrl) (24.1)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from torchrl) (2.2.1)\n",
            "Requirement already satisfied: tensordict>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from torchrl) (0.5.0)\n",
            "Requirement already satisfied: orjson in /usr/local/lib/python3.10/dist-packages (from tensordict>=0.5.0->torchrl) (3.10.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchrl) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchrl) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchrl) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchrl) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchrl) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchrl) (2024.6.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.3.0->torchrl) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.3.0->torchrl) (1.3.0)\n",
            "Requirement already satisfied: tensordict in /usr/local/lib/python3.10/dist-packages (0.5.0)\n",
            "Requirement already satisfied: torch>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from tensordict) (2.4.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tensordict) (1.26.4)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from tensordict) (2.2.1)\n",
            "Requirement already satisfied: orjson in /usr/local/lib/python3.10/dist-packages (from tensordict) (3.10.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->tensordict) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->tensordict) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->tensordict) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->tensordict) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->tensordict) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->tensordict) (2024.6.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.4.0->tensordict) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.4.0->tensordict) (1.3.0)\n",
            "Requirement already satisfied: torchview in /usr/local/lib/python3.10/dist-packages (0.2.6)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.19.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: torch==2.4.1 in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.4.1+cu121)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (10.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1->torchvision) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1->torchvision) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1->torchvision) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1->torchvision) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1->torchvision) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1->torchvision) (2024.6.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.4.1->torchvision) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.4.1->torchvision) (1.3.0)\n",
            "Requirement already satisfied: pydrive in /usr/local/lib/python3.10/dist-packages (1.3.1)\n",
            "Requirement already satisfied: google-api-python-client>=1.2 in /usr/local/lib/python3.10/dist-packages (from pydrive) (2.137.0)\n",
            "Requirement already satisfied: oauth2client>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from pydrive) (4.1.3)\n",
            "Requirement already satisfied: PyYAML>=3.0 in /usr/local/lib/python3.10/dist-packages (from pydrive) (6.0.2)\n",
            "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.2->pydrive) (0.22.0)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.2->pydrive) (2.27.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.2->pydrive) (0.2.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.2->pydrive) (2.19.2)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.2->pydrive) (4.1.1)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.10/dist-packages (from oauth2client>=4.0.0->pydrive) (0.6.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.10/dist-packages (from oauth2client>=4.0.0->pydrive) (0.4.1)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from oauth2client>=4.0.0->pydrive) (4.9)\n",
            "Requirement already satisfied: six>=1.6.1 in /usr/local/lib/python3.10/dist-packages (from oauth2client>=4.0.0->pydrive) (1.16.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client>=1.2->pydrive) (1.65.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0.dev0,>=3.19.5 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client>=1.2->pydrive) (3.20.3)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client>=1.2->pydrive) (1.24.0)\n",
            "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client>=1.2->pydrive) (2.32.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client>=1.2->pydrive) (5.5.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client>=1.2->pydrive) (3.1.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client>=1.2->pydrive) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client>=1.2->pydrive) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client>=1.2->pydrive) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client>=1.2->pydrive) (2024.8.30)\n",
            "Requirement already satisfied: ipython-autotime in /usr/local/lib/python3.10/dist-packages (0.3.2)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.10/dist-packages (from ipython-autotime) (7.34.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (71.0.4)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (0.19.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (3.0.47)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (4.9.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython->ipython-autotime) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython->ipython-autotime) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->ipython-autotime) (0.2.13)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (2.17.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.64.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.7)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.26.4)\n",
            "Requirement already satisfied: protobuf!=4.24.0,<5.0.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.20.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (71.0.4)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard) (2.1.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "tBdvI114pYjy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import multiprocessing\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import nn\n",
        "from tensordict.nn import TensorDictModule\n",
        "from tensordict.nn.distributions import NormalParamExtractor\n",
        "from torchrl.collectors import SyncDataCollector\n",
        "from torchrl.data.replay_buffers import ReplayBuffer\n",
        "from torchrl.data.replay_buffers.samplers import SamplerWithoutReplacement\n",
        "from torchrl.data.replay_buffers.storages import LazyTensorStorage\n",
        "\n",
        "from torchrl.envs.transforms import (\n",
        "    Compose,\n",
        "    DoubleToFloat,\n",
        "    ObservationNorm,\n",
        "    RewardScaling,\n",
        "    RewardSum,\n",
        "    StepCounter,\n",
        "    UnsqueezeTransform,\n",
        "    TransformedEnv,)\n",
        "\n",
        "from torchrl.envs.libs.gym import GymEnv\n",
        "from torchrl.envs.utils import check_env_specs, ExplorationType, set_exploration_type\n",
        "from torchrl.modules import ProbabilisticActor, TanhNormal, ValueOperator\n",
        "from torchrl.objectives import ClipPPOLoss\n",
        "from torchrl.objectives.value import GAE\n",
        "from tqdm import tqdm\n",
        "import google.colab\n",
        "import pygame\n",
        "from gym.spaces import Discrete, Box, Dict, Tuple, MultiBinary, MultiDiscrete\n",
        "import random\n",
        "import os\n",
        "import math\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import namedtuple, deque\n",
        "from itertools import count\n",
        "import plotly.express as px\n",
        "import pandas as pd\n",
        "\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import datasets\n",
        "from google.colab import drive\n",
        "google.colab.drive.mount('/content/drive')\n",
        "from collections import defaultdict\n",
        "from typing import Optional\n",
        "import torchrl\n",
        "import numpy as np\n",
        "from tensordict import TensorDict, TensorDictBase\n",
        "from torchrl.modules import MultiAgentConvNet\n",
        "from torchrl.data import BoundedTensorSpec, CompositeSpec, UnboundedContinuousTensorSpec,DiscreteTensorSpec\n",
        "from torchrl.envs import (\n",
        "    CatTensors,\n",
        "    EnvBase,\n",
        "    Transform,\n",
        "    TransformedEnv,\n",
        "    UnsqueezeTransform,\n",
        "    VecGymEnvTransform,\n",
        "\n",
        "    Resize,\n",
        ")\n",
        "\n",
        "from torchrl.envs.transforms.transforms import _apply_to_composite\n",
        "from torchrl.envs.utils import check_env_specs, step_mdp\n",
        "import tensordict as td\n",
        "from torchrl.envs import EnvBase\n",
        "from torch import  tensor\n",
        "from torchrl.envs.transforms import TransformedEnv\n",
        "import tensordict\n",
        "\n",
        "from torchrl.envs import RewardSum, TransformedEnv\n",
        "from torchrl.envs.libs.vmas import VmasEnv\n",
        "from torchrl.envs.utils import check_env_specs\n",
        "\n",
        "# Multi-agent network\n",
        "from torchrl.modules import MultiAgentMLP, ProbabilisticActor, TanhNormal\n",
        "\n",
        "# Loss\n",
        "from torchrl.objectives import ClipPPOLoss, ValueEstimators\n",
        "\n",
        "# Utils\n",
        "torch.manual_seed(0)\n",
        "from matplotlib import pyplot as plt\n",
        "from typing import Union, Sequence, Type\n",
        "\n",
        "import torch.nn as nn\n",
        "from torchrl.envs.utils import check_env_specs, step_mdp\n",
        "from torchrl.modules import ProbabilisticActor\n",
        "#####################################\n",
        "\"\"\"DataInput\"\"\"\n",
        "#####################################\n",
        "import collections\n",
        "import numpy as np  # Import NumPy\n",
        "k=0\n",
        "\n",
        "class DDataenv():\n",
        "\n",
        "  #Initialize\n",
        "  def __init__(self):\n",
        "    # Load data here\n",
        "      self.DDDDataDic =np.empty((8,7), dtype=np.float32)\n",
        "\n",
        "      # We have 3 actions, corresponding to \"increase\", \"decrease\", \"no change \" in fuel price\n",
        "      #self.action_space = spaces.Discrete(3)\n",
        "      # Observations are dictionaries with the agent's Observation which are.\n",
        "      # Forex, Crude oil pric, Fuel price, reward, action\n",
        "      self.vvmm=np.empty((8,10), dtype=np.float32)\n",
        "      self.k=k\n",
        "\n",
        "  def _downl_Data(self):\n",
        "        with open('/content/drive/MyDrive/deep learning codes/EIAAPI_DOWNLOAD/solutions/mergedata/DataDic.pt','rb') as rpp:\n",
        "\n",
        "          DataDic = torch.load(rpp,weights_only=True)\n",
        "        DDataDic=DataDic[0]\n",
        "        DDDDataDic=DDataDic\n",
        "        return DDDDataDic\n",
        "\n",
        "  def _get_obs_stats(self):\n",
        "        self.vvmm_dict = {}\n",
        "        observation=[]\n",
        "        vvmm_dict={},\n",
        "        vvnn=[]\n",
        "        vvnv={}\n",
        "        DD=[]\n",
        "        DDDataDic=[]\n",
        "        aadd={}\n",
        "        aadd1={}\n",
        "        aadd2={}\n",
        "\n",
        "        aabb=[]\n",
        "        actionState=[]\n",
        "        rewardState=[]\n",
        "        obsState=[]\n",
        "        obsFuels=[]\n",
        "        rewardFuels=[]\n",
        "        actionFuels=[]\n",
        "        Envvstatesinput=[]\n",
        "        Envvfuelsinput=[]\n",
        "         #observation\n",
        "        DDDataDic=self._downl_Data()\n",
        "        observation=DDDataDic[np.random.choice(DDDataDic.shape[0], 1, replace=False),:].numpy().astype(np.float32)\n",
        "        observation.flatten()\n",
        "        aabb=pd.DataFrame(observation)\n",
        "        aabb.transpose()\n",
        "        aabb.columns=['Forex','WTI','Brent','OPEC','Fuelprice5','Fuelprice6','Fuelprice7','Fuelprice8','Fuelprice9','Fuelprice10','Fuelprice11','Fuelprice12','Fuelprice13',\n",
        "                     'reward0','reward1','reward2','reward3','reward4','reward5','reward6','reward7','reward8','reward9','reward10','reward11','reward12',\n",
        "                    'action0','action1','action2','action3','action4','action5','action6','action7','action8','action9','action10','action11','action12',]\n",
        "\n",
        "        obsState=np.array(aabb.iloc[0,0:4])\n",
        "        rewardState=np.array(aabb.iloc[0,13:17])\n",
        "        actionState=np.array(aabb.iloc[0,26:30])\n",
        "        obsfuels=np.array(aabb.iloc[0,4:13])\n",
        "        rewardfuels=np.array(aabb.iloc[0,17:26])\n",
        "        actionfuels=np.array(aabb.iloc[0,30:39])\n",
        "\n",
        "        aadd1=pd.concat((pd.Series(obsState),pd.Series(rewardState),pd.Series(actionState)),axis=1)\n",
        "\n",
        "        aadd1=pd.DataFrame(aadd1)\n",
        "        aadd1.columns=['obsState','rewardState','actionState']\n",
        "\n",
        "\n",
        "        aadd2=pd.concat([pd.Series(obsfuels),pd.Series(rewardfuels),pd.Series(actionfuels)],axis=1)\n",
        "\n",
        "        aadd2=pd.DataFrame(aadd2)\n",
        "        aadd2.columns=['obsFuels','rewardFuels','actionFuels']\n",
        "\n",
        "\n",
        "        obsState_max=[]\n",
        "        obsState_min=[]\n",
        "        rewardState_max=[]\n",
        "        rewardState_min=[]\n",
        "        actionState_max=[]\n",
        "        actionState_min=[]\n",
        "        obsfuels_max=[]\n",
        "        obsfuels_min=[]\n",
        "        rewardfuels_max=[]\n",
        "        rewardfuels_min=[]\n",
        "        actionfuels_max=[]\n",
        "        actionfuels_min=[]\n",
        "\n",
        "\n",
        "        DD = DDDataDic.clone()\n",
        "        DD.reshape(-1, DD.shape[-1])\n",
        "        vvmm=np.zeros((8,DD.shape[1]))\n",
        "        df = pd.DataFrame(DD)\n",
        "\n",
        "        vvmm = df.describe()\n",
        "        vvmm.columns=['Forex','WTI','Brent','OPEC','Fuelprice5','Fuelprice6','Fuelprice7','Fuelprice8','Fuelprice9','Fuelprice10','Fuelprice11','Fuelprice12','Fuelprice13',\n",
        "                      'reward0','reward1','reward2','reward3','reward4','reward5','reward6','reward7','reward8','reward9','reward10','reward11','reward12',\n",
        "                      'action0','action1','action2','action3','action4','action5','action6','action7','action8','action9','action10','action11','action12',]\n",
        "\n",
        "        vvmm.index=['count', 'mean', 'std', 'min', '25%', '50%', '75%', 'max']\n",
        "        vvmm1=pd.concat((vvmm.iloc[:,0:4],vvmm.iloc[:,13:17],vvmm.iloc[:,26:30]),axis=1)\n",
        "        vvmm2=pd.concat((vvmm.iloc[:,4:13] ,vvmm.iloc[:,17:26],vvmm.iloc[:,30:39]),axis=1)\n",
        "\n",
        "        vvmm1.index=['count', 'mean', 'std', 'min', '25%', '50%', '75%', 'max']\n",
        "        vvmm2.index=['count', 'mean', 'std', 'min', '25%', '50%', '75%', 'max']\n",
        "\n",
        "\n",
        "        ii= [3, 7]\n",
        "       # vvmm.astype(dtype=np.float32, copy=True, errors='list')\n",
        "        xx1=[]\n",
        "        yy1=[]\n",
        "        xxx1=[]\n",
        "        yyy1=[]\n",
        "        vvvv1=[]\n",
        "\n",
        "        for k in range(len(vvmm1.columns)):\n",
        "          for i in ii:\n",
        "            xx1.append(vvmm1.iat[i, k])\n",
        "\n",
        "\n",
        "        for k in range(len(vvmm1.columns)):\n",
        "          for i in ii:\n",
        "            yy1.append(str(vvmm1.index[i]) + '.' + str(vvmm1.columns[k]))\n",
        "\n",
        "        xx1=np.array(xx1)\n",
        "        xx1 = xx1.reshape(1,24)\n",
        "\n",
        "        yyy1=iter(yy1)\n",
        "        vvnn1=pd.DataFrame(xx1,dtype=np.float32)\n",
        "\n",
        "\n",
        "        vvnn1.columns=yyy1\n",
        "\n",
        "\n",
        "        for j in range(24):\n",
        "          if j < 4:\n",
        "            obsState_min.append(((vvnn1.iloc[0,2*j  :2*j+1]).squeeze()))\n",
        "            obsState_max.append(((vvnn1.iloc[0,2*j+1:2*j+2]).squeeze()))\n",
        "            rewardState_min.append(((vvnn1.iloc[0,2*j+8:2*j+9]).squeeze()))\n",
        "            rewardState_max.append(((vvnn1.iloc[0,2*j+9:2*j+10]).squeeze()))\n",
        "            actionState_min.append(((vvnn1.iloc[0,2*j+16:2*j+17]).squeeze()))\n",
        "            actionState_max.append(((vvnn1.iloc[0,2*j+17:2*j+18]).squeeze()))\n",
        "\n",
        "\n",
        "        ii= [3, 7]\n",
        "       # vvmm.astype(dtype=np.float32, copy=True, errors='list')\n",
        "        xx2=[]\n",
        "        yy2=[]\n",
        "        xxx2=[]\n",
        "        yyy2=[]\n",
        "        vvvv2=[]\n",
        "\n",
        "        for k in range(len(vvmm2.columns)):\n",
        "          for i in ii:\n",
        "            xx2.append(vvmm2.iat[i, k])\n",
        "\n",
        "\n",
        "        for k in range(len(vvmm2.columns)):\n",
        "          for i in ii:\n",
        "            yy2.append(str(vvmm2.index[i]) + '.' + str(vvmm2.columns[k]))\n",
        "\n",
        "        xx2=np.array(xx2)\n",
        "        xx2 = xx2.reshape(1,54)\n",
        "\n",
        "        yyy2=iter(yy2)\n",
        "        vvnn2=pd.DataFrame(xx2,dtype=np.float32)\n",
        "\n",
        "\n",
        "        vvnn2.columns=yyy2\n",
        "\n",
        "\n",
        "\n",
        "        for j in range(54):\n",
        "          if j < 9:\n",
        "            obsfuels_max.append(((vvnn2.iloc[0,2*j:2*j+1])))\n",
        "            obsfuels_min.append(((vvnn2.iloc[0,2*j+1:2*j+2])))\n",
        "\n",
        "            rewardfuels_min.append(((vvnn2.iloc[0,2*j+17:2*j+18])))\n",
        "            rewardfuels_max.append(((vvnn2.iloc[0,2*j+18:2*j+19])))\n",
        "\n",
        "            actionfuels_max.append(((vvnn2.iloc[0,2*j+36:2*j+37])))\n",
        "            actionfuels_min.append(((vvnn2.iloc[0,2*j+37:2*j+38])))\n",
        "\n",
        "        obsfuels_max=np.array(obsfuels_max).reshape(-1)\n",
        "        obsfuels_min=np.array(obsfuels_min).reshape(-1)\n",
        "        actionfuels_max=np.array(actionfuels_max).reshape(-1)\n",
        "        actionfuels_min=np.array(actionfuels_min).reshape(-1)\n",
        "        rewardfuels_max=np.array(rewardfuels_max).reshape(-1)\n",
        "        rewardfuels_min=np.array(rewardfuels_min).reshape(-1)\n",
        "\n",
        "\n",
        "        vvmm1_dict=pd.concat([pd.Series(obsState_max),pd.Series(obsState_min),pd.Series(rewardState_max),pd.Series(rewardState_min),pd.Series(actionState_max),pd.Series(actionState_min)],axis=1)\n",
        "\n",
        "        vvmm1_dict.columns=['obsState_max','obsState_min','rewardState_max','rewardState_min','actionState_max','actionState_min']\n",
        "\n",
        "        vvmm2_dict=pd.concat([pd.Series(obsfuels_max),pd.Series(obsfuels_min),pd.Series(rewardfuels_max),pd.Series(rewardfuels_min),pd.Series(actionfuels_max),pd.Series(actionfuels_min)],axis=1)\n",
        "\n",
        "        vvmm2_dict.columns=['obsFuels_min','obsFuels_max','rewardFuels_min','rewardFuels_max','actionFuels_min','actionFuels_max']\n",
        "\n",
        "\n",
        "        fv=pd.concat((vvmm2_dict,aadd2),axis=1)\n",
        "        sv=pd.concat((vvmm1_dict,aadd1),axis=1)\n",
        "        ssv=np.zeros((9,9))\n",
        "        ssv=pd.DataFrame(ssv)\n",
        "        ssv.columns=sv.columns\n",
        "        sssv=sv+ssv\n",
        "        sv=sssv\n",
        "        svfv=pd.concat((sv,fv),axis=1)\n",
        "\n",
        "        result=svfv.to_dict(orient='list')\n",
        "\n",
        "        return result\n",
        "\n",
        "\n",
        "\"\"\"MARL Environment \"\"\"\n",
        "\n",
        "\n",
        "\n",
        "import multiprocessing\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import nn\n",
        "from tensordict.nn import TensorDictModule\n",
        "from tensordict.nn.distributions import NormalParamExtractor\n",
        "\n",
        "from torchrl.collectors import SyncDataCollector\n",
        "from torchrl.data.replay_buffers import ReplayBuffer\n",
        "from torchrl.data.replay_buffers.samplers import SamplerWithoutReplacement\n",
        "from torchrl.data.replay_buffers.storages import LazyTensorStorage\n",
        "from torchrl.envs import (Compose, DoubleToFloat, ObservationNorm, StepCounter,TransformedEnv )\n",
        "from torchrl.envs.libs.gym import GymEnv\n",
        "from torchrl.envs.utils import check_env_specs, ExplorationType, set_exploration_type\n",
        "from torchrl.modules import ProbabilisticActor, TanhNormal, ValueOperator\n",
        "from torchrl.objectives import ClipPPOLoss\n",
        "from torchrl.objectives.value import GAE\n",
        "from tqdm import tqdm\n",
        "import google.colab\n",
        "import pygame\n",
        "from gym.spaces import Discrete, Box, Dict, Tuple, MultiBinary, MultiDiscrete\n",
        "import random\n",
        "import os\n",
        "import math\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import namedtuple, deque\n",
        "from itertools import count\n",
        "import plotly.express as px\n",
        "import pandas as pd\n",
        "\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import datasets\n",
        "from google.colab import drive\n",
        "google.colab.drive.mount('/content/drive')\n",
        "from collections import defaultdict\n",
        "from typing import Optional\n",
        "import torchrl\n",
        "import numpy as np\n",
        "from tensordict import TensorDict, TensorDictBase\n",
        "from torchrl.modules import MultiAgentConvNet\n",
        "from torchrl.data import BoundedTensorSpec, CompositeSpec, UnboundedContinuousTensorSpec,DiscreteTensorSpec\n",
        "from torchrl.envs import (\n",
        "    CatTensors,\n",
        "    EnvBase,\n",
        "    Transform,\n",
        "    TransformedEnv,\n",
        "    UnsqueezeTransform,\n",
        ")\n",
        "\n",
        "from torchrl.envs.transforms.transforms import _apply_to_composite\n",
        "from torchrl.envs.utils import check_env_specs, step_mdp\n",
        "import tensordict as td\n",
        "from torchrl.envs import EnvBase\n",
        "from torch import  tensor\n",
        "from torchrl.envs.transforms import TransformedEnv\n",
        "import tensordict\n",
        "\n",
        "from torchrl.envs import RewardSum, TransformedEnv\n",
        "from torchrl.envs.libs.vmas import VmasEnv\n",
        "from torchrl.envs.utils import check_env_specs\n",
        "\n",
        "# Multi-agent network\n",
        "from torchrl.modules import MultiAgentMLP, ProbabilisticActor, TanhNormal\n",
        "\n",
        "# Loss\n",
        "from torchrl.objectives import ClipPPOLoss, ValueEstimators\n",
        "\n",
        "# Utils\n",
        "torch.manual_seed(0)\n",
        "from matplotlib import pyplot as plt\n",
        "from typing import Union, Sequence, Type\n",
        "\n",
        "import torch.nn as nn\n",
        "from torchrl.envs.utils import check_env_specs, step_mdp\n",
        "from torchrl.modules import ProbabilisticActor\n",
        "#####################################\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import collections\n",
        "import numpy as np  # Import NumPy\n",
        "k=0\n",
        "\n",
        "class DDataenv():\n",
        "\n",
        "  #Initialize\n",
        "  def __init__(self):\n",
        "    # Load data here\n",
        "      self.DDDDataDic =np.empty((8,7), dtype=np.float32)\n",
        "      # We have 3 actions, corresponding to \"increase\", \"decrease\", \"no change \" in fuel price\n",
        "      #self.action_space = spaces.Discrete(3)\n",
        "      # Observations are dictionaries with the agent's Observation which are.\n",
        "      # Forex, Crude oil pric, Fuel price, reward, action\n",
        "      self.vvmm=np.empty((8,10), dtype=np.float32)\n",
        "      self.k=k\n",
        "\n",
        "  def _downl_Data(self):\n",
        "        with open('/content/drive/MyDrive/deep learning codes/EIAAPI_DOWNLOAD/solutions/mergedata/DataDic.pt','rb') as rpp:\n",
        "          DataDic = torch.load(rpp, weights_only=True)\n",
        "        DDataDic=DataDic[0]\n",
        "        DDDDataDic=DDataDic\n",
        "        return DDDDataDic\n",
        "\n",
        "  def _get_obs_stats(self):\n",
        "        self.vvmm_dict = {}\n",
        "        observation=[]\n",
        "        vvmm_dict={},\n",
        "        vvnn=[]\n",
        "        vvnv={}\n",
        "        DD=[]\n",
        "        DDDataDic=[]\n",
        "        aadd={}\n",
        "        aadd1={}\n",
        "        aadd2={}\n",
        "\n",
        "        aabb=[]\n",
        "        actionState=[]\n",
        "        rewardState=[]\n",
        "        obsState=[]\n",
        "        obsFuels=[]\n",
        "        rewardFuels=[]\n",
        "        actionFuels=[]\n",
        "        Envvstatesinput=[]\n",
        "        Envvfuelsinput=[]\n",
        "         #observation\n",
        "        DDDataDic=self._downl_Data()\n",
        "        observation=DDDataDic[np.random.choice(DDDataDic.shape[0], 1, replace=False),:].numpy().astype(np.float32)\n",
        "        observation.flatten()\n",
        "        aabb=pd.DataFrame(observation)\n",
        "        aabb.transpose()\n",
        "        aabb.columns=['Forex','WTI','Brent','OPEC','Fuelprice5','Fuelprice6','Fuelprice7','Fuelprice8','Fuelprice9','Fuelprice10','Fuelprice11','Fuelprice12','Fuelprice13',\n",
        "                     'reward0','reward1','reward2','reward3','reward4','reward5','reward6','reward7','reward8','reward9','reward10','reward11','reward12',\n",
        "                    'action0','action1','action2','action3','action4','action5','action6','action7','action8','action9','action10','action11','action12',]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        obsState=np.array(aabb.iloc[0,0:4])\n",
        "        rewardState=np.array(aabb.iloc[0,13:17])\n",
        "        actionState=np.array(aabb.iloc[0,26:30])\n",
        "        obsfuels=np.array(aabb.iloc[0,4:13])\n",
        "        rewardfuels=np.array(aabb.iloc[0,17:26])\n",
        "        actionfuels=np.array(aabb.iloc[0,30:39])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        aadd1=pd.concat((pd.Series(obsState),pd.Series(rewardState),pd.Series(actionState)),axis=1)\n",
        "\n",
        "        aadd1=pd.DataFrame(aadd1)\n",
        "        aadd1.columns=['obsState','rewardState','actionState']\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        aadd2=pd.concat([pd.Series(obsfuels),pd.Series(rewardfuels),pd.Series(actionfuels)],axis=1)\n",
        "\n",
        "        aadd2=pd.DataFrame(aadd2)\n",
        "        aadd2.columns=['obsFuels','rewardFuels','actionFuels']\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        obsState_max=[]\n",
        "        obsState_min=[]\n",
        "        rewardState_max=[]\n",
        "        rewardState_min=[]\n",
        "        actionState_max=[]\n",
        "        actionState_min=[]\n",
        "        obsfuels_max=[]\n",
        "        obsfuels_min=[]\n",
        "        rewardfuels_max=[]\n",
        "        rewardfuels_min=[]\n",
        "        actionfuels_max=[]\n",
        "        actionfuels_min=[]\n",
        "\n",
        "\n",
        "        DD = DDDataDic.clone()\n",
        "        DD.reshape(-1, DD.shape[-1])\n",
        "        vvmm=np.zeros((8,DD.shape[1]))\n",
        "        df = pd.DataFrame(DD)\n",
        "\n",
        "        vvmm = df.describe()\n",
        "        vvmm.columns=['Forex','WTI','Brent','OPEC','Fuelprice5','Fuelprice6','Fuelprice7','Fuelprice8','Fuelprice9','Fuelprice10','Fuelprice11','Fuelprice12','Fuelprice13',\n",
        "                      'reward0','reward1','reward2','reward3','reward4','reward5','reward6','reward7','reward8','reward9','reward10','reward11','reward12',\n",
        "                      'action0','action1','action2','action3','action4','action5','action6','action7','action8','action9','action10','action11','action12',]\n",
        "\n",
        "        vvmm.index=['count', 'mean', 'std', 'min', '25%', '50%', '75%', 'max']\n",
        "        vvmm1=pd.concat((vvmm.iloc[:,0:4],vvmm.iloc[:,13:17],vvmm.iloc[:,26:30]),axis=1)\n",
        "        vvmm2=pd.concat((vvmm.iloc[:,4:13] ,vvmm.iloc[:,17:26],vvmm.iloc[:,30:39]),axis=1)\n",
        "\n",
        "        vvmm1.index=['count', 'mean', 'std', 'min', '25%', '50%', '75%', 'max']\n",
        "        vvmm2.index=['count', 'mean', 'std', 'min', '25%', '50%', '75%', 'max']\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        ii= [3, 7]\n",
        "       # vvmm.astype(dtype=np.float32, copy=True, errors='list')\n",
        "        xx1=[]\n",
        "        yy1=[]\n",
        "        xxx1=[]\n",
        "        yyy1=[]\n",
        "        vvvv1=[]\n",
        "\n",
        "        for k in range(len(vvmm1.columns)):\n",
        "          for i in ii:\n",
        "            xx1.append(vvmm1.iat[i, k])\n",
        "\n",
        "\n",
        "        for k in range(len(vvmm1.columns)):\n",
        "          for i in ii:\n",
        "            yy1.append(str(vvmm1.index[i]) + '.' + str(vvmm1.columns[k]))\n",
        "\n",
        "        xx1=np.array(xx1)\n",
        "        xx1 = xx1.reshape(1,24)\n",
        "\n",
        "        yyy1=iter(yy1)\n",
        "        vvnn1=pd.DataFrame(xx1,dtype=np.float32)\n",
        "\n",
        "\n",
        "        vvnn1.columns=yyy1\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        for j in range(24):\n",
        "          if j < 4:\n",
        "            obsState_min.append(((vvnn1.iloc[0,2*j  :2*j+1]).squeeze()))\n",
        "            obsState_max.append(((vvnn1.iloc[0,2*j+1:2*j+2]).squeeze()))\n",
        "            rewardState_min.append(((vvnn1.iloc[0,2*j+8:2*j+9]).squeeze()))\n",
        "            rewardState_max.append(((vvnn1.iloc[0,2*j+9:2*j+10]).squeeze()))\n",
        "            actionState_min.append(((vvnn1.iloc[0,2*j+16:2*j+17]).squeeze()))\n",
        "            actionState_max.append(((vvnn1.iloc[0,2*j+17:2*j+18]).squeeze()))\n",
        "\n",
        "\n",
        "        ii= [3, 7]\n",
        "       # vvmm.astype(dtype=np.float32, copy=True, errors='list')\n",
        "        xx2=[]\n",
        "        yy2=[]\n",
        "        xxx2=[]\n",
        "        yyy2=[]\n",
        "        vvvv2=[]\n",
        "\n",
        "        for k in range(len(vvmm2.columns)):\n",
        "          for i in ii:\n",
        "            xx2.append(vvmm2.iat[i, k])\n",
        "\n",
        "\n",
        "        for k in range(len(vvmm2.columns)):\n",
        "          for i in ii:\n",
        "            yy2.append(str(vvmm2.index[i]) + '.' + str(vvmm2.columns[k]))\n",
        "\n",
        "        xx2=np.array(xx2)\n",
        "        xx2 = xx2.reshape(1,54)\n",
        "\n",
        "        yyy2=iter(yy2)\n",
        "        vvnn2=pd.DataFrame(xx2,dtype=np.float32)\n",
        "\n",
        "\n",
        "        vvnn2.columns=yyy2\n",
        "\n",
        "\n",
        "\n",
        "        for j in range(54):\n",
        "          if j < 9:\n",
        "            obsfuels_max.append(((vvnn2.iloc[0,2*j:2*j+1])))\n",
        "            obsfuels_min.append(((vvnn2.iloc[0,2*j+1:2*j+2])))\n",
        "\n",
        "            rewardfuels_min.append(((vvnn2.iloc[0,2*j+17:2*j+18])))\n",
        "            rewardfuels_max.append(((vvnn2.iloc[0,2*j+18:2*j+19])))\n",
        "\n",
        "            actionfuels_max.append(((vvnn2.iloc[0,2*j+36:2*j+37])))\n",
        "            actionfuels_min.append(((vvnn2.iloc[0,2*j+37:2*j+38])))\n",
        "\n",
        "        obsfuels_max=np.array(obsfuels_max).reshape(-1)\n",
        "        obsfuels_min=np.array(obsfuels_min).reshape(-1)\n",
        "        actionfuels_max=np.array(actionfuels_max).reshape(-1)\n",
        "        actionfuels_min=np.array(actionfuels_min).reshape(-1)\n",
        "        rewardfuels_max=np.array(rewardfuels_max).reshape(-1)\n",
        "        rewardfuels_min=np.array(rewardfuels_min).reshape(-1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        vvmm1_dict=pd.concat([pd.Series(obsState_max),pd.Series(obsState_min),pd.Series(rewardState_max),pd.Series(rewardState_min),pd.Series(actionState_max),pd.Series(actionState_min)],axis=1)\n",
        "\n",
        "        vvmm1_dict.columns=['obsState_max','obsState_min','rewardState_max','rewardState_min','actionState_max','actionState_min']\n",
        "\n",
        "        vvmm2_dict=pd.concat([pd.Series(obsfuels_max),pd.Series(obsfuels_min),pd.Series(rewardfuels_max),pd.Series(rewardfuels_min),pd.Series(actionfuels_max),pd.Series(actionfuels_min)],axis=1)\n",
        "\n",
        "        vvmm2_dict.columns=['obsFuels_min','obsFuels_max','rewardFuels_min','rewardFuels_max','actionFuels_min','actionFuels_max']\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        fv=pd.concat((vvmm2_dict,aadd2),axis=1)\n",
        "        sv=pd.concat((vvmm1_dict,aadd1),axis=1)\n",
        "        ssv=np.zeros((9,9))\n",
        "        ssv=pd.DataFrame(ssv)\n",
        "        ssv.columns=sv.columns\n",
        "        sssv=sv+ssv\n",
        "        sv=sssv\n",
        "        svfv=pd.concat((sv,fv),axis=1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        #result=pd.concat([aadd1,vvmm1_dict], axis=1)\n",
        "        #result.columns=['obsState','actionState','reward','obsState_max','obsState_min','rewardState_max','rewardState_min','actionState_max','actionState_min']\n",
        "       # result2=pd.concat([aadd2,vvnn2], axis=1)\n",
        "       # resulttensor=torch.tensor(result.to_numpy())\n",
        "        #print(resulttensor)\n",
        "        result=svfv.to_dict(orient='list')\n",
        "\n",
        "        return result\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def _step(tensordict):\n",
        "    # ...\n",
        "    td=env.gen_params()\n",
        "\n",
        "    # Extract the necessary DataFrames from rresult\n",
        "    # Extract the variables needed in _make_spec\n",
        "    n_agents =  env.n_agents\n",
        "    agent_tds = []\n",
        "    agents = [{} for _ in range(n_agents)]\n",
        "    obs=[]\n",
        "    reward=[]\n",
        "    action=[]\n",
        "    obsj=[]\n",
        "    rewardj=[]\n",
        "    actionj=[]\n",
        "    newobs=[]\n",
        "    for i in range(n_agents):\n",
        "        agent_obs_list=[]\n",
        "        agent_reward_list=[]\n",
        "        agent_action_list=[]\n",
        "        newobs_obs_list=[]\n",
        "        agent_reward_list1=[]\n",
        "        agent_action_list1=[]\n",
        "\n",
        "        for j in range(env.batch_size[0]):\n",
        "            td=env.gen_params()\n",
        "            obsState=td['params','obsState'].clone().detach()\n",
        "            rewardState=td['params','rewardState'].clone().detach()\n",
        "            actionState=td['params','actionState'].clone().detach()\n",
        "            obsFuels=td['params','obsFuels'].clone().detach().unsqueeze((-1))\n",
        "            rewardFuels=td['params','rewardFuels'].clone().detach().unsqueeze((-1))\n",
        "            actionFuels=td['params','actionFuels'].clone().detach().unsqueeze((-1))\n",
        "\n",
        "            obs=torch.cat(((torch.mul((obsState[0:4]),torch.ones(len(obsFuels),1))),obsFuels),dim=1)\n",
        "            reward=torch.cat(((torch.mul((rewardState[0:4]),torch.ones(len(obsFuels),1))),rewardFuels),dim=1)\n",
        "            action=torch.cat(((torch.mul((actionState[0:4]),torch.ones(len(obsFuels),1))),actionFuels),dim=1)\n",
        "            agent_obs_list.append(obs)\n",
        "            agent_reward_list.append(reward)\n",
        "            agent_reward_list1.append(reward[4])\n",
        "            agent_action_list.append(action)\n",
        "            agent_action_list1.append(action[4])\n",
        "\n",
        "        torch.stack(agent_reward_list, dim=1)\n",
        "        torch.stack(agent_reward_list1, dim=1)\n",
        "        torch.stack(agent_action_list, dim=1)\n",
        "        torch.stack(agent_action_list1, dim=1)\n",
        "        torch.stack(agent_obs_list, dim=1)\n",
        "\n",
        "        for i,[agent_obs,agent_reward,agent_action], in enumerate(zip(agent_obs_list,agent_reward_list,agent_action_list)):\n",
        "\n",
        "            newobs=torch.add(agent_obs,((agent_action)*agent_reward))\n",
        "            newobs_obs_list.append(newobs)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        agent_reward=torch.stack(agent_reward_list1, dim=0) # Changed rewardj to agent_reward_list\n",
        "\n",
        "        agent_action=torch.stack(agent_action_list1, dim=0) # Changed actionj to agent_action_list\n",
        "\n",
        "        agent_obs=torch.stack(newobs_obs_list, dim=0) # Changed obsj to newobs_obs_list\n",
        "\n",
        "\n",
        "\n",
        "      # Ensure agent_obs_tensor has the correct batch dimension\n",
        "        observation  = agent_obs.float()\n",
        "        episode_reward  = agent_reward.float()\n",
        "\n",
        "        agent_action_tensor =  agent_action.float()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    dones = torch.zeros((env.batch_size[0],1), dtype=torch.bool)\n",
        "    nextt = TensorDict({\n",
        "      \"agents\": {\n",
        "            \"observation\": observation[:, 0:n_agents, :], # Make sure 'observation' is included here\n",
        "            \"reward\":episode_reward[:, 0:n_agents].unsqueeze(-1),\n",
        "\n",
        "\n",
        "          },\n",
        "\n",
        "       \"terminated\": dones.clone(),\n",
        "        \"done\": dones.clone(),\n",
        "        \"info\": {}\n",
        "    },\n",
        "                       batch_size=env.batch_size, device=env.device)\n",
        "    return nextt\n",
        "\n",
        "def _reset(self, tensordict=None, **kwargs):\n",
        "\n",
        "    if tensordict is None:\n",
        "      td = self.gen_params(batch_size=self.batch_size)\n",
        "      obsState_max=td['params','obsState_max'].clone().detach()\n",
        "      obsState_min=td['params','obsState_min'].clone().detach()\n",
        "      obsFuels_max=td['params','obsFuels_max'].clone().detach()\n",
        "      obsFuels_min=td['params','obsFuels_min'].clone().detach()\n",
        "      n_agents = self.n_agents\n",
        "\n",
        "\n",
        "\n",
        "      # Initialize agent list here\n",
        "      batchtentensor=[]\n",
        "      agents = [{} for _ in range(self.n_agents)]\n",
        "      agents = [{\"id\": i, \"data\": torch.randn(5)} for i in range(self.n_agents)]\n",
        "      agent_obs_list = [] # Collect observations in a list first\n",
        "      agent_tds = []\n",
        "      agent_obs_tensor=[]\n",
        "      agents = [{} for _ in range(self.n_agents)]\n",
        "      agents = [{\"id\": i, \"data\": torch.randn(5)} for i in range(self.n_agents)]\n",
        "      agent_obs_list = [] # Collect observations in a list first\n",
        "      agent_tds = []\n",
        "      agent_obs_tensor=[]\n",
        "\n",
        "\n",
        "      # Iterate over the DataFrame\n",
        "      low_x=[]\n",
        "      high_x=[]\n",
        "      obs=[]\n",
        "      random_numbers = torch.rand((self.batch_size[0],5), generator=self.rng, device=self.device) # Changed random number generation\n",
        "      for i in range(self.batch_size[0]):\n",
        "          # Check if obsFuels_max has enough elements in dimension 0\n",
        "          if obsFuels_max.shape[0] > i:\n",
        "              high_x.append(torch.cat(((obsState_max[i,0:4].expand(n_agents,4)),obsFuels_max[i,0:n_agents].unsqueeze(0).T),dim=1)) # Use n_agents instead of hardcoded 9, add unsqueeze for correct shape\n",
        "              low_x.append(torch.cat(((obsState_min[i,0:4].expand(n_agents,4)),obsFuels_min[i,0:n_agents].unsqueeze(0).T),dim=1)) # Use n_agents instead of hardcoded 9, add unsqueeze for correct shape\n",
        "          else:\n",
        "              # Handle the case where obsFuels_max has fewer elements\n",
        "              # For example, you could repeat the last element or use a default value\n",
        "              high_x.append(torch.cat(((obsState_max[i,0:4].expand(n_agents,4)),obsFuels_max[-1,:n_agents].unsqueeze(1).T),dim=1)) # Repeat last element\n",
        "              low_x.append(torch.cat(((obsState_min[i,0:4].expand(n_agents,4)),obsFuels_min[-1,:n_agents].unsqueeze(1).T),dim=1)) # Repeat last element\n",
        "\n",
        "      low_xx=torch.stack(low_x, dim=0)\n",
        "      low_xx=low_xx[:,:,:5]# Changed stacking dimension to 0\n",
        "      high_xx=torch.stack(high_x, dim=0) # Changed stacking dimension to 0\n",
        "      high_xx=low_xx[:,:,:5]\n",
        "\n",
        "\n",
        "      obs= torch.add(torch.mul(random_numbers.unsqueeze(1), torch.add(high_xx, -low_xx)), low_xx) # Removed slicing, added unsqueeze\n",
        "\n",
        "      obs= obs.float()\n",
        "          # Iterate over the DataFrame\n",
        "\n",
        "      # Removed unnecessary loop\n",
        "      agent_obs_tensor = obs # Assign obs directly to agent_\n",
        "\n",
        "      dones = torch.zeros((self.batch_size[0],1), dtype=torch.bool)\n",
        "\n",
        "      resett = TensorDict(\n",
        "        {\n",
        "        \"agents\": {  # Add \"agents\" key\n",
        "            \"observation\": agent_obs_tensor,  # Directly use agent_obs_tensor\n",
        "        },\n",
        "        \"terminated\": dones.clone(),\n",
        "        \"done\": dones.clone(),\n",
        "        \"info\": {}\n",
        "         },\n",
        "        batch_size=self.batch_size[0], device=self.device)\n",
        "      return resett\n",
        "\n",
        "# @title Default title text\n",
        "def _make_spec(self, td_agents):\n",
        "    agent =[{}]*self.n_agents\n",
        "    action_specs = []\n",
        "    observation_specs = []\n",
        "    reward_specs = []\n",
        "\n",
        "    # Initialize result lists outside the loop\n",
        "\n",
        "\n",
        "    td = self.gen_params()\n",
        "    obsState_max=td_agents['params','obsState_max'].clone().detach()\n",
        "    obsState_min=td_agents['params','obsState_min'].clone().detach()\n",
        "    rewardState_max=td_agents['params','rewardState_max'].clone().detach()\n",
        "    rewardState_min=td_agents['params','rewardState_min'].clone().detach()\n",
        "    actionState_max=td_agents['params','actionState_max'].clone().detach()\n",
        "    actionState_min=td_agents['params','actionState_min'].clone().detach()\n",
        "    obsFuels_max=td_agents['params','obsFuels_max'].clone().detach()\n",
        "    obsFuels_min=td_agents['params','obsFuels_min'].clone().detach()\n",
        "    rewardFuels_max=td_agents['params','rewardFuels_max'].clone().detach()\n",
        "    rewardFuels_min=td_agents['params','rewardFuels_min'].clone().detach()\n",
        "    actionFuels_max=td_agents['params','actionFuels_max'].clone().detach()\n",
        "    actionFuels_min=td_agents['params','actionFuels_min'].clone().detach()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    low=torch.cat((torch.multiply(torch.ones((self.n_agents,1)),torch.tensor(self.rewstin.values)[:,None])),torch.reshape(torch.tensor(self.rewfmin.values),(self.n_agents, 1)),dim=1)\n",
        "    for i in range(self.n_agents):\n",
        "        agent[i][\"action_spec\"] =  BoundedTensorSpec(low = (actionFuels_min[i:i+1]).reshape(1,),\n",
        "                                                     high = (actionFuels_max[i:i+1]).reshape(1,),\n",
        "                                                     shape=(1,),\n",
        "                                                     dtype=torch.float32),\n",
        "\n",
        "        agent[i][\"reward_spec\"] =  BoundedTensorSpec(low = (rewardFuels_min[i:i+1]).reshape(1,),\n",
        "                                                     high = (rewardFuels_max[i:i+1]).reshape(1,),\n",
        "                                                     shape=(1,),\n",
        "                                                     dtype=torch.float32),\n",
        "\n",
        "        agent[i][\"reward_spec\"] =  BoundedTensorSpec(low = (rewardFuels_min[i:i+1]).reshape(1,),\n",
        "                                                     high = (rewardFuels_max[i:i+1]).reshape(1,),\n",
        "                                                     shape=(1,),\n",
        "                                                     dtype=torch.float32),\n",
        "\n",
        "\n",
        "        agent[i][\"observation_spec\"]  = BoundedTensorSpec(low = torch.cat((obsState_min[0:4],obsFuels_min[i:i+1]),1).reshape(1, 5),\n",
        "                                                          high = torch.cat((obsState_max[0:4],obsFuels_max[i:i+1]),1).reshape(1, 5),\n",
        "                                                          shape=(5,),\n",
        "                                                          dtype=torch.float32),\n",
        "\n",
        "\n",
        "        action_specs.append(agent[i][\"action_spec\"])\n",
        "        reward_specs.append(agent[i][\"reward_spec\"])\n",
        "        observation_specs.append(agent[i][\"observation_spec\"])\n",
        "\n",
        "\n",
        "\n",
        "# Construct CompositeSpec objects with the correct nesting and batch size\n",
        "def _make_spec_updated(self, td_agents):\n",
        "    if not isinstance(td_agents, (dict, list, TensorDictBase)):\n",
        "      raise TypeError(\"td_agents must be subscriptable (e.g., a dictionary or list)\")\n",
        "\n",
        "    td_agents=self.gen_params()\n",
        "\n",
        "    agent =[{}]*self.n_agents\n",
        "    action_specs = []\n",
        "    observation_specs = []\n",
        "    reward_specs = []\n",
        "\n",
        "    # Initialize result lists outside the loop\n",
        "    actionState_min=td_agents['params','actionState_min'].clone().detach()\n",
        "    actionState_max=td_agents['params','actionState_max'].clone().detach()\n",
        "    rewardState_min=td_agents['params','rewardState_min'].clone().detach()\n",
        "    rewardState_max=td_agents['params','rewardState_max'].clone().detach()\n",
        "    obsState_min=td_agents['params','obsState_min'].clone().detach()\n",
        "    obsState_max=td_agents['params','obsState_max'].clone().detach()\n",
        "    actionFuels_min=td_agents['params','actionFuels_min'].clone().detach()\n",
        "    actionFuels_max=td_agents['params','actionFuels_max'].clone().detach()\n",
        "    rewardFuels_min=td_agents['params','rewardFuels_min'].clone().detach()\n",
        "    rewardFuels_max=td_agents['params','rewardFuels_max'].clone().detach()\n",
        "    obsFuels_min=td_agents['params','obsFuels_min'].clone().detach()\n",
        "    obsFuels_max=td_agents['params','obsFuels_max'].clone().detach()\n",
        "\n",
        "\n",
        "    result55=[]\n",
        "    result55=[]\n",
        "    result44=[]\n",
        "    result33=[]\n",
        "    result22=[]\n",
        "    result11=[]\n",
        "    result00=[]\n",
        "    result555=[]\n",
        "    result444=[]\n",
        "    result333=[]\n",
        "    result222=[]\n",
        "    result111=[]\n",
        "    result000=[]\n",
        "    for i in range(self.n_agents):  # Make sure the loop iterates 9 times\n",
        "        result55.append((actionFuels_min[i]).reshape(1,)) # make sure the shape is (1,)\n",
        "        result44.append((actionFuels_max[i]).reshape(1,)) # make sure the shape is (1,)\n",
        "        result33.append((rewardFuels_min[i]).reshape(1,)) # make sure the shape is (1,)\n",
        "        result22.append((rewardFuels_max[i]).reshape(1,)) # make sure the shape is (1,)\n",
        "        result11.append(torch.cat((obsState_min[0:4],obsFuels_min[i:i+1]),0).reshape(5,))\n",
        "        result00.append(torch.cat((obsState_max[0:4],obsFuels_max[i:i+1]),0).reshape(5,)) # make sure the shape is (5,)\n",
        "\n",
        "    result555= torch.stack(result55,dim=0) # Transpose dimensions 0 and 1\n",
        "    result444 =torch.stack(result44,dim=0)\n",
        "    result333 =torch.stack(result33,dim=0)\n",
        "    result222 =torch.stack(result22,dim=0)\n",
        "    result111 =torch.stack(result11,dim=0)\n",
        "    result000 =torch.stack(result00,dim=0)\n",
        "    print(result555)\n",
        "    print(result444)\n",
        "    print(result333)\n",
        "    print(result222)\n",
        "    print(result111)\n",
        "    print(result000)\n",
        "\n",
        "\n",
        "    self.unbatched_action_spec = CompositeSpec(\n",
        "    {\"agents\": CompositeSpec(\n",
        "           {\"action\": BoundedTensorSpec(\n",
        "                low=result555,\n",
        "                high=result444,\n",
        "                shape=(self.n_agents,1),\n",
        "                dtype=torch.float32,\n",
        "             )}\n",
        "        )}\n",
        "    )\n",
        "\n",
        "    self.unbatched_reward_spec = CompositeSpec(\n",
        "    {\"agents\": CompositeSpec(\n",
        "            {\"reward\": BoundedTensorSpec(\n",
        "                low=result333,\n",
        "                high=result222,\n",
        "                shape=(self.n_agents,1),\n",
        "                dtype=torch.float32,\n",
        "             )}\n",
        "        )}\n",
        "    )\n",
        "\n",
        "\n",
        "    self.unbatched_observation_spec = CompositeSpec(  # Change to unbatched_observation_spec\n",
        "    {\"agents\": CompositeSpec(\n",
        "            {\"observation\": BoundedTensorSpec(\n",
        "                low=result111,\n",
        "                high=result000,\n",
        "                shape=(self.n_agents,5),\n",
        "                dtype=torch.float32,\n",
        "             )}\n",
        "        )}\n",
        "    )\n",
        "\n",
        "\n",
        "\n",
        "    self.unbatched_done_spec = DiscreteTensorSpec(n = 2,shape =torch.Size((1,)), dtype = torch.bool)\n",
        "\n",
        "    # Now you can expand the specs\n",
        "    self.unbatched_done_spec = DiscreteTensorSpec(\n",
        "        n=2, shape=torch.Size((1,)), dtype=torch.bool\n",
        "    )\n",
        "\n",
        "    # Now you can expand the specs\n",
        "    self.action_spec = self.unbatched_action_spec.expand(\n",
        "        *self.batch_size, *self.unbatched_action_spec.shape\n",
        "    )\n",
        "    self.observation_spec = self.unbatched_observation_spec.expand(\n",
        "        *self.batch_size, *self.unbatched_observation_spec.shape\n",
        "    )  # Use unbatched_observation_spec\n",
        "    self.reward_spec = self.unbatched_reward_spec.expand(\n",
        "        *self.batch_size, *self.unbatched_reward_spec.shape\n",
        "    )\n",
        "    self.done_spec = self.unbatched_done_spec.expand(\n",
        "        *self.batch_size, *self.unbatched_done_spec.shape\n",
        "    )\n",
        "\n",
        "\n",
        "\n",
        "def make_composite_from_td(td):\n",
        "    # custom function to convert a ``tensordict`` in a similar spec structure\n",
        "    # of unbounded values.\n",
        "    composite = CompositeSpec(\n",
        "        {\n",
        "            key: make_composite_from_td(tensor)\n",
        "            if isinstance(tensor, TensorDictBase)\n",
        "            else UnboundedContinuousTensorSpec(\n",
        "                dtype=tensor.dtype, device=tensor.device, shape=tensor.shape\n",
        "            )\n",
        "            for key, tensor in td.items()\n",
        "        },\n",
        "        shape=td.shape,\n",
        "    )\n",
        "    return composite\n",
        "\n",
        "\n",
        "\n",
        "def gen_params(batch_size=torch.Size()) -> TensorDictBase:\n",
        "    \"\"\"Returns a ``tensordict`` containing the input tensors.\"\"\"\n",
        "    if batch_size is None:\n",
        "      batch_size = []\n",
        "    my_object=DDataenv()\n",
        "    ac=my_object._get_obs_stats()\n",
        "    if batch_size:\n",
        "        # Assuming 'ac' is a dictionary of tensors, expand each tensor\n",
        "        ac = {k: torch.tensor(v).expand(*batch_size, *torch.tensor(v).shape)  for k, v in ac.items()} # Convert lists to tensors before expanding\n",
        "\n",
        "\n",
        "    td = TensorDict({\n",
        "\n",
        "          \"params\":{\"actionState_min\": ac['actionState_min'], # Add the missing key-value pair\n",
        "            \"actionState_max\": ac['actionState_max'], # Add the missing key-value pair\n",
        "            \"rewardState_min\": ac['rewardState_min'], # Add the missing key-value pair\n",
        "            \"rewardState_max\": ac['rewardState_max'], # Add the missing key-value pair\n",
        "            \"obsState_min\": ac['obsState_min'], # Add the missing key-value pair\n",
        "            \"obsState_max\": ac['obsState_max'], # Add the missing key-value pair\n",
        "            'obsState':ac['obsState'],\n",
        "            'rewardState':ac['rewardState'],\n",
        "            'actionState':ac['actionState'],\n",
        "            'obsFuels_min': ac['obsFuels_min'],\n",
        "            'obsFuels_max': ac['obsFuels_max'],\n",
        "            'rewardFuels_min':ac['rewardFuels_min'],\n",
        "            'rewardFuels_max':ac['rewardFuels_max'],\n",
        "            'actionFuels_min': ac['actionFuels_min'],\n",
        "            'actionFuels_max': ac['actionFuels_max'],\n",
        "            'obsFuels': ac['obsFuels'],\n",
        "            'rewardFuels': ac['rewardFuels'],\n",
        "            'actionFuels': ac['actionFuels'],\n",
        "            }\n",
        "          }\n",
        "        ,\n",
        "        batch_size=batch_size,\n",
        "        device=torch.device(\"cpu\" if torch.cuda.is_available() else \"cpu\"),\n",
        "    )\n",
        "    if batch_size:\n",
        "      td = td.expand(batch_size).contiguous()\n",
        "    return td\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def _set_seed(self, seed:45):\n",
        "    rng = torch.manual_seed(seed)\n",
        "    self.rng = rng\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class AnFuelpriceEnv(EnvBase):\n",
        "    metadata = {\n",
        "        \"render_modes\": [\"human\", \"rgb_array\"],\n",
        "        \"render_fps\": 30,\n",
        "    }\n",
        "    batch_locked = False\n",
        "\n",
        "    def __init__(self,td_params=None, seed=None, device=\"cpu\"):\n",
        "        if td_params is None:\n",
        "            td_params = self.gen_params()\n",
        "\n",
        "\n",
        "        # Extract the variables needed in _make_spec\n",
        "        self.n_agents = 2\n",
        "\n",
        "        self.agent_tds = []\n",
        "        self.agents = [{} for _ in range(self.n_agents)]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        super().__init__(device=device, batch_size=[10])\n",
        "        self._make_spec(td_params)\n",
        "        if seed is None:\n",
        "            seed = torch.empty((), dtype=torch.int64).random_().item()\n",
        "        self.set_seed(seed)\n",
        "\n",
        "\n",
        "\n",
        "    # Helpers: _make_step and gen_params\n",
        "    gen_params =staticmethod(gen_params)\n",
        "    _make_spec = _make_spec_updated\n",
        "    # Mandatory methods: _step, _reset and _set_seed\n",
        "    _reset = _reset\n",
        "    _step = staticmethod(_step)\n",
        "    _set_seed = _set_seed\n",
        "\n",
        "env = AnFuelpriceEnv()\n",
        "print(\"\\n*action_spec:\", env.full_action_spec)\n",
        "print(\"\\n*reward_spec:\", env.full_reward_spec)\n",
        "print(\"\\n*done_spec:\", env.full_done_spec)\n",
        "print(\"\\n*observation_spec:\", env.observation_spec)\n",
        "\n",
        "print(\"\\n-action_keys:\", env.action_keys)\n",
        "print(\"\\n-reward_keys:\", env.reward_keys)\n",
        "print(\"\\n-done_keys:\", env.done_keys)\n",
        "\n",
        "print(\"input_spec:\", env.input_spec)\n",
        "print(\"action_spec (as defined by input_spec):\", env.action_spec)\n",
        "print(\"reward_spec:\", env.reward_spec)\n",
        "td = env.reset()\n",
        "print(\"reset tensordict\", td)\n",
        "check_env_specs(env)"
      ],
      "metadata": {
        "id": "8_nd6bvcyda9",
        "outputId": "5983e240-000d-46b0-8eca-c3d7fcc0dea1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "tensor([[0.],\n",
            "        [0.]], dtype=torch.float64)\n",
            "tensor([[2.],\n",
            "        [2.]], dtype=torch.float64)\n",
            "tensor([[0.],\n",
            "        [0.]], dtype=torch.float64)\n",
            "tensor([[5.0710],\n",
            "        [3.7210]], dtype=torch.float64)\n",
            "tensor([[ 0.6057, 12.2200,  9.1200,  0.0000,  0.2280],\n",
            "        [ 0.6057, 12.2200,  9.1200,  0.0000,  0.2030]], dtype=torch.float64)\n",
            "tensor([[  0.7894, 140.7300, 144.0000, 145.2000,   5.2960],\n",
            "        [  0.7894, 140.7300, 144.0000, 145.2000,   5.1960]],\n",
            "       dtype=torch.float64)\n",
            "\n",
            "*action_spec: CompositeSpec(\n",
            "    agents: CompositeSpec(\n",
            "        action: BoundedTensorSpec(\n",
            "            shape=torch.Size([10, 2, 1]),\n",
            "            space=ContinuousBox(\n",
            "                low=Tensor(shape=torch.Size([10, 2, 1]), device=cpu, dtype=torch.float32, contiguous=True),\n",
            "                high=Tensor(shape=torch.Size([10, 2, 1]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
            "            device=cpu,\n",
            "            dtype=torch.float32,\n",
            "            domain=continuous),\n",
            "        device=cpu,\n",
            "        shape=torch.Size([10])),\n",
            "    device=cpu,\n",
            "    shape=torch.Size([10]))\n",
            "\n",
            "*reward_spec: CompositeSpec(\n",
            "    agents: CompositeSpec(\n",
            "        reward: BoundedTensorSpec(\n",
            "            shape=torch.Size([10, 2, 1]),\n",
            "            space=ContinuousBox(\n",
            "                low=Tensor(shape=torch.Size([10, 2, 1]), device=cpu, dtype=torch.float32, contiguous=True),\n",
            "                high=Tensor(shape=torch.Size([10, 2, 1]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
            "            device=cpu,\n",
            "            dtype=torch.float32,\n",
            "            domain=continuous),\n",
            "        device=cpu,\n",
            "        shape=torch.Size([10])),\n",
            "    device=cpu,\n",
            "    shape=torch.Size([10]))\n",
            "\n",
            "*done_spec: CompositeSpec(\n",
            "    done: DiscreteTensorSpec(\n",
            "        shape=torch.Size([10, 1]),\n",
            "        space=DiscreteBox(n=2),\n",
            "        device=cpu,\n",
            "        dtype=torch.bool,\n",
            "        domain=discrete),\n",
            "    terminated: DiscreteTensorSpec(\n",
            "        shape=torch.Size([10, 1]),\n",
            "        space=DiscreteBox(n=2),\n",
            "        device=cpu,\n",
            "        dtype=torch.bool,\n",
            "        domain=discrete),\n",
            "    device=cpu,\n",
            "    shape=torch.Size([10]))\n",
            "\n",
            "*observation_spec: CompositeSpec(\n",
            "    agents: CompositeSpec(\n",
            "        observation: BoundedTensorSpec(\n",
            "            shape=torch.Size([10, 2, 5]),\n",
            "            space=ContinuousBox(\n",
            "                low=Tensor(shape=torch.Size([10, 2, 5]), device=cpu, dtype=torch.float32, contiguous=True),\n",
            "                high=Tensor(shape=torch.Size([10, 2, 5]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
            "            device=cpu,\n",
            "            dtype=torch.float32,\n",
            "            domain=continuous),\n",
            "        device=cpu,\n",
            "        shape=torch.Size([10])),\n",
            "    device=cpu,\n",
            "    shape=torch.Size([10]))\n",
            "\n",
            "-action_keys: [('agents', 'action')]\n",
            "\n",
            "-reward_keys: [('agents', 'reward')]\n",
            "\n",
            "-done_keys: ['done', 'terminated']\n",
            "input_spec: CompositeSpec(\n",
            "    full_state_spec: CompositeSpec(\n",
            "    ,\n",
            "        device=cpu,\n",
            "        shape=torch.Size([10])),\n",
            "    full_action_spec: CompositeSpec(\n",
            "        agents: CompositeSpec(\n",
            "            action: BoundedTensorSpec(\n",
            "                shape=torch.Size([10, 2, 1]),\n",
            "                space=ContinuousBox(\n",
            "                    low=Tensor(shape=torch.Size([10, 2, 1]), device=cpu, dtype=torch.float32, contiguous=True),\n",
            "                    high=Tensor(shape=torch.Size([10, 2, 1]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
            "                device=cpu,\n",
            "                dtype=torch.float32,\n",
            "                domain=continuous),\n",
            "            device=cpu,\n",
            "            shape=torch.Size([10])),\n",
            "        device=cpu,\n",
            "        shape=torch.Size([10])),\n",
            "    device=cpu,\n",
            "    shape=torch.Size([10]))\n",
            "action_spec (as defined by input_spec): BoundedTensorSpec(\n",
            "    shape=torch.Size([10, 2, 1]),\n",
            "    space=ContinuousBox(\n",
            "        low=Tensor(shape=torch.Size([10, 2, 1]), device=cpu, dtype=torch.float32, contiguous=True),\n",
            "        high=Tensor(shape=torch.Size([10, 2, 1]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
            "    device=cpu,\n",
            "    dtype=torch.float32,\n",
            "    domain=continuous)\n",
            "reward_spec: BoundedTensorSpec(\n",
            "    shape=torch.Size([10, 2, 1]),\n",
            "    space=ContinuousBox(\n",
            "        low=Tensor(shape=torch.Size([10, 2, 1]), device=cpu, dtype=torch.float32, contiguous=True),\n",
            "        high=Tensor(shape=torch.Size([10, 2, 1]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
            "    device=cpu,\n",
            "    dtype=torch.float32,\n",
            "    domain=continuous)\n",
            "reset tensordict TensorDict(\n",
            "    fields={\n",
            "        agents: TensorDict(\n",
            "            fields={\n",
            "                observation: Tensor(shape=torch.Size([10, 2, 5]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
            "            batch_size=torch.Size([10]),\n",
            "            device=cpu,\n",
            "            is_shared=False),\n",
            "        done: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
            "        info: TensorDict(\n",
            "            fields={\n",
            "            },\n",
            "            batch_size=torch.Size([10]),\n",
            "            device=cpu,\n",
            "            is_shared=False),\n",
            "        terminated: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
            "    batch_size=torch.Size([10]),\n",
            "    device=cpu,\n",
            "    is_shared=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024-09-22 15:36:54,437 [torchrl][INFO] check_env_specs succeeded!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_object=DDataenv()\n",
        "ac=my_object._get_obs_stats()\n",
        "print(ac)"
      ],
      "metadata": {
        "id": "SKdVNtF0ZqDL",
        "outputId": "aedfe0f5-8d68-4a75-f63b-fea794e86a76",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'obsState_max': [0.789355993270874, 140.72999572753906, 144.0, 145.1999969482422, nan, nan, nan, nan, nan], 'obsState_min': [0.6056600213050842, 12.220000267028809, 9.119999885559082, 0.0, nan, nan, nan, nan, nan], 'rewardState_max': [0.04583945497870445, 39.67445755004883, 40.8235969543457, 36.34737014770508, nan, nan, nan, nan, nan], 'rewardState_min': [0.0, 0.0, 0.0, 0.0, nan, nan, nan, nan, nan], 'actionState_max': [2.0, 2.0, 2.0, 2.0, nan, nan, nan, nan, nan], 'actionState_min': [0.0, 0.0, 0.0, 0.0, nan, nan, nan, nan, nan], 'obsState': [0.6826540231704712, 39.5, 43.099998474121094, 45.619998931884766, nan, nan, nan, nan, nan], 'rewardState': [0.0, 0.0, 0.0, 0.0, nan, nan, nan, nan, nan], 'actionState': [1.0, 1.0, 1.0, 1.0, nan, nan, nan, nan, nan], 'obsFuels_min': [0.2280000001192093, 0.2029999941587448, 0.24500000476837158, 0.21799999475479126, 0.27399998903274536, 0.2930000126361847, 0.24799999594688416, 0.3199999928474426, 0.23000000417232513], 'obsFuels_max': [5.296000003814697, 5.196000099182129, 4.9679999351501465, 5.008999824523926, 5.160999774932861, 5.339000225067139, 5.065999984741211, 5.339000225067139, 5.071000099182129], 'rewardFuels_min': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'rewardFuels_max': [5.071000099182129, 3.7209999561309814, 3.7049999237060547, 3.9049999713897705, 3.0880000591278076, 3.4749999046325684, 3.6610000133514404, 3.8369998931884766, 3.4609999656677246], 'actionFuels_min': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'actionFuels_max': [2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0], 'obsFuels': [1.2860000133514404, 1.4900000095367432, 1.371000051498413, 1.2640000581741333, 1.5149999856948853, 1.2589999437332153, 0.7850000262260437, 1.2730000019073486, 1.3860000371932983], 'rewardFuels': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'actionFuels': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vectorize Environments"
      ],
      "metadata": {
        "id": "1jVP8BBfiLqD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class VectorEnv:\n",
        "    def __init__(self, make_env_fn, n):\n",
        "        self.envs = tuple(make_env_fn() for _ in range(n))\n",
        "\n",
        "    # Call this only once at the beginning of training (optional):\n",
        "    def seed(self, seeds):\n",
        "        assert len(self.envs) == len(seeds)\n",
        "        return tuple(env.seed(s) for env, s in zip(self.envs, seeds))\n",
        "\n",
        "    # Call this only once at the beginning of training:\n",
        "    def reset(self):\n",
        "        return tuple(env.reset() for env in self.envs)\n",
        "\n",
        "    # Call this on every timestep:\n",
        "    def step(self, actions):\n",
        "        assert len(self.envs) == len(actions)\n",
        "        return_values = []\n",
        "        for env, a in zip(self.envs, actions):\n",
        "            observation, reward, done, info = env.step(a)\n",
        "            if done:\n",
        "                observation = env.reset()\n",
        "            return_values.append((observation, reward, done, info))\n",
        "        return tuple(return_values)\n",
        "\n",
        "    # Call this at the end of training:\n",
        "    def close(self):\n",
        "        for env in self.envs:\n",
        "            env.close()"
      ],
      "metadata": {
        "id": "JwCcOuCoReWm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Hyperparameters"
      ],
      "metadata": {
        "id": "-XGMmWJMiCdq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " #Access the base environment through the 'env' attribute\n",
        "# Devices\n",
        "is_fork = multiprocessing.get_start_method() == \"fork\"\n",
        "device = torch.device(\"cpu\")\n",
        "\n",
        "# Sampling\n",
        "frames_per_batch = 100 #Number of team frames collected per training iteration\n",
        "n_iters = 5  # Number of sampling and training iterations\n",
        "total_frames = frames_per_batch * n_iters\n",
        "\n",
        "# Training\n",
        "num_epochs = 10  # Number of optimization steps per training iteration\n",
        "minibatch_size = 10  # Size of the mini-batches in each optimization step\n",
        "lr = 0.00000002  # Learning rate\n",
        "max_grad_norm = 1.0  # Maximum norm for the gradients\n",
        "\n",
        "# PPO\n",
        "clip_epsilon = 0.2  # clip value for PPO loss\n",
        "gamma = 0.99  # discount factor\n",
        "lmbda = 0.9  # lambda for generalised advantage estimation\n",
        "entropy_eps = 1e-4  # coefficient of the entropy term in the PPO loss"
      ],
      "metadata": {
        "id": "7k4FEG6YwQYV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_env = env\n",
        "env = TransformedEnv(\n",
        "   base_env,\n",
        "    Compose(ObservationNorm(in_keys=[(\"agents\", \"observation\")],),\n",
        "        DoubleToFloat(),\n",
        "        StepCounter(),\n",
        "\n",
        "\n",
        "        RewardSum(in_keys=[env.reward_key], out_keys=[(\"agents\", \"episode_reward\")]),\n",
        "        UnsqueezeTransform(in_keys=[(\"agents\", \"observation\")], out_keys=[(\"agents\", \"observation\")], dim=0)\n",
        "        BatchSizeTransform([10], reset_func=reset_func, env_kwarg=True)\n",
        "        PermuteTransform(dims[1,2,3,4,0, in_keys=[(\"agents\", \"observation\")], out_keys=[(\"agents\", \"observation\")],])\n",
        "        UnsqueezeTransform(in_keys=[(\"agents\", \"observation\")], out_keys=[(\"agents\", \"observation\")], dim=-2)\n",
        "\n",
        "    )\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "# Call init_stats to initialize the parameters of the ObservationNorm transform\n",
        "print(\"Data shape before init_stats:\", env.transform[0].in_keys)  # Check the shape of the input data\n",
        "for key in env.transform[0].in_keys:\n",
        "    print(f\"Data sample for key {key}:\", [(\"agents\", \"observation\")])  # Print a sample of the data\n",
        "env.transform[0].init_stats(num_iter=10, reduce_dim=[0], cat_dim=0)\n",
        "\n",
        "normashape = env.transform[0].loc.shape\n",
        "print(normashape)\n",
        "\n",
        "\n",
        "\n",
        "print(\"normalization constant shape:\", env.transform[0].loc.shape)\n",
        "print(env.transform[0].loc)\n",
        "print(env.transform[0].scale)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gxl_Br_nfFYn",
        "outputId": "2ea8f6b5-6724-468f-dd72-c2fd51f4072b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data shape before init_stats: [('agents', 'observation')]\n",
            "Data sample for key ('agents', 'observation'): [('agents', 'observation')]\n",
            "torch.Size([10, 2, 5])\n",
            "normalization constant shape: torch.Size([10, 2, 5])\n",
            "tensor([[[-6.0566e+05, -1.2220e+07, -9.1200e+06, -0.0000e+00, -2.2800e+05],\n",
            "         [-6.0566e+05, -1.2220e+07, -9.1200e+06, -0.0000e+00, -2.0300e+05]],\n",
            "\n",
            "        [[-1.3318e+01, -3.0910e+00, -2.9995e+00, -2.9825e+00, -2.2111e+00],\n",
            "         [-1.3318e+01, -3.0910e+00, -2.9995e+00, -2.9825e+00, -2.7087e+00]],\n",
            "\n",
            "        [[-2.3133e+01, -2.3555e+00, -2.3934e+00, -2.6221e+00, -1.7390e+00],\n",
            "         [-2.3133e+01, -2.3555e+00, -2.3934e+00, -2.6221e+00, -2.3773e+00]],\n",
            "\n",
            "        [[-1.7494e+01, -2.3449e+00, -2.3420e+00, -2.4212e+00, -1.5142e+00],\n",
            "         [-1.7494e+01, -2.3449e+00, -2.3420e+00, -2.4212e+00, -2.1686e+00]],\n",
            "\n",
            "        [[-1.4977e+01, -2.3040e+00, -2.3380e+00, -2.2524e+00, -2.0336e+00],\n",
            "         [-1.4977e+01, -2.3040e+00, -2.3380e+00, -2.2524e+00, -2.7608e+00]],\n",
            "\n",
            "        [[-1.2701e+01, -3.8046e+00, -4.0638e+00, -4.5377e+00, -1.9939e+00],\n",
            "         [-1.2701e+01, -3.8046e+00, -4.0638e+00, -4.5377e+00, -3.6735e+00]],\n",
            "\n",
            "        [[-1.7156e+01, -3.3407e+00, -3.3444e+00, -3.4375e+00, -2.6430e+00],\n",
            "         [-1.7156e+01, -3.3407e+00, -3.3444e+00, -3.4375e+00, -2.9634e+00]],\n",
            "\n",
            "        [[-2.1836e+01, -2.8309e+00, -2.9836e+00, -3.2294e+00, -1.4388e+00],\n",
            "         [-2.1836e+01, -2.8309e+00, -2.9836e+00, -3.2294e+00, -2.2687e+00]],\n",
            "\n",
            "        [[-1.4822e+01, -2.3265e+00, -2.3915e+00, -2.5419e+00, -2.0078e+00],\n",
            "         [-1.4822e+01, -2.3265e+00, -2.3915e+00, -2.5419e+00, -2.0270e+00]],\n",
            "\n",
            "        [[-1.6619e+01, -2.1604e+00, -2.1782e+00, -2.4300e+00, -2.0999e+00],\n",
            "         [-1.6619e+01, -2.1604e+00, -2.1782e+00, -2.4300e+00, -2.2829e+00]]])\n",
            "tensor([[[1.0000e+06, 1.0000e+06, 1.0000e+06, 1.0000e+06, 1.0000e+06],\n",
            "         [1.0000e+06, 1.0000e+06, 1.0000e+06, 1.0000e+06, 1.0000e+06]],\n",
            "\n",
            "        [[1.9523e+01, 4.1923e-02, 4.0116e-02, 4.2609e-02, 1.1333e+00],\n",
            "         [1.9523e+01, 4.1923e-02, 4.0116e-02, 4.2609e-02, 1.1924e+00]],\n",
            "\n",
            "        [[3.4118e+01, 3.3472e-02, 3.2590e-02, 3.7682e-02, 1.0887e+00],\n",
            "         [3.4118e+01, 3.3472e-02, 3.2590e-02, 3.7682e-02, 1.2282e+00]],\n",
            "\n",
            "        [[2.5630e+01, 2.9371e-02, 2.8130e-02, 3.0204e-02, 6.8434e-01],\n",
            "         [2.5630e+01, 2.9371e-02, 2.8130e-02, 3.0204e-02, 9.1072e-01]],\n",
            "\n",
            "        [[2.1411e+01, 3.0369e-02, 3.0028e-02, 3.0505e-02, 9.6119e-01],\n",
            "         [2.1411e+01, 3.0369e-02, 3.0028e-02, 3.0505e-02, 1.3167e+00]],\n",
            "\n",
            "        [[1.8471e+01, 4.4956e-02, 4.7838e-02, 5.5334e-02, 6.3941e-01],\n",
            "         [1.8471e+01, 4.4956e-02, 4.7838e-02, 5.5334e-02, 1.4567e+00]],\n",
            "\n",
            "        [[2.5011e+01, 4.1503e-02, 4.0249e-02, 4.5177e-02, 1.2983e+00],\n",
            "         [2.5011e+01, 4.1503e-02, 4.0249e-02, 4.5177e-02, 1.2587e+00]],\n",
            "\n",
            "        [[3.0361e+01, 4.3172e-02, 4.4360e-02, 5.2181e-02, 1.0684e+00],\n",
            "         [3.0361e+01, 4.3172e-02, 4.4360e-02, 5.2181e-02, 1.2553e+00]],\n",
            "\n",
            "        [[2.1480e+01, 2.9540e-02, 3.0269e-02, 3.3707e-02, 8.0192e-01],\n",
            "         [2.1480e+01, 2.9540e-02, 3.0269e-02, 3.3707e-02, 9.2618e-01]],\n",
            "\n",
            "        [[2.4342e+01, 3.1455e-02, 3.1077e-02, 3.5563e-02, 1.0274e+00],\n",
            "         [2.4342e+01, 3.1455e-02, 3.1077e-02, 3.5563e-02, 1.1557e+00]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "env.reset()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sfPlzH3WyojD",
        "outputId": "1a028961-fea3-4814-8b37-55fb819e2d78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorDict(\n",
              "    fields={\n",
              "        agents: TensorDict(\n",
              "            fields={\n",
              "                observation: Tensor(shape=torch.Size([10, 2, 5]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
              "            batch_size=torch.Size([10]),\n",
              "            device=cpu,\n",
              "            is_shared=False),\n",
              "        done: Tensor(shape=torch.Size([10, 2, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
              "        info: TensorDict(\n",
              "            fields={\n",
              "            },\n",
              "            batch_size=torch.Size([10]),\n",
              "            device=cpu,\n",
              "            is_shared=False),\n",
              "        step_count: Tensor(shape=torch.Size([10, 2, 1]), device=cpu, dtype=torch.int64, is_shared=False),\n",
              "        terminated: Tensor(shape=torch.Size([10, 2, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
              "    batch_size=torch.Size([10]),\n",
              "    device=cpu,\n",
              "    is_shared=False)"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cCxLvThI6hWZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "_dFBP0hnGTmp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "env.rollout(3)"
      ],
      "metadata": {
        "id": "AGcfP8loWS3J",
        "outputId": "433dcde0-8416-4292-f69e-7fe48e458fff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorDict(\n",
              "    fields={\n",
              "        agents: TensorDict(\n",
              "            fields={\n",
              "                action: Tensor(shape=torch.Size([10, 3, 2, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
              "                observation: Tensor(shape=torch.Size([10, 3, 2, 5]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
              "            batch_size=torch.Size([10, 3]),\n",
              "            device=cpu,\n",
              "            is_shared=False),\n",
              "        done: Tensor(shape=torch.Size([10, 3, 2, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
              "        info: TensorDict(\n",
              "            fields={\n",
              "            },\n",
              "            batch_size=torch.Size([10, 3]),\n",
              "            device=cpu,\n",
              "            is_shared=False),\n",
              "        next: TensorDict(\n",
              "            fields={\n",
              "                agents: TensorDict(\n",
              "                    fields={\n",
              "                        observation: Tensor(shape=torch.Size([10, 3, 2, 5]), device=cpu, dtype=torch.float32, is_shared=False),\n",
              "                        reward: Tensor(shape=torch.Size([10, 3, 2, 1]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
              "                    batch_size=torch.Size([10, 3]),\n",
              "                    device=cpu,\n",
              "                    is_shared=False),\n",
              "                done: Tensor(shape=torch.Size([10, 3, 2, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
              "                info: TensorDict(\n",
              "                    fields={\n",
              "                    },\n",
              "                    batch_size=torch.Size([10, 3]),\n",
              "                    device=cpu,\n",
              "                    is_shared=False),\n",
              "                step_count: Tensor(shape=torch.Size([10, 3, 2, 1]), device=cpu, dtype=torch.int64, is_shared=False),\n",
              "                terminated: Tensor(shape=torch.Size([10, 3, 2, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
              "            batch_size=torch.Size([10, 3]),\n",
              "            device=cpu,\n",
              "            is_shared=False),\n",
              "        step_count: Tensor(shape=torch.Size([10, 3, 2, 1]), device=cpu, dtype=torch.int64, is_shared=False),\n",
              "        terminated: Tensor(shape=torch.Size([10, 3, 2, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
              "    batch_size=torch.Size([10, 3]),\n",
              "    device=cpu,\n",
              "    is_shared=False)"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "source": [
        "##PolicyNet\n",
        "\n",
        "\n",
        "policy_net = torch.nn.Sequential(\n",
        "    MultiAgentMLP(n_agent_inputs=env.observation_spec[\"agents\", \"observation\"].shape[-1],\n",
        "                  n_agent_outputs=2 * env.action_spec.shape[-1],\n",
        "                  n_agents=env.n_agents,\n",
        "                  centralized= False ,\n",
        "                  share_params=False,\n",
        "                  device= device,\n",
        "                  depth=3 ,\n",
        "                  num_cells=[64,128,256],\n",
        "                  activation_class= torch.nn.Tanh,\n",
        "                  ),\n",
        "    NormalParamExtractor() # Extract the loc and scale parameters\n",
        ")\n",
        "\n",
        "\n",
        "policy_module = TensorDictModule(\n",
        "    policy_net,\n",
        "    in_keys=[(\"agents\", \"observation\")],\n",
        "    out_keys=[(\"agents\", \"loc\"), (\"agents\", \"scale\")],\n",
        ")\n",
        "\n",
        "\n",
        "policy = ProbabilisticActor(\n",
        "    module=policy_module,\n",
        "    spec=env.unbatched_action_spec,\n",
        "    in_keys=[(\"agents\", \"loc\"), (\"agents\", \"scale\")],\n",
        "    out_keys=[env.action_key],\n",
        "    distribution_class=TanhNormal,\n",
        "    distribution_kwargs={\n",
        "        \"low\": env.unbatched_action_spec[env.action_key].space.low,\n",
        "        \"high\": env.unbatched_action_spec[env.action_key].space.high,\n",
        "    },\n",
        "    return_log_prob=True,\n",
        "    log_prob_key=(\"agents\", \"sample_log_prob\"),\n",
        ")  # we'll need the log-prob for the PPO loss\n",
        "\n",
        "\n",
        "###CriticNet\n",
        "\n",
        "\n",
        "\n",
        "critic_net = torch.nn.Sequential(\n",
        "     MultiAgentMLP(\n",
        "         n_agent_inputs=env.observation_spec[\"agents\", \"observation\"].shape[-1],\n",
        "         n_agent_outputs=1,\n",
        "         n_agents=env.n_agents,\n",
        "         centralized= False ,\n",
        "         share_params=False,\n",
        "         device= device,\n",
        "         depth=3 ,\n",
        "         num_cells=[64,128,256],\n",
        "         activation_class= torch.nn.Tanh, ), )\n",
        "\n",
        "\n",
        "\n",
        "critic = TensorDictModule(\n",
        "    module=critic_net,\n",
        "    in_keys=[(\"agents\", \"observation\")],\n",
        "    out_keys=[(\"agents\", \"state_value\")],\n",
        ")\n",
        "critic_net.to(device)\n",
        "policy.to(device)\n",
        "\n",
        "# Add print statements to check shapes before collector initialization\n",
        "\n",
        "\n",
        "collector = SyncDataCollector(\n",
        "    env,\n",
        "    policy,\n",
        "    device=device,\n",
        "    storing_device=device,\n",
        "    frames_per_batch=frames_per_batch,\n",
        "    total_frames=total_frames,\n",
        ")\n",
        "print(\"Running policy:\", policy(env.reset()))\n",
        "print(\"Running value:\", critic(env.reset()))\n",
        "\n"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "nPfwJ7x2jyyU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "605015e3-a36c-4b04-a41d-e42db5ac8ed3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running policy: TensorDict(\n",
            "    fields={\n",
            "        agents: TensorDict(\n",
            "            fields={\n",
            "                action: Tensor(shape=torch.Size([10, 2, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
            "                episode_reward: Tensor(shape=torch.Size([10, 2, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
            "                loc: Tensor(shape=torch.Size([10, 2, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
            "                observation: Tensor(shape=torch.Size([10, 2, 5]), device=cpu, dtype=torch.float32, is_shared=False),\n",
            "                sample_log_prob: Tensor(shape=torch.Size([10, 2]), device=cpu, dtype=torch.float32, is_shared=False),\n",
            "                scale: Tensor(shape=torch.Size([10, 2, 1]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
            "            batch_size=torch.Size([10]),\n",
            "            device=cpu,\n",
            "            is_shared=False),\n",
            "        done: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
            "        info: TensorDict(\n",
            "            fields={\n",
            "            },\n",
            "            batch_size=torch.Size([10]),\n",
            "            device=cpu,\n",
            "            is_shared=False),\n",
            "        step_count: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.int64, is_shared=False),\n",
            "        terminated: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
            "    batch_size=torch.Size([10]),\n",
            "    device=cpu,\n",
            "    is_shared=False)\n",
            "Running value: TensorDict(\n",
            "    fields={\n",
            "        agents: TensorDict(\n",
            "            fields={\n",
            "                episode_reward: Tensor(shape=torch.Size([10, 2, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
            "                observation: Tensor(shape=torch.Size([10, 2, 5]), device=cpu, dtype=torch.float32, is_shared=False),\n",
            "                state_value: Tensor(shape=torch.Size([10, 2, 1]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
            "            batch_size=torch.Size([10]),\n",
            "            device=cpu,\n",
            "            is_shared=False),\n",
            "        done: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
            "        info: TensorDict(\n",
            "            fields={\n",
            "            },\n",
            "            batch_size=torch.Size([10]),\n",
            "            device=cpu,\n",
            "            is_shared=False),\n",
            "        step_count: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.int64, is_shared=False),\n",
            "        terminated: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
            "    batch_size=torch.Size([10]),\n",
            "    device=cpu,\n",
            "    is_shared=False)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Replay buffer"
      ],
      "metadata": {
        "id": "OQ6wyA5YXADt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "replay_buffer = ReplayBuffer(\n",
        "    storage=LazyTensorStorage(\n",
        "        frames_per_batch, device=device\n",
        "    ),  # We store the frames_per_batch collected at each iteration\n",
        "    sampler=SamplerWithoutReplacement(),\n",
        "    batch_size=minibatch_size,  # We will sample minibatches of this size\n",
        ")\n"
      ],
      "metadata": {
        "id": "WQ_mLVQDW_KH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loss function"
      ],
      "metadata": {
        "id": "nbEG9jBEW2Nr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_module = ClipPPOLoss(\n",
        "    actor_network=policy,\n",
        "    critic_network=critic,\n",
        "    clip_epsilon=clip_epsilon,\n",
        "    entropy_coef=entropy_eps,\n",
        "    normalize_advantage=False,  # Important to avoid normalizing across the agent dimension\n",
        ")\n",
        "loss_module.set_keys(  # We have to tell the loss where to find the keys\n",
        "    reward=env.reward_key,\n",
        "    action=env.action_key,\n",
        "    sample_log_prob=(\"agents\", \"sample_log_prob\"),\n",
        "    value=(\"agents\", \"state_value\"),\n",
        "    # These last 2 keys will be expanded to match the reward shape\n",
        "    done=(\"agents\", \"done\"),\n",
        "    terminated=(\"agents\", \"terminated\"),\n",
        ")\n",
        "\n",
        "\n",
        "loss_module.make_value_estimator(\n",
        "    ValueEstimators.GAE, gamma=gamma, lmbda=lmbda\n",
        ")  # We build GAE\n",
        "GAE = loss_module.value_estimator\n",
        "\n",
        "optim = torch.optim.Adam(loss_module.parameters(), lr)"
      ],
      "metadata": {
        "id": "Iw63QVQ-W0sD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "owVNY3DPRmUz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch\n",
        "!pip install tensordict\n",
        "!pip install optuna\n",
        "!pip install tqdm\n",
        "\n",
        "import optuna\n",
        "from tqdm import tqdm\n",
        "from collections import defaultdict\n",
        "import torch\n",
        "from optuna import trial\n",
        "\n",
        "\n",
        "def objective(trial):\n",
        "    # Suggest hyperparameters\n",
        "    learning_rate = trial.suggest_loguniform('learning_rate',1e-8 , 1)\n",
        "    batch_size = trial.suggest_int('batch_size',10 ,100)\n",
        "    num_epochs = trial.suggest_int('num_epochs',5, 50)\n",
        "    # Model training and evaluation logic here\n",
        "    logs = defaultdict(list)\n",
        "pbar = tqdm(total=n_iters, desc=\"episode_reward_mean = 0\")\n",
        "episode_reward_mean_list = []\n",
        "for tensordict_data in collector:\n",
        "    tensordict_data.set(\n",
        "        (\"next\", \"agents\", \"done\"),\n",
        "        tensordict_data.get((\"next\", \"done\"))\n",
        "        .unsqueeze(-1)\n",
        "        .expand(tensordict_data.get_item_shape((\"next\", env.reward_key))),\n",
        "    )\n",
        "    tensordict_data.set(\n",
        "        (\"next\", \"agents\", \"terminated\"),\n",
        "        tensordict_data.get((\"next\", \"terminated\"))\n",
        "        .unsqueeze(-1)\n",
        "        .expand(tensordict_data.get_item_shape((\"next\", env.reward_key))),\n",
        "    )\n",
        "    # We need to expand the done and terminated to match the reward shape (this is expected by the value estimator)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        GAE(\n",
        "            tensordict_data,\n",
        "            params=loss_module.critic_network_params,\n",
        "            target_params=loss_module.target_critic_network_params,\n",
        "        )  # Compute GAE and add it to the data\n",
        "\n",
        "    data_view = tensordict_data.reshape(-1)  # Flatten the batch size to shuffle data\n",
        "    replay_buffer.extend(data_view)\n",
        "\n",
        "    for _ in range(num_epochs):\n",
        "        for _ in range(frames_per_batch // minibatch_size):\n",
        "            subdata = replay_buffer.sample()\n",
        "            loss_vals = loss_module(subdata)\n",
        "\n",
        "            loss_value = (\n",
        "                loss_vals[\"loss_objective\"]\n",
        "                + loss_vals[\"loss_critic\"]\n",
        "                + loss_vals[\"loss_entropy\"]\n",
        "            )\n",
        "\n",
        "            loss_value.backward()\n",
        "\n",
        "            torch.nn.utils.clip_grad_norm_(\n",
        "                loss_module.parameters(), max_grad_norm\n",
        "            )  # Optional\n",
        "\n",
        "            optim.step()\n",
        "            optim.zero_grad()\n",
        "\n",
        "    collector.update_policy_weights_()\n",
        "\n",
        "    # Logging\n",
        "    done = tensordict_data.get((\"next\", \"agents\", \"done\"))\n",
        "    episode_reward_mean = (\n",
        "        tensordict_data.get((\"next\", \"agents\", \"episode_reward\"))[done].mean().item()\n",
        "    )\n",
        "    episode_reward_mean_list.append(episode_reward_mean)\n",
        "    pbar.set_description(f\"episode_reward_mean = {episode_reward_mean}\", refresh=False)\n",
        "    pbar.update()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "study = optuna.create_study()\n",
        "study.optimize(objective, n_trials=100)\n",
        "\n",
        "\n",
        "save_study = optuna.create_study(study_name=\"example-study1\", storage=\"https://github.com/rsarpongstreetor/rlroughwork.git\")\n",
        "save_study.add_trials(study.trials)\n",
        "# reload study and optimize\n",
        "study = optuna.load_study(study_name=\"example-study1\", storage=\"https://github.com/rsarpongstreetor/rlroughwork.git\")\n",
        "study.optimize(objective, n_trials=30)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "e-H2Z4Gs5PjJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed8dd824-6c73-4ac3-fe30-648748e074cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: tensordict in /usr/local/lib/python3.10/dist-packages (0.5.0)\n",
            "Requirement already satisfied: torch>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from tensordict) (2.4.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tensordict) (1.26.4)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from tensordict) (2.2.1)\n",
            "Requirement already satisfied: orjson in /usr/local/lib/python3.10/dist-packages (from tensordict) (3.10.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->tensordict) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->tensordict) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->tensordict) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->tensordict) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->tensordict) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->tensordict) (2024.6.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.4.0->tensordict) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.4.0->tensordict) (1.3.0)\n",
            "Requirement already satisfied: optuna in /usr/local/lib/python3.10/dist-packages (4.0.0)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (1.13.2)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.10/dist-packages (from optuna) (6.8.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (24.1)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.35)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.66.5)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.2)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (1.3.5)\n",
            "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna) (3.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.1.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "episode_reward_mean = nan:  80%|  | 4/5 [01:38<00:24, 24.55s/it][I 2024-09-22 14:58:01,876] A new study created in memory with name: no-name-e39b18c2-febb-47f5-a324-c73f88977afe\n",
            "<ipython-input-92-15b62bb517c7>:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate',1e-8 , 1)\n",
            "[W 2024-09-22 14:58:01,882] Trial 0 failed with parameters: {'learning_rate': 4.984734296490636e-06, 'batch_size': 86, 'num_epochs': 37} because of the following error: The value None could not be cast to float..\n",
            "[W 2024-09-22 14:58:01,883] Trial 0 failed with value None.\n",
            "[W 2024-09-22 14:58:01,890] Trial 1 failed with parameters: {'learning_rate': 0.03252997481863884, 'batch_size': 52, 'num_epochs': 48} because of the following error: The value None could not be cast to float..\n",
            "[W 2024-09-22 14:58:01,891] Trial 1 failed with value None.\n",
            "[W 2024-09-22 14:58:01,894] Trial 2 failed with parameters: {'learning_rate': 0.00013732921544863322, 'batch_size': 62, 'num_epochs': 40} because of the following error: The value None could not be cast to float..\n",
            "[W 2024-09-22 14:58:01,895] Trial 2 failed with value None.\n",
            "[W 2024-09-22 14:58:01,898] Trial 3 failed with parameters: {'learning_rate': 0.001306226929366293, 'batch_size': 25, 'num_epochs': 40} because of the following error: The value None could not be cast to float..\n",
            "[W 2024-09-22 14:58:01,900] Trial 3 failed with value None.\n",
            "[W 2024-09-22 14:58:01,902] Trial 4 failed with parameters: {'learning_rate': 0.0009605634813623226, 'batch_size': 77, 'num_epochs': 8} because of the following error: The value None could not be cast to float..\n",
            "[W 2024-09-22 14:58:01,904] Trial 4 failed with value None.\n",
            "[W 2024-09-22 14:58:01,909] Trial 5 failed with parameters: {'learning_rate': 0.004571661678977917, 'batch_size': 93, 'num_epochs': 8} because of the following error: The value None could not be cast to float..\n",
            "[W 2024-09-22 14:58:01,910] Trial 5 failed with value None.\n",
            "[W 2024-09-22 14:58:01,912] Trial 6 failed with parameters: {'learning_rate': 0.14220895081791263, 'batch_size': 11, 'num_epochs': 16} because of the following error: The value None could not be cast to float..\n",
            "[W 2024-09-22 14:58:01,916] Trial 6 failed with value None.\n",
            "[W 2024-09-22 14:58:01,919] Trial 7 failed with parameters: {'learning_rate': 2.5598317913360003e-05, 'batch_size': 14, 'num_epochs': 39} because of the following error: The value None could not be cast to float..\n",
            "[W 2024-09-22 14:58:01,920] Trial 7 failed with value None.\n",
            "[W 2024-09-22 14:58:01,922] Trial 8 failed with parameters: {'learning_rate': 1.5510992145492006e-07, 'batch_size': 76, 'num_epochs': 27} because of the following error: The value None could not be cast to float..\n",
            "[W 2024-09-22 14:58:01,926] Trial 8 failed with value None.\n",
            "[W 2024-09-22 14:58:01,928] Trial 9 failed with parameters: {'learning_rate': 0.04071013133912666, 'batch_size': 79, 'num_epochs': 17} because of the following error: The value None could not be cast to float..\n",
            "[W 2024-09-22 14:58:01,930] Trial 9 failed with value None.\n",
            "[W 2024-09-22 14:58:01,932] Trial 10 failed with parameters: {'learning_rate': 4.097148202401132e-06, 'batch_size': 31, 'num_epochs': 16} because of the following error: The value None could not be cast to float..\n",
            "[W 2024-09-22 14:58:01,936] Trial 10 failed with value None.\n",
            "[W 2024-09-22 14:58:01,938] Trial 11 failed with parameters: {'learning_rate': 3.6107776954147055e-06, 'batch_size': 47, 'num_epochs': 22} because of the following error: The value None could not be cast to float..\n",
            "[W 2024-09-22 14:58:01,939] Trial 11 failed with value None.\n",
            "[W 2024-09-22 14:58:01,941] Trial 12 failed with parameters: {'learning_rate': 0.03382648559278883, 'batch_size': 91, 'num_epochs': 30} because of the following error: The value None could not be cast to float..\n",
            "[W 2024-09-22 14:58:01,945] Trial 12 failed with value None.\n",
            "[W 2024-09-22 14:58:01,947] Trial 13 failed with parameters: {'learning_rate': 0.3400010152722843, 'batch_size': 73, 'num_epochs': 19} because of the following error: The value None could not be cast to float..\n",
            "[W 2024-09-22 14:58:01,949] Trial 13 failed with value None.\n",
            "[W 2024-09-22 14:58:01,951] Trial 14 failed with parameters: {'learning_rate': 3.261509826200337e-07, 'batch_size': 67, 'num_epochs': 18} because of the following error: The value None could not be cast to float..\n",
            "[W 2024-09-22 14:58:01,952] Trial 14 failed with value None.\n",
            "[W 2024-09-22 14:58:01,955] Trial 15 failed with parameters: {'learning_rate': 0.10817191707576983, 'batch_size': 75, 'num_epochs': 8} because of the following error: The value None could not be cast to float..\n",
            "[W 2024-09-22 14:58:01,957] Trial 15 failed with value None.\n",
            "[W 2024-09-22 14:58:01,959] Trial 16 failed with parameters: {'learning_rate': 3.001316309863732e-07, 'batch_size': 32, 'num_epochs': 26} because of the following error: The value None could not be cast to float..\n",
            "[W 2024-09-22 14:58:01,960] Trial 16 failed with value None.\n",
            "[W 2024-09-22 14:58:01,963] Trial 17 failed with parameters: {'learning_rate': 2.4365038586059e-07, 'batch_size': 13, 'num_epochs': 23} because of the following error: The value None could not be cast to float..\n",
            "[W 2024-09-22 14:58:01,965] Trial 17 failed with value None.\n",
            "[W 2024-09-22 14:58:01,967] Trial 18 failed with parameters: {'learning_rate': 1.4422990760175613e-06, 'batch_size': 53, 'num_epochs': 13} because of the following error: The value None could not be cast to float..\n",
            "[W 2024-09-22 14:58:01,968] Trial 18 failed with value None.\n",
            "[W 2024-09-22 14:58:01,971] Trial 19 failed with parameters: {'learning_rate': 0.004202253328946955, 'batch_size': 67, 'num_epochs': 8} because of the following error: The value None could not be cast to float..\n",
            "[W 2024-09-22 14:58:01,972] Trial 19 failed with value None.\n",
            "[W 2024-09-22 14:58:01,975] Trial 20 failed with parameters: {'learning_rate': 1.6440611938682746e-08, 'batch_size': 62, 'num_epochs': 36} because of the following error: The value None could not be cast to float..\n",
            "[W 2024-09-22 14:58:01,976] Trial 20 failed with value None.\n",
            "[W 2024-09-22 14:58:01,979] Trial 21 failed with parameters: {'learning_rate': 0.7202709472658357, 'batch_size': 32, 'num_epochs': 35} because of the following error: The value None could not be cast to float..\n",
            "[W 2024-09-22 14:58:01,980] Trial 21 failed with value None.\n",
            "[W 2024-09-22 14:58:01,982] Trial 22 failed with parameters: {'learning_rate': 0.14719538426545054, 'batch_size': 26, 'num_epochs': 40} because of the following error: The value None could not be cast to float..\n",
            "[W 2024-09-22 14:58:01,983] Trial 22 failed with value None.\n",
            "[W 2024-09-22 14:58:01,985] Trial 23 failed with parameters: {'learning_rate': 0.0003557169353211946, 'batch_size': 12, 'num_epochs': 26} because of the following error: The value None could not be cast to float..\n",
            "[W 2024-09-22 14:58:01,987] Trial 23 failed with value None.\n",
            "[W 2024-09-22 14:58:01,989] Trial 24 failed with parameters: {'learning_rate': 0.01804324555991751, 'batch_size': 31, 'num_epochs': 36} because of the following error: The value None could not be cast to float..\n",
            "[W 2024-09-22 14:58:01,990] Trial 24 failed with value None.\n",
            "[W 2024-09-22 14:58:01,993] Trial 25 failed with parameters: {'learning_rate': 0.003881093241035529, 'batch_size': 79, 'num_epochs': 25} because of the following error: The value None could not be cast to float..\n",
            "[W 2024-09-22 14:58:01,994] Trial 25 failed with value None.\n",
            "[W 2024-09-22 14:58:01,996] Trial 26 failed with parameters: {'learning_rate': 2.2117825848182144e-07, 'batch_size': 22, 'num_epochs': 49} because of the following error: The value None could not be cast to float..\n",
            "[W 2024-09-22 14:58:02,001] Trial 26 failed with value None.\n",
            "[W 2024-09-22 14:58:02,004] Trial 27 failed with parameters: {'learning_rate': 0.08239541748004511, 'batch_size': 67, 'num_epochs': 37} because of the following error: The value None could not be cast to float..\n",
            "[W 2024-09-22 14:58:02,005] Trial 27 failed with value None.\n",
            "[W 2024-09-22 14:58:02,008] Trial 28 failed with parameters: {'learning_rate': 2.5682153650338364e-07, 'batch_size': 12, 'num_epochs': 13} because of the following error: The value None could not be cast to float..\n",
            "[W 2024-09-22 14:58:02,010] Trial 28 failed with value None.\n",
            "[W 2024-09-22 14:58:02,012] Trial 29 failed with parameters: {'learning_rate': 0.0001714134232334255, 'batch_size': 45, 'num_epochs': 35} because of the following error: The value None could not be cast to float..\n",
            "[W 2024-09-22 14:58:02,014] Trial 29 failed with value None.\n",
            "[W 2024-09-22 14:58:02,016] Trial 30 failed with parameters: {'learning_rate': 0.7617797145698513, 'batch_size': 37, 'num_epochs': 23} because of the following error: The value None could not be cast to float..\n",
            "[W 2024-09-22 14:58:02,018] Trial 30 failed with value None.\n",
            "[W 2024-09-22 14:58:02,020] Trial 31 failed with parameters: {'learning_rate': 9.221635327673781e-08, 'batch_size': 91, 'num_epochs': 9} because of the following error: The value None could not be cast to float..\n",
            "[W 2024-09-22 14:58:02,021] Trial 31 failed with value None.\n",
            "[W 2024-09-22 14:58:02,024] Trial 32 failed with parameters: {'learning_rate': 8.32123703554008e-08, 'batch_size': 37, 'num_epochs': 31} because of the following error: The value None could not be cast to float..\n",
            "[W 2024-09-22 14:58:02,025] Trial 32 failed with value None.\n",
            "[W 2024-09-22 14:58:02,028] Trial 33 failed with parameters: {'learning_rate': 0.0049771133561231865, 'batch_size': 96, 'num_epochs': 35} because of the following error: The value None could not be cast to float..\n",
            "[W 2024-09-22 14:58:02,029] Trial 33 failed with value None.\n",
            "[W 2024-09-22 14:58:02,034] Trial 34 failed with parameters: {'learning_rate': 1.5098620161796738e-07, 'batch_size': 90, 'num_epochs': 33} because of the following error: The value None could not be cast to float..\n",
            "[W 2024-09-22 14:58:02,038] Trial 34 failed with value None.\n",
            "[W 2024-09-22 14:58:02,040] Trial 35 failed with parameters: {'learning_rate': 1.0217839627932726e-08, 'batch_size': 44, 'num_epochs': 44} because of the following error: The value None could not be cast to float..\n",
            "[W 2024-09-22 14:58:02,042] Trial 35 failed with value None.\n",
            "[W 2024-09-22 14:58:02,046] Trial 36 failed with parameters: {'learning_rate': 2.8262395058068197e-08, 'batch_size': 48, 'num_epochs': 49} because of the following error: The value None could not be cast to float..\n",
            "[W 2024-09-22 14:58:02,047] Trial 36 failed with value None.\n",
            "[W 2024-09-22 14:58:02,049] Trial 37 failed with parameters: {'learning_rate': 8.171521672822398e-05, 'batch_size': 76, 'num_epochs': 41} because of the following error: The value None could not be cast to float..\n",
            "[W 2024-09-22 14:58:02,051] Trial 37 failed with value None.\n",
            "[W 2024-09-22 14:58:02,054] Trial 38 failed with parameters: {'learning_rate': 5.687157552751403e-08, 'batch_size': 86, 'num_epochs': 5} because of the following error: The value None could not be cast to float..\n",
            "[W 2024-09-22 14:58:02,055] Trial 38 failed with value None.\n",
            "[W 2024-09-22 14:58:02,057] Trial 39 failed with parameters: {'learning_rate': 2.2798094688307266e-07, 'batch_size': 29, 'num_epochs': 42} because of the following error: The value None could not be cast to float..\n",
            "[W 2024-09-22 14:58:02,058] Trial 39 failed with value None.\n",
            "[W 2024-09-22 14:58:02,063] Trial 40 failed with parameters: {'learning_rate': 8.733444914608255e-08, 'batch_size': 66, 'num_epochs': 27} because of the following error: The value None could not be cast to float..\n",
            "[W 2024-09-22 14:58:02,064] Trial 40 failed with value None.\n",
            "[W 2024-09-22 14:58:02,066] Trial 41 failed with parameters: {'learning_rate': 0.9987467307310668, 'batch_size': 55, 'num_epochs': 28} because of the following error: The value None could not be cast to float..\n",
            "[W 2024-09-22 14:58:02,067] Trial 41 failed with value None.\n",
            "[W 2024-09-22 14:58:02,071] Trial 42 failed with parameters: {'learning_rate': 0.015026580735938, 'batch_size': 94, 'num_epochs': 28} because of the following error: The value None could not be cast to float..\n",
            "[W 2024-09-22 14:58:02,072] Trial 42 failed with value None.\n",
            "[W 2024-09-22 14:58:02,077] Trial 43 failed with parameters: {'learning_rate': 7.044860531018219e-08, 'batch_size': 17, 'num_epochs': 37} because of the following error: The value None could not be cast to float..\n",
            "[W 2024-09-22 14:58:02,078] Trial 43 failed with value None.\n",
            "[W 2024-09-22 14:58:02,080] Trial 44 failed with parameters: {'learning_rate': 1.67428914909528e-06, 'batch_size': 57, 'num_epochs': 32} because of the following error: The value None could not be cast to float..\n",
            "[W 2024-09-22 14:58:02,081] Trial 44 failed with value None.\n",
            "[W 2024-09-22 14:58:02,083] Trial 45 failed with parameters: {'learning_rate': 0.009465434708963988, 'batch_size': 51, 'num_epochs': 14} because of the following error: The value None could not be cast to float..\n",
            "[W 2024-09-22 14:58:02,084] Trial 45 failed with value None.\n",
            "[W 2024-09-22 14:58:02,090] Trial 46 failed with parameters: {'learning_rate': 0.33773123060871657, 'batch_size': 76, 'num_epochs': 30} because of the following error: The value None could not be cast to float..\n",
            "[W 2024-09-22 14:58:02,091] Trial 46 failed with value None.\n",
            "[W 2024-09-22 14:58:02,094] Trial 47 failed with parameters: {'learning_rate': 1.9724287234818523e-07, 'batch_size': 16, 'num_epochs': 14} because of the following error: The value None could not be cast to float..\n",
            "[W 2024-09-22 14:58:02,095] Trial 47 failed with value None.\n",
            "[W 2024-09-22 14:58:02,097] Trial 48 failed with parameters: {'learning_rate': 3.359847600201376e-05, 'batch_size': 53, 'num_epochs': 39} because of the following error: The value None could not be cast to float..\n",
            "[W 2024-09-22 14:58:02,100] Trial 48 failed with value None.\n",
            "[W 2024-09-22 14:58:02,103] Trial 49 failed with parameters: {'learning_rate': 8.645975387737914e-06, 'batch_size': 37, 'num_epochs': 26} because of the following error: The value None could not be cast to float..\n",
            "[W 2024-09-22 14:58:02,104] Trial 49 failed with value None.\n",
            "[W 2024-09-22 14:58:02,106] Trial 50 failed with parameters: {'learning_rate': 0.000160693125982892, 'batch_size': 88, 'num_epochs': 16} because of the following error: The value None could not be cast to float..\n",
            "[W 2024-09-22 14:58:02,107] Trial 50 failed with value None.\n",
            "[W 2024-09-22 14:58:02,112] Trial 51 failed with parameters: {'learning_rate': 1.354021139711831e-07, 'batch_size': 55, 'num_epochs': 36} because of the following error: The value None could not be cast to float..\n",
            "[W 2024-09-22 14:58:02,113] Trial 51 failed with value None.\n",
            "[W 2024-09-22 14:58:02,115] Trial 52 failed with parameters: {'learning_rate': 0.00011282837355583578, 'batch_size': 14, 'num_epochs': 7} because of the following error: The value None could not be cast to float..\n",
            "[W 2024-09-22 14:58:02,118] Trial 52 failed with value None.\n",
            "[W 2024-09-22 14:58:02,120] Trial 53 failed with parameters: {'learning_rate': 1.725596138012708e-05, 'batch_size': 30, 'num_epochs': 45} because of the following error: The value None could not be cast to float..\n",
            "[W 2024-09-22 14:58:02,121] Trial 53 failed with value None.\n",
            "[W 2024-09-22 14:58:02,123] Trial 54 failed with parameters: {'learning_rate': 0.00070737413236283, 'batch_size': 64, 'num_epochs': 11} because of the following error: The value None could not be cast to float..\n",
            "[W 2024-09-22 14:58:02,128] Trial 54 failed with value None.\n",
            "[W 2024-09-22 14:58:02,130] Trial 55 failed with parameters: {'learning_rate': 0.00010107563964921951, 'batch_size': 58, 'num_epochs': 34} because of the following error: The value None could not be cast to float..\n",
            "[W 2024-09-22 14:58:02,132] Trial 55 failed with value None.\n",
            "[W 2024-09-22 14:58:02,134] Trial 56 failed with parameters: {'learning_rate': 1.4710019204436242e-07, 'batch_size': 17, 'num_epochs': 7} because of the following error: The value None could not be cast to float..\n",
            "[W 2024-09-22 14:58:02,136] Trial 56 failed with value None.\n",
            "[W 2024-09-22 14:58:02,138] Trial 57 failed with parameters: {'learning_rate': 0.021228697113627806, 'batch_size': 12, 'num_epochs': 18} because of the following error: The value None could not be cast to float..\n",
            "[W 2024-09-22 14:58:02,139] Trial 57 failed with value None.\n",
            "[W 2024-09-22 14:58:02,142] Trial 58 failed with parameters: {'learning_rate': 0.03811129851069864, 'batch_size': 43, 'num_epochs': 39} because of the following error: The value None could not be cast to float..\n",
            "[W 2024-09-22 14:58:02,143] Trial 58 failed with value None.\n",
            "[W 2024-09-22 14:58:02,146] Trial 59 failed with parameters: {'learning_rate': 8.463579189217662e-05, 'batch_size': 81, 'num_epochs': 50} because of the following error: The value None could not be cast to float..\n",
            "[W 2024-09-22 14:58:02,147] Trial 59 failed with value None.\n",
            "[W 2024-09-22 14:58:02,149] Trial 60 failed with parameters: {'learning_rate': 1.2846430441866522e-06, 'batch_size': 78, 'num_epochs': 8} because of the following error: The value None could not be cast to float..\n",
            "[W 2024-09-22 14:58:02,150] Trial 60 failed with value None.\n",
            "[W 2024-09-22 14:58:02,153] Trial 61 failed with parameters: {'learning_rate': 2.384377080823881e-08, 'batch_size': 55, 'num_epochs': 24} because of the following error: The value None could not be cast to float..\n",
            "[W 2024-09-22 14:58:02,155] Trial 61 failed with value None.\n",
            "[W 2024-09-22 14:58:02,157] Trial 62 failed with parameters: {'learning_rate': 6.828022827808029e-08, 'batch_size': 11, 'num_epochs': 37} because of the following error: The value None could not be cast to float..\n",
            "[W 2024-09-22 14:58:02,158] Trial 62 failed with value None.\n",
            "[W 2024-09-22 14:58:02,161] Trial 63 failed with parameters: {'learning_rate': 0.009881213411991637, 'batch_size': 35, 'num_epochs': 44} because of the following error: The value None could not be cast to float..\n",
            "[W 2024-09-22 14:58:02,162] Trial 63 failed with value None.\n",
            "[W 2024-09-22 14:58:02,164] Trial 64 failed with parameters: {'learning_rate': 1.341208676540676e-06, 'batch_size': 90, 'num_epochs': 28} because of the following error: The value None could not be cast to float..\n",
            "[W 2024-09-22 14:58:02,166] Trial 64 failed with value None.\n",
            "[W 2024-09-22 14:58:02,169] Trial 65 failed with parameters: {'learning_rate': 0.05349683279090219, 'batch_size': 66, 'num_epochs': 28} because of the following error: The value None could not be cast to float..\n",
            "[W 2024-09-22 14:58:02,171] Trial 65 failed with value None.\n",
            "[W 2024-09-22 14:58:02,173] Trial 66 failed with parameters: {'learning_rate': 0.00023930894909848275, 'batch_size': 30, 'num_epochs': 45} because of the following error: The value None could not be cast to float..\n",
            "[W 2024-09-22 14:58:02,174] Trial 66 failed with value None.\n",
            "[W 2024-09-22 14:58:02,177] Trial 67 failed with parameters: {'learning_rate': 3.711631095754889e-07, 'batch_size': 96, 'num_epochs': 33} because of the following error: The value None could not be cast to float..\n",
            "[W 2024-09-22 14:58:02,179] Trial 67 failed with value None.\n",
            "[W 2024-09-22 14:58:02,181] Trial 68 failed with parameters: {'learning_rate': 3.844053944503034e-08, 'batch_size': 73, 'num_epochs': 17} because of the following error: The value None could not be cast to float..\n",
            "[W 2024-09-22 14:58:02,182] Trial 68 failed with value None.\n",
            "[W 2024-09-22 14:58:02,188] Trial 69 failed with parameters: {'learning_rate': 0.5477414860745733, 'batch_size': 71, 'num_epochs': 43} because of the following error: The value None could not be cast to float..\n",
            "[W 2024-09-22 14:58:02,189] Trial 69 failed with value None.\n",
            "[W 2024-09-22 14:58:02,192] Trial 70 failed with parameters: {'learning_rate': 0.012780690345346065, 'batch_size': 17, 'num_epochs': 19} because of the following error: The value None could not be cast to float..\n",
            "[W 2024-09-22 14:58:02,194] Trial 70 failed with value None.\n",
            "[W 2024-09-22 14:58:02,196] Trial 71 failed with parameters: {'learning_rate': 0.0007469924327448851, 'batch_size': 34, 'num_epochs': 46} because of the following error: The value None could not be cast to float..\n",
            "[W 2024-09-22 14:58:02,198] Trial 71 failed with value None.\n",
            "[W 2024-09-22 14:58:02,200] Trial 72 failed with parameters: {'learning_rate': 7.864184869264803e-05, 'batch_size': 20, 'num_epochs': 15} because of the following error: The value None could not be cast to float..\n",
            "[W 2024-09-22 14:58:02,201] Trial 72 failed with value None.\n",
            "[W 2024-09-22 14:58:02,204] Trial 73 failed with parameters: {'learning_rate': 3.503765691435548e-08, 'batch_size': 11, 'num_epochs': 12} because of the following error: The value None could not be cast to float..\n",
            "[W 2024-09-22 14:58:02,206] Trial 73 failed with value None.\n",
            "[W 2024-09-22 14:58:02,208] Trial 74 failed with parameters: {'learning_rate': 0.1194013969139942, 'batch_size': 82, 'num_epochs': 8} because of the following error: The value None could not be cast to float..\n",
            "[W 2024-09-22 14:58:02,209] Trial 74 failed with value None.\n",
            "[W 2024-09-22 14:58:02,213] Trial 75 failed with parameters: {'learning_rate': 5.852386469143686e-07, 'batch_size': 23, 'num_epochs': 18} because of the following error: The value None could not be cast to float..\n",
            "[W 2024-09-22 14:58:02,214] Trial 75 failed with value None.\n",
            "[W 2024-09-22 14:58:02,217] Trial 76 failed with parameters: {'learning_rate': 3.698553681727393e-08, 'batch_size': 98, 'num_epochs': 42} because of the following error: The value None could not be cast to float..\n",
            "[W 2024-09-22 14:58:02,218] Trial 76 failed with value None.\n",
            "[W 2024-09-22 14:58:02,221] Trial 77 failed with parameters: {'learning_rate': 0.9623926069071961, 'batch_size': 73, 'num_epochs': 5} because of the following error: The value None could not be cast to float..\n",
            "[W 2024-09-22 14:58:02,222] Trial 77 failed with value None.\n",
            "[W 2024-09-22 14:58:02,226] Trial 78 failed with parameters: {'learning_rate': 1.10477766889994e-07, 'batch_size': 25, 'num_epochs': 12} because of the following error: The value None could not be cast to float..\n",
            "[W 2024-09-22 14:58:02,228] Trial 78 failed with value None.\n",
            "[W 2024-09-22 14:58:02,230] Trial 79 failed with parameters: {'learning_rate': 0.0004295792503509782, 'batch_size': 26, 'num_epochs': 26} because of the following error: The value None could not be cast to float..\n",
            "[W 2024-09-22 14:58:02,234] Trial 79 failed with value None.\n",
            "[W 2024-09-22 14:58:02,236] Trial 80 failed with parameters: {'learning_rate': 0.0008580049953540027, 'batch_size': 84, 'num_epochs': 44} because of the following error: The value None could not be cast to float..\n",
            "[W 2024-09-22 14:58:02,237] Trial 80 failed with value None.\n",
            "[W 2024-09-22 14:58:02,240] Trial 81 failed with parameters: {'learning_rate': 0.004329152220185085, 'batch_size': 16, 'num_epochs': 16} because of the following error: The value None could not be cast to float..\n",
            "[W 2024-09-22 14:58:02,241] Trial 81 failed with value None.\n",
            "[W 2024-09-22 14:58:02,244] Trial 82 failed with parameters: {'learning_rate': 8.28553335789959e-05, 'batch_size': 17, 'num_epochs': 14} because of the following error: The value None could not be cast to float..\n",
            "[W 2024-09-22 14:58:02,245] Trial 82 failed with value None.\n",
            "[W 2024-09-22 14:58:02,248] Trial 83 failed with parameters: {'learning_rate': 0.2433239827984362, 'batch_size': 59, 'num_epochs': 27} because of the following error: The value None could not be cast to float..\n",
            "[W 2024-09-22 14:58:02,249] Trial 83 failed with value None.\n",
            "[W 2024-09-22 14:58:02,252] Trial 84 failed with parameters: {'learning_rate': 1.9929418278253052e-07, 'batch_size': 26, 'num_epochs': 11} because of the following error: The value None could not be cast to float..\n",
            "[W 2024-09-22 14:58:02,253] Trial 84 failed with value None.\n",
            "[W 2024-09-22 14:58:02,264] Trial 85 failed with parameters: {'learning_rate': 1.001480016879354e-06, 'batch_size': 36, 'num_epochs': 47} because of the following error: The value None could not be cast to float..\n",
            "[W 2024-09-22 14:58:02,265] Trial 85 failed with value None.\n",
            "[W 2024-09-22 14:58:02,268] Trial 86 failed with parameters: {'learning_rate': 3.0828893568370076e-06, 'batch_size': 92, 'num_epochs': 27} because of the following error: The value None could not be cast to float..\n",
            "[W 2024-09-22 14:58:02,269] Trial 86 failed with value None.\n",
            "[W 2024-09-22 14:58:02,275] Trial 87 failed with parameters: {'learning_rate': 1.7584254076645255e-05, 'batch_size': 33, 'num_epochs': 17} because of the following error: The value None could not be cast to float..\n",
            "[W 2024-09-22 14:58:02,276] Trial 87 failed with value None.\n",
            "[W 2024-09-22 14:58:02,278] Trial 88 failed with parameters: {'learning_rate': 0.31508232234110134, 'batch_size': 55, 'num_epochs': 14} because of the following error: The value None could not be cast to float..\n",
            "[W 2024-09-22 14:58:02,283] Trial 88 failed with value None.\n",
            "[W 2024-09-22 14:58:02,286] Trial 89 failed with parameters: {'learning_rate': 4.485356467403024e-05, 'batch_size': 89, 'num_epochs': 19} because of the following error: The value None could not be cast to float..\n",
            "[W 2024-09-22 14:58:02,290] Trial 89 failed with value None.\n",
            "[W 2024-09-22 14:58:02,293] Trial 90 failed with parameters: {'learning_rate': 5.7658368355902873e-08, 'batch_size': 31, 'num_epochs': 21} because of the following error: The value None could not be cast to float..\n",
            "[W 2024-09-22 14:58:02,296] Trial 90 failed with value None.\n",
            "[W 2024-09-22 14:58:02,301] Trial 91 failed with parameters: {'learning_rate': 0.00011247780675181123, 'batch_size': 45, 'num_epochs': 43} because of the following error: The value None could not be cast to float..\n",
            "[W 2024-09-22 14:58:02,331] Trial 91 failed with value None.\n",
            "[W 2024-09-22 14:58:02,335] Trial 92 failed with parameters: {'learning_rate': 0.02262870880553619, 'batch_size': 44, 'num_epochs': 40} because of the following error: The value None could not be cast to float..\n",
            "[W 2024-09-22 14:58:02,336] Trial 92 failed with value None.\n",
            "[W 2024-09-22 14:58:02,339] Trial 93 failed with parameters: {'learning_rate': 0.3722335186223769, 'batch_size': 66, 'num_epochs': 25} because of the following error: The value None could not be cast to float..\n",
            "[W 2024-09-22 14:58:02,352] Trial 93 failed with value None.\n",
            "[W 2024-09-22 14:58:02,380] Trial 94 failed with parameters: {'learning_rate': 0.0019728401998377007, 'batch_size': 90, 'num_epochs': 20} because of the following error: The value None could not be cast to float..\n",
            "[W 2024-09-22 14:58:02,427] Trial 94 failed with value None.\n",
            "[W 2024-09-22 14:58:02,433] Trial 95 failed with parameters: {'learning_rate': 1.3901909104939989e-08, 'batch_size': 50, 'num_epochs': 13} because of the following error: The value None could not be cast to float..\n",
            "[W 2024-09-22 14:58:02,466] Trial 95 failed with value None.\n",
            "[W 2024-09-22 14:58:02,470] Trial 96 failed with parameters: {'learning_rate': 1.0682613936598076e-06, 'batch_size': 42, 'num_epochs': 46} because of the following error: The value None could not be cast to float..\n",
            "[W 2024-09-22 14:58:02,522] Trial 96 failed with value None.\n",
            "[W 2024-09-22 14:58:02,526] Trial 97 failed with parameters: {'learning_rate': 0.054694491651463076, 'batch_size': 72, 'num_epochs': 18} because of the following error: The value None could not be cast to float..\n",
            "[W 2024-09-22 14:58:02,527] Trial 97 failed with value None.\n",
            "[W 2024-09-22 14:58:02,530] Trial 98 failed with parameters: {'learning_rate': 0.26631412979542113, 'batch_size': 30, 'num_epochs': 5} because of the following error: The value None could not be cast to float..\n",
            "[W 2024-09-22 14:58:02,531] Trial 98 failed with value None.\n",
            "[W 2024-09-22 14:58:02,534] Trial 99 failed with parameters: {'learning_rate': 0.0005542380789219919, 'batch_size': 39, 'num_epochs': 25} because of the following error: The value None could not be cast to float..\n",
            "[W 2024-09-22 14:58:02,536] Trial 99 failed with value None.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Model structure: {critic}\\n\\n\")\n",
        "for name, param in critic.named_parameters():\n",
        "    print(f\"Layer: {name} | Size: {param.size()} | Values : {param[:2]} \\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BLqc2yJKD3MO",
        "outputId": "bbc82532-030a-4263-ff56-04d2eea7d59f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model structure: TensorDictModule(\n",
            "    module=Sequential(\n",
            "      (0): MultiAgentMLP(\n",
            "          MLP(\n",
            "            (0): Linear(in_features=5, out_features=64, bias=True)\n",
            "            (1): Tanh()\n",
            "            (2): Linear(in_features=64, out_features=128, bias=True)\n",
            "            (3): Tanh()\n",
            "            (4): Linear(in_features=128, out_features=256, bias=True)\n",
            "            (5): Tanh()\n",
            "            (6): Linear(in_features=256, out_features=1, bias=True)\n",
            "          ),\n",
            "          n_agents=2,\n",
            "          share_params=False,\n",
            "          centralized=False,\n",
            "          agent_dim=-2)\n",
            "    ),\n",
            "    device=cpu,\n",
            "    in_keys=[('agents', 'observation')],\n",
            "    out_keys=[('agents', 'state_value')])\n",
            "\n",
            "\n",
            "Layer: module.0.params.2.bias | Size: torch.Size([2, 128]) | Values : tensor([[-0.0229,  0.0179,  0.0305,  0.0201, -0.0648, -0.0537, -0.0406, -0.0619,\n",
            "         -0.0062,  0.0330, -0.0623, -0.0581,  0.0639, -0.0766, -0.0867, -0.0328,\n",
            "         -0.0381, -0.0272, -0.0500, -0.0866,  0.0280,  0.0738,  0.0491,  0.1021,\n",
            "         -0.0998, -0.0199,  0.0788,  0.0456,  0.1248, -0.0540,  0.1242,  0.0782,\n",
            "          0.0833,  0.1123, -0.0066,  0.0492, -0.0293, -0.0537, -0.0372, -0.0337,\n",
            "         -0.0287, -0.0325,  0.0958,  0.0895, -0.0171, -0.0754,  0.0062, -0.0269,\n",
            "          0.0218,  0.0369,  0.1077,  0.0835,  0.0936,  0.0159,  0.1247,  0.0309,\n",
            "         -0.0646,  0.0432, -0.0997,  0.1036,  0.0877, -0.0151, -0.0288,  0.0025,\n",
            "          0.0822,  0.0028,  0.0651,  0.0177,  0.0708,  0.0675,  0.0896,  0.0061,\n",
            "          0.0353, -0.0891, -0.0093,  0.0061,  0.0683, -0.0862, -0.0731,  0.1066,\n",
            "         -0.0770, -0.0577, -0.0213, -0.0211,  0.0151, -0.0188,  0.0356,  0.0961,\n",
            "         -0.0682, -0.1074,  0.1123, -0.0122, -0.0181, -0.0907,  0.0797, -0.0688,\n",
            "          0.0893, -0.0406,  0.1190,  0.0222,  0.0937, -0.0007,  0.1068, -0.0746,\n",
            "          0.0396,  0.1096, -0.0812,  0.1009, -0.1091, -0.0543, -0.0342, -0.0482,\n",
            "         -0.0932, -0.0559, -0.0810,  0.0936, -0.0211, -0.0488, -0.0588,  0.0024,\n",
            "         -0.0404,  0.1056, -0.1159,  0.0334, -0.0173,  0.0871,  0.0331,  0.0935],\n",
            "        [-0.0840, -0.0346,  0.0602,  0.0910,  0.0701, -0.0653, -0.1083, -0.0782,\n",
            "          0.0240, -0.0623, -0.0842, -0.1247, -0.0864, -0.0597,  0.0737, -0.0578,\n",
            "         -0.0189,  0.0616, -0.0738, -0.1227,  0.0187, -0.0664,  0.0404,  0.0336,\n",
            "         -0.0474, -0.0014,  0.0455, -0.0172,  0.0487, -0.1193,  0.0475, -0.0602,\n",
            "         -0.1216,  0.0889, -0.0935,  0.0267,  0.0035,  0.1169,  0.0899,  0.0229,\n",
            "         -0.0761,  0.0373,  0.1121,  0.0821, -0.0744,  0.0949, -0.1233, -0.0466,\n",
            "         -0.1034,  0.0040,  0.0311, -0.1238,  0.1235, -0.0978, -0.1172, -0.0421,\n",
            "         -0.0406, -0.0457, -0.1059,  0.1048,  0.0170, -0.0079,  0.0585, -0.0941,\n",
            "         -0.1114, -0.0081,  0.0353, -0.0503, -0.0950, -0.0171, -0.1166,  0.1069,\n",
            "          0.0338, -0.0390,  0.1035,  0.1153, -0.0163,  0.0392,  0.0242, -0.1060,\n",
            "          0.1143,  0.1170, -0.0441, -0.1178,  0.0621,  0.0204, -0.0164,  0.0877,\n",
            "         -0.0522, -0.0784, -0.0051, -0.0574, -0.0606, -0.0503, -0.0793,  0.0884,\n",
            "          0.0972,  0.0305, -0.0842,  0.0802, -0.0218,  0.0338,  0.0734, -0.0467,\n",
            "         -0.0640,  0.0211,  0.0015, -0.0641, -0.0814,  0.0817,  0.0888, -0.0409,\n",
            "          0.1135, -0.1164,  0.0614, -0.0664, -0.0666, -0.0486,  0.1218,  0.0772,\n",
            "          0.0039,  0.0614, -0.0322,  0.0637,  0.0697,  0.0931, -0.0302, -0.1242]],\n",
            "       grad_fn=<SliceBackward0>) \n",
            "\n",
            "Layer: module.0.params.2.weight | Size: torch.Size([2, 128, 64]) | Values : tensor([[[-0.0246, -0.0809,  0.1070,  ...,  0.0788, -0.1188,  0.0407],\n",
            "         [-0.0065,  0.0891, -0.1012,  ..., -0.0479,  0.0370, -0.0630],\n",
            "         [ 0.0405,  0.0323, -0.0403,  ..., -0.0048,  0.0039,  0.1176],\n",
            "         ...,\n",
            "         [-0.0642, -0.0479,  0.0865,  ..., -0.0430, -0.0480,  0.0531],\n",
            "         [ 0.1015,  0.0878,  0.0687,  ...,  0.1109,  0.0824, -0.0523],\n",
            "         [-0.0672,  0.0109, -0.0021,  ..., -0.1102,  0.0766, -0.0983]],\n",
            "\n",
            "        [[ 0.0218,  0.0408,  0.0151,  ..., -0.1246, -0.0799,  0.1144],\n",
            "         [-0.1064,  0.0232,  0.0999,  ..., -0.0075,  0.0997,  0.0504],\n",
            "         [-0.0508, -0.0930, -0.0299,  ..., -0.1149, -0.0351, -0.0926],\n",
            "         ...,\n",
            "         [-0.0917, -0.0483, -0.0119,  ...,  0.0150, -0.0991, -0.0616],\n",
            "         [-0.0782, -0.0750,  0.0280,  ..., -0.0283, -0.1042, -0.0534],\n",
            "         [ 0.0385,  0.0032, -0.0843,  ..., -0.0083,  0.0760, -0.1007]]],\n",
            "       grad_fn=<SliceBackward0>) \n",
            "\n",
            "Layer: module.0.params.0.bias | Size: torch.Size([2, 64]) | Values : tensor([[ 0.4199,  0.0142,  0.1176,  0.4434,  0.3678,  0.2967,  0.4361,  0.2837,\n",
            "         -0.3525,  0.3532,  0.0069, -0.2154,  0.4423, -0.2554,  0.0578,  0.0447,\n",
            "         -0.1075,  0.2173, -0.3883, -0.3042, -0.4180, -0.3942, -0.0971,  0.1836,\n",
            "          0.2944,  0.0289,  0.1596,  0.2627, -0.3398,  0.3825,  0.4269, -0.1103,\n",
            "          0.3512,  0.0809,  0.0764, -0.1900,  0.2313,  0.2565,  0.0872, -0.3230,\n",
            "          0.3702, -0.2799, -0.2308, -0.3464,  0.0523,  0.0252,  0.2803,  0.1306,\n",
            "          0.1732, -0.1786,  0.1511, -0.2390,  0.1291, -0.3186,  0.4266,  0.1493,\n",
            "         -0.3171, -0.2028, -0.4279,  0.4191, -0.3421, -0.3984,  0.1630,  0.0465],\n",
            "        [ 0.1708, -0.4257,  0.0879,  0.0153, -0.0558,  0.2393, -0.0006, -0.3830,\n",
            "          0.2690, -0.1153, -0.3602,  0.3413,  0.2234,  0.2910,  0.2446,  0.1304,\n",
            "          0.4336,  0.1849, -0.3070,  0.2226,  0.0409, -0.2794, -0.1103,  0.1184,\n",
            "         -0.2842, -0.3111,  0.1145, -0.0793, -0.4380, -0.4218, -0.4096,  0.2291,\n",
            "         -0.2321, -0.2878,  0.2783, -0.3135, -0.1245, -0.2594, -0.2184, -0.1186,\n",
            "         -0.3069,  0.0694, -0.0432,  0.4122, -0.3318, -0.4065,  0.3020,  0.3789,\n",
            "          0.2673, -0.0102,  0.2405,  0.2338,  0.2757,  0.0022, -0.3237,  0.0764,\n",
            "          0.3663,  0.3692, -0.3849,  0.1496,  0.4217, -0.1601, -0.1562,  0.1455]],\n",
            "       grad_fn=<SliceBackward0>) \n",
            "\n",
            "Layer: module.0.params.0.weight | Size: torch.Size([2, 64, 5]) | Values : tensor([[[-0.3695, -0.3527,  0.3144,  0.4461,  0.2215],\n",
            "         [ 0.3941, -0.2790,  0.1389,  0.0210,  0.2484],\n",
            "         [ 0.3313, -0.1639, -0.1600, -0.2906,  0.3133],\n",
            "         [-0.1417,  0.2147,  0.0549,  0.4310, -0.0422],\n",
            "         [ 0.0253, -0.1063,  0.1007,  0.3186, -0.2723],\n",
            "         [ 0.2674, -0.2620, -0.2474,  0.2861,  0.4114],\n",
            "         [-0.3293,  0.3627,  0.0983, -0.2247,  0.4129],\n",
            "         [ 0.3825, -0.1371, -0.4251, -0.1812, -0.1855],\n",
            "         [ 0.2066, -0.1353,  0.0915, -0.0417, -0.1463],\n",
            "         [ 0.3784, -0.2370, -0.2273, -0.4468, -0.2612],\n",
            "         [ 0.4093, -0.1376, -0.0346, -0.3270,  0.1154],\n",
            "         [ 0.1046, -0.0785,  0.2826, -0.3279,  0.3992],\n",
            "         [-0.1236, -0.4348, -0.1587,  0.3729,  0.0031],\n",
            "         [-0.2522,  0.4118,  0.0333, -0.3444, -0.2358],\n",
            "         [ 0.2242, -0.2141, -0.1587, -0.0192, -0.2281],\n",
            "         [ 0.2074,  0.2139,  0.4139, -0.2847, -0.4337],\n",
            "         [ 0.3932,  0.1477,  0.1355,  0.3398, -0.0127],\n",
            "         [ 0.0565,  0.3976, -0.2036, -0.2925, -0.2079],\n",
            "         [-0.0190, -0.1638,  0.4312, -0.3414, -0.1783],\n",
            "         [ 0.1155, -0.0891, -0.1335, -0.1106, -0.1548],\n",
            "         [-0.0107, -0.0816, -0.2086, -0.0470, -0.0425],\n",
            "         [ 0.2160,  0.2574, -0.0144, -0.0638,  0.4455],\n",
            "         [-0.0009,  0.0329,  0.2135, -0.2904,  0.3609],\n",
            "         [ 0.0079,  0.1175, -0.0134, -0.3668, -0.1727],\n",
            "         [-0.2040,  0.1769, -0.3770,  0.1472,  0.0090],\n",
            "         [ 0.1324, -0.3348, -0.1106, -0.4346, -0.1087],\n",
            "         [-0.2376, -0.1100, -0.0956, -0.1886, -0.2827],\n",
            "         [ 0.0950, -0.3938,  0.2618, -0.0270, -0.2624],\n",
            "         [-0.3892,  0.2424,  0.1673, -0.0743, -0.4232],\n",
            "         [-0.2359,  0.4422,  0.1716,  0.1332, -0.4157],\n",
            "         [ 0.3456,  0.2148,  0.3380, -0.1884, -0.4119],\n",
            "         [ 0.2533,  0.3515, -0.1414, -0.2985,  0.3147],\n",
            "         [-0.0005, -0.2178, -0.2196, -0.2026, -0.2603],\n",
            "         [-0.1417, -0.3090, -0.0900,  0.3329, -0.0919],\n",
            "         [-0.2195, -0.1251, -0.1456,  0.0395, -0.2281],\n",
            "         [ 0.2494,  0.3433, -0.1628,  0.2447, -0.0933],\n",
            "         [ 0.2065, -0.1999, -0.1065,  0.1187,  0.3943],\n",
            "         [-0.1776, -0.2875,  0.2560,  0.2651,  0.2483],\n",
            "         [-0.2816, -0.1583, -0.0019,  0.1291, -0.2515],\n",
            "         [-0.0374,  0.3913,  0.1998, -0.4274, -0.1046],\n",
            "         [-0.1808,  0.0856,  0.1298, -0.2448,  0.0897],\n",
            "         [-0.2160,  0.1397,  0.0278, -0.2602,  0.0909],\n",
            "         [ 0.1236, -0.3731,  0.0102, -0.1003, -0.2536],\n",
            "         [ 0.2206, -0.2118, -0.2603,  0.0331, -0.4117],\n",
            "         [ 0.4472, -0.4371,  0.0942,  0.3905,  0.3916],\n",
            "         [-0.2701,  0.1207, -0.3705, -0.1944, -0.4139],\n",
            "         [ 0.1279, -0.2086, -0.1318,  0.0998,  0.1578],\n",
            "         [-0.0937, -0.1494,  0.3814, -0.4022,  0.4031],\n",
            "         [ 0.3453, -0.0302,  0.4358,  0.0930,  0.1041],\n",
            "         [ 0.3151,  0.0017, -0.3936, -0.2939,  0.1162],\n",
            "         [ 0.0796,  0.3388,  0.1816, -0.1873, -0.1445],\n",
            "         [ 0.2538, -0.2224,  0.3529,  0.0540, -0.0118],\n",
            "         [ 0.1435,  0.0943,  0.1770, -0.2865, -0.2972],\n",
            "         [ 0.1740, -0.2426,  0.1044,  0.2405, -0.0390],\n",
            "         [-0.2672, -0.3059,  0.1728, -0.2507,  0.2312],\n",
            "         [ 0.0931, -0.2962, -0.3070,  0.3129,  0.2408],\n",
            "         [-0.0613,  0.4295,  0.1204, -0.0998, -0.4472],\n",
            "         [-0.2525,  0.3355,  0.0026, -0.0148,  0.0517],\n",
            "         [-0.0370,  0.2137, -0.1300,  0.3862, -0.3755],\n",
            "         [ 0.1263,  0.2591,  0.3514,  0.2078,  0.3572],\n",
            "         [ 0.1122,  0.0364,  0.0521,  0.1291, -0.0208],\n",
            "         [ 0.0073,  0.3554,  0.3438,  0.2385,  0.2402],\n",
            "         [ 0.4305, -0.2199,  0.0151,  0.2186,  0.3078],\n",
            "         [-0.2151, -0.1808, -0.1030, -0.3209, -0.1234]],\n",
            "\n",
            "        [[ 0.4379,  0.1111,  0.0750,  0.3579, -0.0818],\n",
            "         [ 0.3984,  0.0472,  0.3333, -0.2163,  0.2897],\n",
            "         [ 0.0308, -0.0009, -0.1059,  0.0904,  0.3938],\n",
            "         [ 0.4126, -0.0809, -0.2538, -0.2804,  0.0210],\n",
            "         [-0.4353, -0.1395,  0.2907, -0.4113, -0.0644],\n",
            "         [-0.1475, -0.0719, -0.4011,  0.1199, -0.3002],\n",
            "         [-0.3052, -0.4148,  0.1172, -0.2404,  0.2909],\n",
            "         [ 0.2230,  0.2957, -0.1626, -0.1952,  0.0086],\n",
            "         [ 0.1490, -0.1296,  0.2418,  0.2806,  0.1344],\n",
            "         [-0.0871, -0.1616,  0.4362, -0.0142,  0.3513],\n",
            "         [ 0.3572,  0.2818, -0.2148, -0.0375, -0.2901],\n",
            "         [ 0.4328,  0.3467,  0.1401,  0.1281, -0.1119],\n",
            "         [-0.2559,  0.3847, -0.0255, -0.2036,  0.1685],\n",
            "         [-0.2101,  0.3294,  0.2516,  0.2681, -0.0698],\n",
            "         [ 0.0615, -0.1407, -0.2848,  0.0790,  0.1089],\n",
            "         [ 0.2022, -0.3880,  0.2127,  0.2833,  0.2939],\n",
            "         [-0.2518, -0.3260, -0.3811,  0.0903,  0.4435],\n",
            "         [-0.1232,  0.2393,  0.3635,  0.1895, -0.1107],\n",
            "         [-0.0922,  0.1487, -0.0876, -0.0180,  0.3586],\n",
            "         [ 0.4416, -0.4152, -0.1921, -0.4164,  0.4263],\n",
            "         [ 0.0584, -0.0519, -0.2582, -0.2065, -0.2302],\n",
            "         [ 0.3959,  0.4204, -0.0456,  0.4452, -0.3908],\n",
            "         [ 0.3417,  0.3691, -0.4124,  0.0809,  0.0743],\n",
            "         [-0.2951,  0.1008, -0.2314, -0.0534,  0.2964],\n",
            "         [ 0.1933,  0.0871,  0.0936, -0.0278, -0.1334],\n",
            "         [-0.3247,  0.2419,  0.2124, -0.4332,  0.3158],\n",
            "         [-0.4176,  0.0086, -0.0056, -0.0413,  0.1814],\n",
            "         [ 0.3636, -0.1082,  0.4340,  0.4365,  0.3982],\n",
            "         [-0.3490,  0.1040, -0.0461, -0.2261, -0.0431],\n",
            "         [-0.4464, -0.3174, -0.0708, -0.0350, -0.0740],\n",
            "         [-0.0032,  0.2809, -0.3165,  0.2715,  0.2572],\n",
            "         [-0.0798, -0.4265, -0.3622,  0.3811,  0.3033],\n",
            "         [-0.0298, -0.3802,  0.0383,  0.2170, -0.3415],\n",
            "         [ 0.4448,  0.2933,  0.2467, -0.1927,  0.0843],\n",
            "         [-0.1636,  0.1096, -0.0576,  0.0395,  0.1984],\n",
            "         [-0.1854,  0.4282,  0.0373,  0.2256, -0.1646],\n",
            "         [ 0.3258, -0.2471, -0.0211, -0.3202, -0.3508],\n",
            "         [-0.4354,  0.3104, -0.1906,  0.1897, -0.1332],\n",
            "         [ 0.2980, -0.1565, -0.0009, -0.0602, -0.3228],\n",
            "         [-0.2650, -0.4141, -0.0494,  0.2963, -0.0570],\n",
            "         [-0.3886, -0.2332,  0.3091, -0.1142,  0.3352],\n",
            "         [-0.1316, -0.3095,  0.2609, -0.3131, -0.0904],\n",
            "         [-0.0093, -0.3633,  0.2063,  0.3435,  0.1110],\n",
            "         [-0.1159, -0.2163,  0.0225, -0.4112,  0.4277],\n",
            "         [ 0.4331, -0.3507, -0.2265, -0.1758,  0.0338],\n",
            "         [ 0.0996, -0.3286, -0.2581,  0.2323, -0.2354],\n",
            "         [-0.0306, -0.4364,  0.1544,  0.0553, -0.2331],\n",
            "         [ 0.1542,  0.3266, -0.3155, -0.0793,  0.4318],\n",
            "         [-0.0594, -0.0956,  0.1436,  0.0356,  0.2900],\n",
            "         [-0.1682, -0.0382, -0.1518, -0.3356,  0.3667],\n",
            "         [-0.0205, -0.3459,  0.0624,  0.2706, -0.1891],\n",
            "         [ 0.3880, -0.0994,  0.0182,  0.2355, -0.4146],\n",
            "         [ 0.1221, -0.1866,  0.2434, -0.0010, -0.2223],\n",
            "         [-0.1359, -0.4172,  0.1178,  0.3879, -0.4074],\n",
            "         [-0.0150,  0.2377, -0.1339, -0.2246,  0.3817],\n",
            "         [ 0.1305, -0.2662, -0.0310,  0.2334,  0.2129],\n",
            "         [ 0.0900,  0.4312, -0.1056,  0.0236,  0.0356],\n",
            "         [ 0.3801,  0.2543, -0.2511, -0.1026, -0.0584],\n",
            "         [-0.1302, -0.0500, -0.2778,  0.2902, -0.1122],\n",
            "         [ 0.2046, -0.2427,  0.4415,  0.0622, -0.0151],\n",
            "         [-0.0132, -0.1645,  0.1477,  0.3535,  0.1283],\n",
            "         [-0.3923, -0.1427,  0.2742, -0.1270,  0.0109],\n",
            "         [-0.0323,  0.0037, -0.3857, -0.3298,  0.1870],\n",
            "         [-0.0949, -0.3135, -0.2623, -0.4459,  0.3595]]],\n",
            "       grad_fn=<SliceBackward0>) \n",
            "\n",
            "Layer: module.0.params.4.bias | Size: torch.Size([2, 256]) | Values : tensor([[ 1.1101e-02,  7.9742e-02, -7.3857e-02,  2.3638e-03, -3.9034e-02,\n",
            "          8.7487e-02,  1.8614e-02,  3.5124e-03, -5.3238e-02,  4.6880e-02,\n",
            "         -3.0479e-02, -7.3233e-02, -7.0023e-02, -1.9170e-02,  1.2327e-02,\n",
            "         -6.2424e-02,  3.1242e-02, -5.8205e-02,  3.3271e-02, -1.6974e-02,\n",
            "         -5.1266e-02,  2.7550e-03,  8.3757e-02, -1.2987e-02, -1.3259e-03,\n",
            "         -3.7616e-02, -2.4788e-02, -6.2301e-02,  1.3282e-02, -5.4609e-02,\n",
            "          8.1797e-02,  7.2190e-03,  8.0823e-02,  3.6908e-02, -7.9726e-02,\n",
            "         -5.0811e-02,  8.1126e-03, -7.7601e-02, -2.3056e-02, -1.0724e-02,\n",
            "          4.4869e-02,  6.5568e-02, -4.5815e-02, -2.8041e-02, -8.0393e-02,\n",
            "          2.7815e-02, -8.9713e-03, -3.0258e-02, -5.3498e-02, -3.8199e-02,\n",
            "          3.7438e-02,  7.2667e-02, -5.2058e-02, -7.5424e-02, -2.9545e-03,\n",
            "          2.4390e-03,  2.3112e-02,  1.0453e-02,  2.8295e-02,  3.3744e-02,\n",
            "         -1.6559e-02,  1.6433e-02,  4.5972e-02,  7.7832e-02, -2.7966e-03,\n",
            "          3.3088e-03, -5.8871e-02, -6.6226e-02,  1.9046e-02, -4.1661e-02,\n",
            "         -4.3054e-02,  5.9384e-02,  4.9786e-02, -7.3458e-02, -6.9836e-03,\n",
            "         -2.1531e-02, -7.8315e-02, -6.5073e-02, -7.3297e-02,  7.1789e-02,\n",
            "         -4.6593e-02, -3.7203e-02,  7.7555e-02,  4.1202e-02, -3.7156e-02,\n",
            "          3.7822e-02, -7.0619e-02, -8.4112e-02, -7.9736e-03,  7.6068e-02,\n",
            "          7.4694e-02,  2.6918e-02, -2.9400e-02, -2.7578e-02,  7.4723e-02,\n",
            "          7.8646e-02, -7.1257e-02,  6.0917e-02, -1.8320e-02,  7.3533e-02,\n",
            "         -3.7125e-03, -6.0228e-02, -5.2188e-03,  1.5047e-02,  1.1327e-02,\n",
            "          2.1404e-03,  3.7143e-02, -6.7343e-02, -2.2297e-02, -5.3553e-03,\n",
            "         -5.5762e-03, -5.6982e-02,  2.7610e-02, -1.4654e-02, -7.2376e-03,\n",
            "          7.1115e-02, -3.4173e-02,  4.3922e-02,  1.1784e-02,  8.6518e-02,\n",
            "         -5.6958e-02, -1.8650e-02, -5.1603e-02, -2.7568e-02, -4.5050e-02,\n",
            "          4.0056e-02, -3.1012e-02, -2.9002e-02,  4.6597e-02, -6.6547e-02,\n",
            "         -2.1920e-02,  4.8597e-02,  6.0747e-02, -2.2144e-02,  2.3682e-02,\n",
            "         -7.5453e-02, -9.2410e-03, -3.2200e-02,  5.1688e-02, -4.3501e-03,\n",
            "          5.1502e-02,  4.7468e-02,  7.4484e-02,  7.8528e-02,  2.5050e-02,\n",
            "          7.0627e-03,  2.7032e-02,  5.7109e-02, -6.1352e-02, -6.1352e-02,\n",
            "          4.4145e-02, -1.5586e-02,  4.4074e-02,  8.4440e-02,  2.2024e-02,\n",
            "         -4.7400e-02, -8.4190e-03,  8.0140e-02,  6.2800e-02,  2.9910e-02,\n",
            "         -8.3976e-02,  6.8429e-02, -4.4272e-03,  3.0694e-02,  4.7345e-02,\n",
            "          2.8003e-02, -7.2855e-02,  5.0082e-02,  1.0218e-02,  8.2610e-02,\n",
            "          7.0594e-02,  5.3272e-02, -3.4101e-02, -4.0621e-02,  4.7494e-02,\n",
            "          6.7617e-02, -7.0532e-02, -5.4601e-02,  6.4228e-02, -4.6715e-02,\n",
            "         -6.1267e-02, -8.8075e-02, -4.2914e-02, -6.2219e-02, -2.1324e-02,\n",
            "         -5.8266e-02,  4.9156e-02, -8.3569e-02, -7.7343e-02, -2.0299e-02,\n",
            "         -8.0472e-02,  2.7575e-02,  5.1608e-03, -3.3626e-02,  6.6067e-02,\n",
            "         -7.0999e-02,  1.7621e-02,  6.8047e-02, -7.4158e-02,  2.0916e-02,\n",
            "         -4.0704e-02,  4.4694e-02,  5.6234e-03, -1.0533e-02, -2.5421e-03,\n",
            "          6.9946e-02, -4.5850e-02, -2.8477e-02,  6.3327e-02,  4.7936e-02,\n",
            "          6.4698e-02, -8.8157e-02, -7.4487e-02,  2.8358e-02,  3.6159e-02,\n",
            "         -1.5480e-02, -3.7739e-02,  1.3745e-02,  5.0021e-02,  3.4885e-02,\n",
            "          7.8028e-02,  4.2417e-03,  4.2390e-02, -5.5472e-02,  2.2687e-02,\n",
            "          4.4042e-04,  1.4628e-02, -3.3776e-02, -1.4358e-02,  1.4046e-02,\n",
            "         -2.5071e-02, -6.6338e-03,  2.5752e-02,  2.6815e-02, -8.7451e-03,\n",
            "         -4.9773e-02,  4.1707e-02, -6.0170e-02, -2.5420e-02,  1.0366e-02,\n",
            "         -2.5846e-02, -4.9284e-02,  2.4488e-02, -3.2118e-02, -7.2120e-03,\n",
            "         -4.2322e-02,  2.2569e-02,  8.7669e-02,  4.9498e-02,  7.4756e-02,\n",
            "          1.9381e-02, -6.5240e-02,  2.6881e-02,  8.4495e-06,  5.2032e-02,\n",
            "         -8.1347e-02],\n",
            "        [ 5.8233e-02, -5.8303e-02, -8.6604e-02, -1.6375e-02,  4.1259e-02,\n",
            "          3.5484e-02, -3.7017e-02,  2.3086e-02,  3.9390e-02, -1.7668e-02,\n",
            "          5.7321e-02,  3.1645e-02,  1.0622e-02, -3.6410e-02, -2.5468e-03,\n",
            "          5.8555e-02,  4.6111e-02, -7.0832e-02,  9.3223e-03,  6.1641e-02,\n",
            "          8.6531e-03, -3.0783e-02, -5.1374e-02,  4.8610e-02,  4.4321e-02,\n",
            "         -3.2663e-02, -8.5657e-02,  6.3627e-03, -2.2117e-02, -3.2242e-02,\n",
            "         -4.7510e-02, -2.6764e-03,  3.5868e-02, -6.7458e-02, -2.1070e-02,\n",
            "         -7.5908e-02,  7.5145e-02,  3.2318e-02,  6.4617e-02,  2.8848e-03,\n",
            "          2.2857e-02, -2.7464e-02, -3.7742e-02, -1.8665e-02,  2.5955e-02,\n",
            "          6.5655e-02, -8.1744e-02,  8.4387e-02,  1.4622e-02, -2.4652e-02,\n",
            "         -6.1555e-02, -2.0566e-02,  3.8836e-02,  1.8980e-02, -8.6233e-02,\n",
            "          7.1806e-02,  8.4176e-02, -1.5073e-03,  3.0835e-02,  7.0195e-02,\n",
            "         -2.9274e-02, -4.1763e-02, -7.3291e-02,  7.3134e-02, -2.0611e-02,\n",
            "         -7.8449e-02,  6.7305e-03,  8.4325e-02,  7.8786e-02,  7.6851e-02,\n",
            "         -8.7792e-02,  1.5598e-02, -5.0807e-02,  7.5943e-02,  4.1864e-02,\n",
            "          1.3873e-02, -8.2744e-02,  3.1161e-02,  1.4531e-02,  5.4344e-02,\n",
            "         -6.3019e-02, -3.6369e-02,  3.7398e-02,  7.6921e-02, -7.5392e-02,\n",
            "          8.1204e-02, -3.3342e-02,  2.0684e-02, -4.6990e-02,  8.6203e-02,\n",
            "         -5.4915e-02, -3.6163e-02,  6.9900e-02, -4.9001e-02, -1.7380e-03,\n",
            "         -4.3296e-02, -1.6110e-02,  1.2727e-02,  3.3388e-02, -8.6831e-03,\n",
            "         -3.2222e-02,  3.7138e-02,  5.0199e-02,  2.3192e-03,  5.6704e-02,\n",
            "         -4.4684e-02, -8.1712e-02,  7.5796e-02,  7.8394e-02,  6.2187e-02,\n",
            "          3.6434e-02,  1.8309e-02,  8.5302e-02,  4.9817e-02,  2.2226e-02,\n",
            "         -5.1006e-02, -7.1353e-02,  6.7780e-02,  6.7326e-02,  1.1634e-02,\n",
            "          5.5317e-02, -5.0413e-02, -3.1879e-02,  5.4325e-02, -7.6413e-02,\n",
            "         -5.3229e-02, -2.3543e-02, -7.8854e-02, -7.5890e-02, -1.0755e-02,\n",
            "         -5.4470e-02, -2.2433e-02, -1.6903e-02, -6.5806e-02, -2.9940e-02,\n",
            "         -3.3798e-03, -9.6291e-03, -1.6678e-04,  2.9396e-02, -5.7110e-02,\n",
            "          2.7113e-03,  6.2884e-03,  6.9523e-02,  7.7690e-02, -3.4807e-02,\n",
            "         -1.6414e-02,  3.8897e-02,  4.8034e-02,  5.6650e-02, -2.2083e-03,\n",
            "         -3.3606e-02, -3.4606e-02, -7.9571e-02,  8.1986e-02,  3.9216e-02,\n",
            "         -4.5699e-04,  5.5096e-02,  7.9700e-02, -1.9207e-02,  7.3532e-02,\n",
            "         -7.9015e-02,  8.3115e-02,  5.3564e-02,  2.7278e-02,  2.2316e-02,\n",
            "          6.0720e-02, -6.7353e-02, -5.1100e-02, -4.6731e-02,  1.9997e-02,\n",
            "          8.1381e-02,  1.7180e-02,  4.4863e-02,  2.2421e-02, -2.5520e-02,\n",
            "          3.3122e-03,  7.8367e-02, -6.2306e-02,  6.6717e-02, -5.8339e-02,\n",
            "          7.5620e-02,  6.4737e-02, -4.9748e-02,  7.7727e-02,  8.2904e-02,\n",
            "          2.5382e-02, -5.4359e-03,  1.2773e-02, -2.6849e-02, -3.3514e-02,\n",
            "         -4.9646e-02,  2.6451e-02,  2.3440e-02, -3.3286e-02,  8.2035e-02,\n",
            "         -6.0361e-02, -6.4179e-02, -8.2047e-02, -7.9525e-02, -7.6475e-02,\n",
            "          7.5966e-02,  1.0406e-02,  8.8654e-03,  5.3716e-02, -7.1743e-02,\n",
            "         -5.6583e-02, -7.7374e-02, -5.1944e-02, -1.2936e-02, -5.5711e-02,\n",
            "         -1.8504e-02,  6.0374e-02, -8.4470e-02, -4.4315e-02, -3.9579e-02,\n",
            "         -3.0149e-02, -8.5393e-03, -8.9026e-03, -1.8237e-02, -4.6141e-02,\n",
            "         -3.5082e-02, -2.0325e-02,  3.4801e-02,  7.7340e-02, -8.5502e-02,\n",
            "         -2.8715e-02,  6.3952e-02, -7.9024e-02,  2.8906e-02,  3.9325e-02,\n",
            "          1.9064e-02,  3.3594e-02,  2.3385e-02,  2.5962e-02,  5.3888e-02,\n",
            "         -2.7538e-02, -3.3201e-02, -8.1853e-02,  3.4723e-02, -4.6523e-02,\n",
            "          2.0843e-02,  2.4651e-04,  7.1458e-02, -8.4793e-02,  2.2665e-02,\n",
            "          8.0215e-02, -1.0734e-03, -7.0477e-02, -4.2369e-02,  8.5271e-02,\n",
            "          1.3434e-02, -6.7526e-02,  1.7683e-02,  8.6294e-02, -7.2019e-02,\n",
            "          3.4579e-02]], grad_fn=<SliceBackward0>) \n",
            "\n",
            "Layer: module.0.params.4.weight | Size: torch.Size([2, 256, 128]) | Values : tensor([[[ 4.6799e-02, -5.5239e-02,  1.3371e-02,  ...,  3.6066e-02,\n",
            "           7.1802e-02,  6.5497e-02],\n",
            "         [ 7.4865e-03, -3.0919e-02, -4.1677e-02,  ..., -4.3453e-02,\n",
            "           1.5071e-02, -7.7522e-02],\n",
            "         [ 2.7457e-02,  1.2871e-02,  8.0350e-02,  ...,  3.2573e-02,\n",
            "           5.3685e-02, -7.8349e-05],\n",
            "         ...,\n",
            "         [ 4.7027e-02, -3.5181e-02,  5.3293e-03,  ...,  1.3389e-03,\n",
            "           9.3676e-03,  1.5408e-02],\n",
            "         [-1.1329e-02,  3.7332e-02,  3.4944e-02,  ...,  1.1559e-02,\n",
            "          -5.0157e-02,  7.7894e-02],\n",
            "         [-3.7480e-02, -6.4033e-02, -5.0707e-02,  ...,  5.4514e-02,\n",
            "          -2.4932e-02,  2.8098e-02]],\n",
            "\n",
            "        [[-1.9468e-02,  4.2890e-03,  7.2872e-03,  ...,  7.1715e-02,\n",
            "          -2.5000e-02, -2.5770e-02],\n",
            "         [ 8.7691e-02, -6.7396e-02,  7.5146e-02,  ..., -7.8474e-02,\n",
            "           5.5856e-02, -2.9544e-02],\n",
            "         [-2.4616e-02, -2.8227e-02, -8.4112e-02,  ...,  8.2231e-02,\n",
            "           2.7275e-02, -8.8028e-02],\n",
            "         ...,\n",
            "         [-4.9724e-03, -5.3783e-02,  6.9166e-02,  ...,  4.2304e-02,\n",
            "          -5.8421e-02,  6.8075e-02],\n",
            "         [ 5.6013e-02,  7.7657e-02,  7.7801e-02,  ..., -5.8891e-02,\n",
            "          -5.4441e-02,  7.8566e-03],\n",
            "         [-5.8391e-02,  2.9647e-02,  6.2092e-02,  ..., -2.3895e-02,\n",
            "          -4.4831e-02, -3.1087e-02]]], grad_fn=<SliceBackward0>) \n",
            "\n",
            "Layer: module.0.params.6.bias | Size: torch.Size([2, 1]) | Values : tensor([[-0.0440],\n",
            "        [ 0.0376]], grad_fn=<SliceBackward0>) \n",
            "\n",
            "Layer: module.0.params.6.weight | Size: torch.Size([2, 1, 256]) | Values : tensor([[[ 0.0312, -0.0138, -0.0176, -0.0053, -0.0395, -0.0485,  0.0052,\n",
            "           0.0065, -0.0073, -0.0398,  0.0340, -0.0402,  0.0014, -0.0424,\n",
            "          -0.0277,  0.0437,  0.0035, -0.0555, -0.0566, -0.0267,  0.0090,\n",
            "           0.0255,  0.0499, -0.0423,  0.0240,  0.0552,  0.0453,  0.0436,\n",
            "           0.0192, -0.0416, -0.0053, -0.0543,  0.0519,  0.0612,  0.0506,\n",
            "          -0.0370, -0.0575, -0.0246,  0.0197, -0.0457, -0.0237, -0.0542,\n",
            "          -0.0095,  0.0526, -0.0216, -0.0324, -0.0558,  0.0056, -0.0138,\n",
            "           0.0565,  0.0075, -0.0187, -0.0244, -0.0041, -0.0021,  0.0310,\n",
            "           0.0328,  0.0188,  0.0395, -0.0035, -0.0439,  0.0046, -0.0430,\n",
            "          -0.0444, -0.0273,  0.0342, -0.0106,  0.0203,  0.0043, -0.0051,\n",
            "          -0.0027,  0.0265,  0.0081, -0.0259, -0.0319, -0.0455,  0.0409,\n",
            "           0.0116,  0.0462,  0.0436,  0.0078,  0.0327,  0.0198, -0.0106,\n",
            "           0.0456,  0.0242, -0.0059,  0.0150,  0.0096, -0.0346,  0.0376,\n",
            "           0.0140, -0.0618,  0.0335, -0.0403,  0.0155,  0.0267,  0.0350,\n",
            "           0.0425, -0.0062,  0.0618, -0.0273,  0.0412,  0.0060, -0.0152,\n",
            "           0.0168, -0.0286,  0.0600,  0.0436,  0.0357,  0.0574,  0.0541,\n",
            "          -0.0161,  0.0386, -0.0014, -0.0020, -0.0505,  0.0554, -0.0434,\n",
            "          -0.0044,  0.0303, -0.0079,  0.0428, -0.0405,  0.0558,  0.0195,\n",
            "          -0.0072,  0.0368, -0.0580, -0.0512,  0.0477,  0.0376,  0.0018,\n",
            "           0.0465, -0.0473,  0.0022, -0.0387, -0.0252,  0.0247, -0.0286,\n",
            "          -0.0354,  0.0477, -0.0132, -0.0436, -0.0145, -0.0153, -0.0145,\n",
            "          -0.0150, -0.0485,  0.0256,  0.0292, -0.0045,  0.0478,  0.0183,\n",
            "          -0.0305, -0.0584,  0.0485,  0.0154, -0.0528,  0.0560, -0.0174,\n",
            "           0.0548, -0.0591, -0.0189, -0.0355, -0.0115,  0.0183,  0.0552,\n",
            "           0.0211, -0.0416,  0.0483,  0.0612,  0.0008,  0.0420, -0.0288,\n",
            "           0.0249, -0.0462, -0.0074,  0.0389,  0.0136, -0.0015,  0.0233,\n",
            "          -0.0040, -0.0596,  0.0482,  0.0052,  0.0088, -0.0426,  0.0172,\n",
            "           0.0345,  0.0465, -0.0127, -0.0230, -0.0134,  0.0405, -0.0597,\n",
            "           0.0289,  0.0466,  0.0031,  0.0537,  0.0380, -0.0338, -0.0598,\n",
            "          -0.0569,  0.0174, -0.0248,  0.0592,  0.0009, -0.0553, -0.0098,\n",
            "          -0.0569,  0.0273, -0.0088, -0.0256, -0.0447, -0.0588, -0.0354,\n",
            "           0.0565,  0.0172, -0.0331, -0.0033,  0.0455, -0.0043, -0.0477,\n",
            "          -0.0040, -0.0585,  0.0499, -0.0522,  0.0414,  0.0542,  0.0592,\n",
            "          -0.0131, -0.0121,  0.0375, -0.0561, -0.0298,  0.0269,  0.0272,\n",
            "          -0.0391,  0.0574, -0.0622,  0.0496, -0.0174, -0.0379, -0.0204,\n",
            "          -0.0123,  0.0599,  0.0362, -0.0305, -0.0028, -0.0212, -0.0385,\n",
            "           0.0520, -0.0239, -0.0233,  0.0062]],\n",
            "\n",
            "        [[ 0.0463,  0.0548,  0.0075, -0.0546, -0.0464, -0.0289,  0.0389,\n",
            "           0.0376, -0.0396, -0.0547, -0.0250,  0.0071, -0.0169,  0.0446,\n",
            "          -0.0354, -0.0242,  0.0342,  0.0611, -0.0052,  0.0410, -0.0071,\n",
            "          -0.0055,  0.0212,  0.0227,  0.0490, -0.0173,  0.0305,  0.0376,\n",
            "          -0.0303,  0.0044, -0.0132,  0.0134,  0.0578,  0.0376, -0.0260,\n",
            "          -0.0187,  0.0613,  0.0533, -0.0144,  0.0194, -0.0142, -0.0622,\n",
            "          -0.0150,  0.0112,  0.0237,  0.0440,  0.0614,  0.0413, -0.0061,\n",
            "          -0.0149,  0.0341, -0.0243,  0.0599, -0.0604,  0.0588, -0.0599,\n",
            "          -0.0080, -0.0497, -0.0582,  0.0412, -0.0027,  0.0420,  0.0444,\n",
            "          -0.0599,  0.0129,  0.0615, -0.0158, -0.0510, -0.0059, -0.0051,\n",
            "          -0.0623, -0.0181,  0.0532, -0.0089, -0.0274,  0.0118, -0.0251,\n",
            "          -0.0368,  0.0507,  0.0227,  0.0515, -0.0021,  0.0551,  0.0587,\n",
            "           0.0445,  0.0093,  0.0479,  0.0348,  0.0541, -0.0508, -0.0264,\n",
            "           0.0034, -0.0206,  0.0150,  0.0400,  0.0452, -0.0080, -0.0621,\n",
            "           0.0564, -0.0226, -0.0044, -0.0007,  0.0191, -0.0270, -0.0086,\n",
            "           0.0618, -0.0451,  0.0115, -0.0369, -0.0221,  0.0216,  0.0157,\n",
            "           0.0567, -0.0550, -0.0102,  0.0222, -0.0343, -0.0009, -0.0067,\n",
            "           0.0488, -0.0275, -0.0179,  0.0207,  0.0073, -0.0622, -0.0153,\n",
            "           0.0518, -0.0219, -0.0156, -0.0190, -0.0152,  0.0170, -0.0417,\n",
            "           0.0513,  0.0311, -0.0521,  0.0234, -0.0114, -0.0018, -0.0068,\n",
            "           0.0368,  0.0304,  0.0598,  0.0226,  0.0400, -0.0381, -0.0157,\n",
            "           0.0183,  0.0248,  0.0416,  0.0588,  0.0321,  0.0444, -0.0064,\n",
            "          -0.0605,  0.0067,  0.0561,  0.0013, -0.0287, -0.0258, -0.0535,\n",
            "           0.0457,  0.0560,  0.0190, -0.0131,  0.0036,  0.0071,  0.0554,\n",
            "          -0.0370, -0.0313, -0.0400,  0.0105, -0.0544, -0.0049, -0.0506,\n",
            "          -0.0027,  0.0015, -0.0072, -0.0111,  0.0226,  0.0239, -0.0243,\n",
            "          -0.0512, -0.0542,  0.0109,  0.0103, -0.0264, -0.0272, -0.0469,\n",
            "           0.0158,  0.0288, -0.0168,  0.0052,  0.0457,  0.0307, -0.0452,\n",
            "          -0.0271, -0.0293,  0.0478, -0.0194,  0.0285, -0.0584,  0.0282,\n",
            "          -0.0430,  0.0122, -0.0410,  0.0374, -0.0576,  0.0527, -0.0064,\n",
            "          -0.0225,  0.0607,  0.0188, -0.0419, -0.0489,  0.0552, -0.0444,\n",
            "          -0.0547, -0.0162, -0.0499, -0.0008, -0.0488,  0.0601,  0.0005,\n",
            "           0.0551,  0.0213, -0.0601, -0.0348, -0.0112,  0.0518,  0.0256,\n",
            "          -0.0545,  0.0600, -0.0368, -0.0302,  0.0233, -0.0382, -0.0087,\n",
            "           0.0502, -0.0516,  0.0613,  0.0213,  0.0205, -0.0040,  0.0473,\n",
            "           0.0349, -0.0028,  0.0262, -0.0454, -0.0454, -0.0467, -0.0006,\n",
            "          -0.0116, -0.0220,  0.0405, -0.0197]]], grad_fn=<SliceBackward0>) \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Model structure: {policy}\\n\\n\")\n",
        "for name, param in policy.named_parameters():\n",
        "    print(f\"Layer: {name} | Size: {param.size()} | Values : {param[:2]} \\n\")"
      ],
      "metadata": {
        "id": "dZ55zR7cP9EV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a27f94ae-412e-448b-d681-e55cf6fbeb00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model structure: ProbabilisticActor(\n",
            "    module=ModuleList(\n",
            "      (0): TensorDictModule(\n",
            "          module=Sequential(\n",
            "            (0): MultiAgentMLP(\n",
            "                MLP(\n",
            "                  (0): Linear(in_features=5, out_features=64, bias=True)\n",
            "                  (1): Tanh()\n",
            "                  (2): Linear(in_features=64, out_features=128, bias=True)\n",
            "                  (3): Tanh()\n",
            "                  (4): Linear(in_features=128, out_features=256, bias=True)\n",
            "                  (5): Tanh()\n",
            "                  (6): Linear(in_features=256, out_features=2, bias=True)\n",
            "                ),\n",
            "                n_agents=2,\n",
            "                share_params=False,\n",
            "                centralized=False,\n",
            "                agent_dim=-2)\n",
            "            (1): NormalParamExtractor(\n",
            "              (scale_mapping): biased_softplus()\n",
            "            )\n",
            "          ),\n",
            "          device=cpu,\n",
            "          in_keys=[('agents', 'observation')],\n",
            "          out_keys=[('agents', 'loc'), ('agents', 'scale')])\n",
            "      (1): SafeProbabilisticModule()\n",
            "    ),\n",
            "    device=cpu,\n",
            "    in_keys=[('agents', 'observation')],\n",
            "    out_keys=[('agents', 'loc'), ('agents', 'scale'), ('agents', 'action'), ('agents', 'sample_log_prob')])\n",
            "\n",
            "\n",
            "Layer: module.0.module.0.params.2.bias | Size: torch.Size([2, 128]) | Values : tensor([[ 0.0287,  0.0935,  0.0660,  0.0949, -0.0323,  0.0187, -0.0987,  0.0156,\n",
            "          0.0664,  0.0528, -0.0112,  0.1141,  0.0893, -0.0031,  0.0374, -0.1107,\n",
            "          0.1214, -0.0066,  0.0722, -0.0214,  0.1016, -0.0239,  0.0316,  0.0977,\n",
            "          0.0978, -0.0274, -0.0413, -0.0530,  0.0359,  0.0061, -0.0916,  0.0647,\n",
            "          0.0243,  0.0585, -0.1001,  0.0695, -0.0722, -0.0856, -0.0996, -0.1002,\n",
            "          0.0045,  0.0693,  0.0331,  0.0601,  0.0525,  0.1168, -0.0097,  0.0072,\n",
            "         -0.0520, -0.0091,  0.0552, -0.0212, -0.0586,  0.0553,  0.0185,  0.1179,\n",
            "          0.0649,  0.0755,  0.0060, -0.0834,  0.0337,  0.0558,  0.0223,  0.0754,\n",
            "         -0.0716, -0.0622, -0.1209,  0.0111,  0.0195,  0.0712,  0.1052, -0.0633,\n",
            "         -0.1055, -0.1140, -0.1182, -0.1228, -0.0802,  0.0866, -0.0825, -0.0252,\n",
            "          0.0836,  0.0197,  0.0556, -0.1234,  0.0411,  0.1215,  0.0848, -0.0137,\n",
            "         -0.0375,  0.0350,  0.0669,  0.0674, -0.1051,  0.0795, -0.0020, -0.1214,\n",
            "         -0.0177,  0.0501,  0.0510, -0.0814,  0.1152,  0.0705, -0.0266,  0.1206,\n",
            "          0.1027, -0.0808,  0.0560, -0.0228, -0.0025, -0.0938, -0.1142,  0.0192,\n",
            "         -0.1022,  0.0967,  0.0849,  0.1017, -0.0957,  0.0875,  0.1064, -0.1067,\n",
            "         -0.0105, -0.1032,  0.1073,  0.0248,  0.0407,  0.0867, -0.1191, -0.1042],\n",
            "        [ 0.0714,  0.0050, -0.0385, -0.0639, -0.1011, -0.0367,  0.1162,  0.1237,\n",
            "          0.0535, -0.1115, -0.0943, -0.0208, -0.1161,  0.0570, -0.0050, -0.0587,\n",
            "         -0.1083, -0.0625,  0.0820,  0.0829, -0.0881,  0.0658, -0.0095, -0.0525,\n",
            "          0.0130, -0.0853, -0.0774,  0.0754,  0.0415,  0.0711, -0.0455,  0.0660,\n",
            "         -0.0828,  0.1000,  0.0697, -0.0413, -0.0719, -0.0834, -0.1131,  0.1048,\n",
            "          0.0727, -0.0090, -0.0357, -0.0228, -0.0057,  0.0619, -0.0261, -0.1159,\n",
            "         -0.0646,  0.0764, -0.0655,  0.0512, -0.0061, -0.0158, -0.0937, -0.0950,\n",
            "         -0.0700,  0.0429,  0.0143,  0.1036,  0.0870, -0.0698,  0.0729, -0.0510,\n",
            "         -0.0400, -0.1129, -0.0182, -0.0151,  0.0025, -0.0408, -0.0555,  0.0766,\n",
            "         -0.1154,  0.0204, -0.0495, -0.0307,  0.0183,  0.0678, -0.0274,  0.0683,\n",
            "         -0.0767, -0.0435,  0.0621,  0.0443,  0.0552,  0.1023,  0.0640,  0.0383,\n",
            "         -0.0151, -0.0460,  0.0183,  0.0514,  0.0692,  0.0623, -0.0973, -0.0225,\n",
            "         -0.0046, -0.1209, -0.1208,  0.0683, -0.0870,  0.0449,  0.1117, -0.0607,\n",
            "         -0.0139,  0.0231,  0.0746, -0.1132,  0.0142,  0.1131, -0.1189,  0.0441,\n",
            "          0.0522, -0.0333,  0.0462, -0.1202, -0.0275,  0.0230, -0.0189, -0.0411,\n",
            "          0.0550,  0.1187, -0.0305, -0.1178,  0.0731, -0.0832, -0.0246,  0.1078]],\n",
            "       grad_fn=<SliceBackward0>) \n",
            "\n",
            "Layer: module.0.module.0.params.2.weight | Size: torch.Size([2, 128, 64]) | Values : tensor([[[-0.0132,  0.0327,  0.1160,  ...,  0.0058,  0.0324,  0.0830],\n",
            "         [ 0.0520, -0.1029, -0.0556,  ...,  0.0850,  0.0993, -0.0249],\n",
            "         [-0.0337, -0.0781, -0.0891,  ..., -0.1007, -0.0122, -0.0061],\n",
            "         ...,\n",
            "         [-0.0850,  0.0556, -0.0820,  ...,  0.0505,  0.0815,  0.0496],\n",
            "         [-0.1108,  0.1242, -0.0872,  ...,  0.1235, -0.0946, -0.0114],\n",
            "         [-0.0071,  0.0324, -0.0613,  ..., -0.0215,  0.0665, -0.0048]],\n",
            "\n",
            "        [[ 0.0954,  0.0718,  0.0352,  ..., -0.0729,  0.0556, -0.0397],\n",
            "         [-0.1022,  0.0391,  0.0719,  ...,  0.1113,  0.0414, -0.0005],\n",
            "         [-0.1041, -0.0346, -0.0011,  ..., -0.0593,  0.0216,  0.0749],\n",
            "         ...,\n",
            "         [-0.0528, -0.0383, -0.0801,  ..., -0.0321, -0.1243, -0.0999],\n",
            "         [ 0.0868,  0.0025,  0.0609,  ...,  0.0671,  0.0263, -0.0159],\n",
            "         [ 0.0061, -0.0177,  0.0642,  ..., -0.0816, -0.0840, -0.1057]]],\n",
            "       grad_fn=<SliceBackward0>) \n",
            "\n",
            "Layer: module.0.module.0.params.0.bias | Size: torch.Size([2, 64]) | Values : tensor([[-0.4424,  0.3862,  0.0538,  0.2587, -0.3494, -0.4137,  0.2649,  0.2404,\n",
            "         -0.1426, -0.1190, -0.1868, -0.0048,  0.1166, -0.2637, -0.1167, -0.3129,\n",
            "         -0.1115,  0.1788,  0.3440, -0.1544,  0.0942, -0.3710,  0.2004,  0.3369,\n",
            "          0.1090,  0.0733, -0.3894,  0.1342, -0.2584, -0.4350, -0.2420, -0.3341,\n",
            "         -0.4319, -0.3921, -0.4188, -0.3783,  0.2359, -0.0304, -0.0405,  0.4288,\n",
            "         -0.1160,  0.1682,  0.3412, -0.1094,  0.4107,  0.2365, -0.1191, -0.0569,\n",
            "          0.2248, -0.4281,  0.2456,  0.0893,  0.1430,  0.4468,  0.1504, -0.2707,\n",
            "         -0.0273, -0.0821, -0.2935,  0.1913,  0.3178, -0.4120, -0.3205,  0.1994],\n",
            "        [ 0.3176,  0.0588,  0.1527, -0.0419, -0.3506,  0.2772, -0.4208, -0.2764,\n",
            "         -0.1591, -0.2650, -0.1630,  0.1157,  0.0437, -0.0270,  0.1797, -0.3659,\n",
            "          0.3628, -0.0883,  0.0247,  0.0703,  0.3383,  0.0458,  0.4017,  0.1000,\n",
            "          0.3670,  0.3750,  0.3146,  0.3476, -0.4284, -0.2914, -0.0810,  0.3922,\n",
            "         -0.3082, -0.2420,  0.1750,  0.3678,  0.1598, -0.1807, -0.0036, -0.4074,\n",
            "         -0.0571,  0.4037, -0.0013,  0.3344,  0.1274,  0.0143, -0.1497, -0.3498,\n",
            "          0.3771,  0.2933,  0.2898,  0.0881,  0.0561,  0.0147,  0.4324,  0.2900,\n",
            "          0.1963,  0.1925, -0.3904, -0.1369,  0.3232,  0.1266,  0.4330,  0.1273]],\n",
            "       grad_fn=<SliceBackward0>) \n",
            "\n",
            "Layer: module.0.module.0.params.0.weight | Size: torch.Size([2, 64, 5]) | Values : tensor([[[ 0.0568, -0.0645,  0.4242, -0.3355, -0.4066],\n",
            "         [ 0.0801, -0.0690,  0.3688,  0.2929,  0.3418],\n",
            "         [ 0.2782, -0.2091,  0.3137, -0.2762,  0.1973],\n",
            "         [ 0.2795, -0.1457, -0.1801,  0.3313,  0.4433],\n",
            "         [-0.0818,  0.2406, -0.2218,  0.1342,  0.1318],\n",
            "         [ 0.1305, -0.3548, -0.4072,  0.0317, -0.3843],\n",
            "         [ 0.0752, -0.2223,  0.1347,  0.1916,  0.0498],\n",
            "         [ 0.2467,  0.2763, -0.0965,  0.3067,  0.3242],\n",
            "         [ 0.2173, -0.3003,  0.1807,  0.3212,  0.4276],\n",
            "         [-0.0223,  0.3217,  0.1625, -0.4045,  0.1817],\n",
            "         [-0.4047,  0.1152,  0.1439,  0.1330,  0.1259],\n",
            "         [-0.0151, -0.0657,  0.3734, -0.4244,  0.2228],\n",
            "         [-0.3082, -0.4444,  0.3546, -0.3961, -0.1354],\n",
            "         [ 0.0160, -0.1203,  0.3041,  0.0416, -0.0158],\n",
            "         [-0.1661, -0.1053, -0.4141,  0.4412, -0.1833],\n",
            "         [-0.0125,  0.1642,  0.4428, -0.3835,  0.3738],\n",
            "         [-0.3616, -0.4420, -0.1694,  0.0599, -0.3887],\n",
            "         [ 0.3625, -0.0523,  0.1166, -0.4230, -0.2780],\n",
            "         [ 0.0273,  0.3625,  0.3150,  0.0580, -0.0601],\n",
            "         [-0.1126,  0.0729, -0.0410,  0.4343,  0.1808],\n",
            "         [-0.0199,  0.3296, -0.3399, -0.0335,  0.3200],\n",
            "         [ 0.1612,  0.2470,  0.2832,  0.2395, -0.4155],\n",
            "         [ 0.1612,  0.0507,  0.2635, -0.1460,  0.3562],\n",
            "         [ 0.2820, -0.2588, -0.4363, -0.1585,  0.3712],\n",
            "         [-0.0167,  0.2188,  0.3584, -0.4067, -0.2256],\n",
            "         [-0.0565,  0.2140, -0.2260, -0.0084, -0.1116],\n",
            "         [-0.2619,  0.1996, -0.2892,  0.3820, -0.0977],\n",
            "         [-0.3461, -0.4252, -0.2968, -0.3464, -0.2857],\n",
            "         [ 0.2357,  0.4296, -0.0021, -0.0067, -0.1434],\n",
            "         [ 0.2202,  0.3796, -0.1411,  0.2527,  0.0021],\n",
            "         [ 0.4168, -0.0488, -0.3317,  0.3380, -0.3716],\n",
            "         [ 0.2310,  0.3719, -0.0429,  0.1863,  0.2280],\n",
            "         [-0.0329, -0.2512, -0.0312,  0.0216, -0.1967],\n",
            "         [ 0.3114,  0.0834,  0.0903, -0.3703,  0.1571],\n",
            "         [ 0.3848,  0.1633,  0.2760, -0.3197,  0.0661],\n",
            "         [ 0.2580, -0.0041,  0.2843, -0.1643,  0.0839],\n",
            "         [ 0.1349, -0.2140, -0.0475,  0.3815,  0.1704],\n",
            "         [ 0.0109,  0.0502,  0.3327,  0.1497,  0.0886],\n",
            "         [-0.0530, -0.4065,  0.0035,  0.2119,  0.3892],\n",
            "         [ 0.3412, -0.2889, -0.3596, -0.2563,  0.1470],\n",
            "         [ 0.3002, -0.3488, -0.4263,  0.0690,  0.3387],\n",
            "         [-0.3887, -0.3258,  0.2291,  0.3609,  0.3669],\n",
            "         [-0.3312,  0.3017, -0.3083, -0.3148,  0.3431],\n",
            "         [-0.0560, -0.3806, -0.1023, -0.2281, -0.2377],\n",
            "         [ 0.4076,  0.3782,  0.1069,  0.0505,  0.3107],\n",
            "         [ 0.4249, -0.1526,  0.3572, -0.0622,  0.2275],\n",
            "         [ 0.1020,  0.0100, -0.3652,  0.0783, -0.3003],\n",
            "         [-0.0749, -0.1796, -0.0200, -0.2862,  0.2524],\n",
            "         [-0.2794, -0.0354,  0.1537, -0.1442,  0.4436],\n",
            "         [-0.2841, -0.0070, -0.0014,  0.0196, -0.3887],\n",
            "         [-0.3052, -0.2613,  0.1988,  0.4034, -0.2118],\n",
            "         [ 0.4311,  0.2022,  0.0951, -0.1374,  0.2779],\n",
            "         [ 0.2681, -0.2054,  0.3780, -0.1080,  0.1438],\n",
            "         [-0.3267,  0.0472,  0.2184, -0.4317,  0.2560],\n",
            "         [ 0.3429,  0.2062, -0.3821,  0.2522, -0.2063],\n",
            "         [-0.3906,  0.0759, -0.3186,  0.2213,  0.2525],\n",
            "         [-0.2728,  0.3014,  0.1913,  0.0188, -0.1946],\n",
            "         [-0.1222,  0.1777,  0.4238, -0.0606,  0.4351],\n",
            "         [ 0.3367,  0.2650,  0.0012, -0.1288,  0.3503],\n",
            "         [ 0.3309, -0.2756, -0.3984, -0.3556,  0.1007],\n",
            "         [ 0.2796, -0.4176,  0.3781, -0.1580, -0.1414],\n",
            "         [ 0.2885,  0.3744,  0.0873,  0.0333,  0.3336],\n",
            "         [-0.3485,  0.1561,  0.1490,  0.3262,  0.2993],\n",
            "         [-0.2897, -0.3539,  0.4093, -0.3002,  0.3573]],\n",
            "\n",
            "        [[-0.4172, -0.1458,  0.3910,  0.1764,  0.0332],\n",
            "         [-0.3188,  0.3486, -0.0789, -0.3747, -0.1778],\n",
            "         [-0.1290,  0.1519, -0.3117, -0.0735,  0.0510],\n",
            "         [-0.4131,  0.3923, -0.1143, -0.3579,  0.4295],\n",
            "         [-0.2398,  0.2817, -0.1521, -0.0996,  0.4374],\n",
            "         [-0.2216, -0.1501,  0.1152,  0.4155,  0.4009],\n",
            "         [-0.0657,  0.0778,  0.0268,  0.1732, -0.1676],\n",
            "         [ 0.4070, -0.0144,  0.2004, -0.1350,  0.4104],\n",
            "         [ 0.1561, -0.2006,  0.3188,  0.1470,  0.3060],\n",
            "         [ 0.2573, -0.1173, -0.2500, -0.1059, -0.1222],\n",
            "         [-0.0011, -0.0270,  0.2858,  0.3817, -0.4086],\n",
            "         [ 0.2827, -0.3642, -0.4221,  0.4385, -0.0314],\n",
            "         [-0.3822, -0.2331,  0.3453,  0.1911, -0.0416],\n",
            "         [-0.4440, -0.1427, -0.4426,  0.1975,  0.1929],\n",
            "         [-0.3325, -0.4184,  0.0909, -0.1392, -0.4211],\n",
            "         [-0.1419, -0.3627,  0.2043, -0.3528,  0.3311],\n",
            "         [-0.4422, -0.0717, -0.1172,  0.4032,  0.3135],\n",
            "         [ 0.2536,  0.2616,  0.2454, -0.1972, -0.0845],\n",
            "         [ 0.3279,  0.0660, -0.2008,  0.2176, -0.4312],\n",
            "         [ 0.3724,  0.2364, -0.4334, -0.3011, -0.2023],\n",
            "         [ 0.3461,  0.0548, -0.4091, -0.1564,  0.0762],\n",
            "         [ 0.3239,  0.3527, -0.0089, -0.0246, -0.3056],\n",
            "         [ 0.3350,  0.0174, -0.0080, -0.3289,  0.0057],\n",
            "         [-0.0554,  0.3673,  0.1578,  0.3654,  0.2317],\n",
            "         [-0.0581,  0.1705, -0.3518, -0.1032, -0.2150],\n",
            "         [-0.1347, -0.3116, -0.2513,  0.3859, -0.4354],\n",
            "         [ 0.1618, -0.1003,  0.4336, -0.3349, -0.3797],\n",
            "         [ 0.1188, -0.3749, -0.0935,  0.1213, -0.3481],\n",
            "         [-0.3206, -0.4362, -0.2574, -0.2351,  0.0518],\n",
            "         [ 0.3215,  0.0925, -0.1809,  0.2783,  0.2627],\n",
            "         [-0.3194, -0.3659,  0.3954, -0.1780,  0.0441],\n",
            "         [-0.3765, -0.1557, -0.1036, -0.3075,  0.2608],\n",
            "         [-0.4155,  0.3048,  0.3362,  0.3579, -0.1188],\n",
            "         [-0.2573,  0.1171, -0.2737,  0.1039, -0.2010],\n",
            "         [ 0.1837, -0.3186,  0.3946,  0.3497, -0.3033],\n",
            "         [ 0.4035,  0.1423,  0.3826,  0.1488,  0.1985],\n",
            "         [ 0.0042, -0.0996, -0.1104, -0.4046,  0.2477],\n",
            "         [-0.3045, -0.3432,  0.4251, -0.4272, -0.0090],\n",
            "         [ 0.2287,  0.0640,  0.2420, -0.4318,  0.0097],\n",
            "         [ 0.1224,  0.1369,  0.3393, -0.3745,  0.2378],\n",
            "         [ 0.3934,  0.3003,  0.3364, -0.0086, -0.0185],\n",
            "         [ 0.4205, -0.3899,  0.2479,  0.2566, -0.4201],\n",
            "         [ 0.2360, -0.3643,  0.3148,  0.1899, -0.0616],\n",
            "         [-0.1389,  0.1046, -0.0917, -0.0951, -0.3846],\n",
            "         [ 0.2973,  0.0075, -0.0798, -0.2010,  0.3454],\n",
            "         [ 0.3608, -0.3772,  0.2298, -0.2130,  0.1123],\n",
            "         [-0.2730,  0.4031, -0.1047, -0.3377,  0.0360],\n",
            "         [ 0.2296,  0.3526,  0.0067,  0.3919, -0.3448],\n",
            "         [ 0.3555,  0.3497, -0.1929, -0.2968, -0.0597],\n",
            "         [ 0.0388,  0.2398, -0.4340,  0.0677,  0.2376],\n",
            "         [-0.0010, -0.1427,  0.2527, -0.1947, -0.1132],\n",
            "         [-0.3947, -0.0600, -0.2159, -0.1606, -0.1641],\n",
            "         [ 0.1003,  0.4012,  0.1735, -0.3003, -0.0616],\n",
            "         [-0.3784, -0.4175,  0.1731, -0.1085,  0.1768],\n",
            "         [ 0.1651,  0.2783,  0.0789, -0.0952, -0.3126],\n",
            "         [ 0.2343, -0.2918,  0.1648, -0.1556, -0.1069],\n",
            "         [ 0.3512,  0.0252,  0.0232,  0.3736, -0.4201],\n",
            "         [-0.1776,  0.2559, -0.3469, -0.1479,  0.1731],\n",
            "         [ 0.2460, -0.0645, -0.1302,  0.4354, -0.1539],\n",
            "         [-0.2509, -0.1988,  0.1932, -0.3210, -0.0313],\n",
            "         [ 0.4174, -0.0291, -0.1414,  0.1063,  0.0474],\n",
            "         [-0.0844,  0.0060, -0.2479, -0.2006, -0.2593],\n",
            "         [ 0.4447, -0.2242,  0.0772, -0.2860, -0.3849],\n",
            "         [ 0.3042, -0.0833, -0.2591,  0.3842,  0.0067]]],\n",
            "       grad_fn=<SliceBackward0>) \n",
            "\n",
            "Layer: module.0.module.0.params.4.bias | Size: torch.Size([2, 256]) | Values : tensor([[ 5.5950e-02, -4.4904e-02, -8.6860e-02, -4.7650e-03,  2.8981e-02,\n",
            "          3.4677e-02, -2.1290e-03, -2.2526e-02, -8.1967e-02,  2.7668e-03,\n",
            "          5.5047e-02,  7.0371e-02,  2.6925e-02, -5.1471e-02,  2.0724e-02,\n",
            "         -8.0058e-02, -1.3351e-02,  4.2831e-02, -5.4385e-02, -3.6937e-02,\n",
            "          3.5339e-02,  7.3916e-02, -4.7255e-02,  4.6274e-02,  6.1232e-02,\n",
            "         -3.0695e-02,  8.4843e-03, -5.2621e-02,  5.8584e-02, -8.1569e-02,\n",
            "         -4.6975e-02, -7.1582e-02,  4.9763e-02, -5.2936e-02, -5.9269e-02,\n",
            "         -1.3373e-02,  2.6761e-03,  6.9681e-02,  2.4490e-02,  6.3718e-02,\n",
            "          7.7675e-02,  3.4728e-02, -6.8929e-02, -5.3982e-02,  7.7644e-02,\n",
            "         -1.5046e-03,  4.1239e-02, -6.6052e-03, -3.5684e-03,  4.1613e-02,\n",
            "         -3.2953e-02, -1.7053e-02, -8.5062e-02, -8.0803e-02, -8.6606e-02,\n",
            "          2.0372e-02,  5.1333e-02,  5.1649e-02,  6.4017e-02,  8.4033e-02,\n",
            "          8.6002e-02, -3.9708e-02,  4.1513e-02, -7.3536e-02, -4.6197e-02,\n",
            "          1.8729e-03, -1.7026e-02, -7.1623e-03, -5.7798e-02,  4.0724e-02,\n",
            "         -3.1263e-02, -3.9816e-02, -4.4736e-03,  4.9215e-02,  2.3180e-02,\n",
            "          6.0370e-02, -4.2451e-02, -4.2964e-04,  6.4275e-02,  4.4052e-02,\n",
            "          6.6518e-02,  7.4656e-02,  1.3848e-02, -8.5509e-02,  7.3917e-02,\n",
            "         -7.3567e-02,  2.5298e-02,  2.7402e-02,  4.4808e-02,  5.3271e-02,\n",
            "          1.9274e-03,  2.9114e-02, -3.6702e-02,  3.9016e-02,  6.4479e-02,\n",
            "         -5.6879e-02,  2.5052e-02,  4.9166e-02,  4.2411e-02, -2.9977e-02,\n",
            "         -7.8348e-02, -3.7110e-02, -8.2046e-02, -2.2401e-02,  4.6377e-02,\n",
            "         -3.1823e-02,  1.6074e-02,  5.8082e-02,  6.9611e-02,  5.4890e-02,\n",
            "         -1.8777e-02, -6.8862e-02, -3.8080e-02, -7.7516e-02, -7.9605e-02,\n",
            "          5.5683e-02,  1.1646e-02,  7.0899e-02, -7.5349e-02, -1.3625e-03,\n",
            "         -1.0100e-02,  6.5505e-02, -6.0387e-02, -7.2041e-02,  2.1088e-03,\n",
            "         -5.5656e-02,  5.1544e-02, -5.4003e-02, -2.8830e-03,  7.0239e-02,\n",
            "          7.6923e-02, -5.3829e-02,  6.7077e-02,  7.7554e-02, -3.5892e-02,\n",
            "          7.9307e-02, -7.8932e-02, -5.0256e-02, -3.7598e-03, -1.7636e-02,\n",
            "         -8.8055e-02,  7.9824e-02,  3.8538e-02,  5.6242e-02, -8.5398e-03,\n",
            "         -1.2333e-02,  3.7826e-02, -5.4174e-02, -3.4931e-02,  5.0083e-02,\n",
            "         -4.1975e-02,  5.5599e-02,  2.4454e-02, -4.3574e-02,  3.7986e-02,\n",
            "          6.5698e-02, -6.3566e-03, -2.4705e-03,  6.5737e-02, -5.4111e-02,\n",
            "          5.6244e-02,  6.3069e-02,  8.5543e-02,  3.8340e-02,  2.0926e-03,\n",
            "         -4.6060e-02, -3.8402e-02,  8.7693e-03,  1.4720e-05, -4.2711e-02,\n",
            "         -3.3644e-02,  3.8164e-02,  6.5871e-02, -2.3939e-02, -3.5722e-02,\n",
            "         -4.5922e-02,  6.9189e-02,  8.0261e-02,  8.8240e-02, -5.6414e-02,\n",
            "         -2.7833e-02, -5.4214e-02, -8.7764e-02,  2.6836e-02, -1.0262e-02,\n",
            "          4.4854e-02,  7.9507e-02,  1.7371e-02,  4.5441e-02, -4.2630e-03,\n",
            "         -4.2415e-02,  1.6013e-02, -5.1197e-02,  6.2601e-02,  7.3273e-02,\n",
            "         -2.6044e-02, -5.1865e-02, -2.1612e-02, -7.0007e-02, -6.6837e-02,\n",
            "          7.7020e-02, -2.2803e-02,  5.4241e-02,  3.4171e-02, -4.3455e-02,\n",
            "         -3.8363e-02,  8.2845e-02,  5.3459e-02,  1.8885e-02, -3.9908e-02,\n",
            "         -3.1536e-02, -1.7422e-02, -2.4771e-02,  3.8822e-02, -2.8537e-02,\n",
            "          2.7303e-03,  6.4984e-02,  5.3784e-02, -3.9288e-02,  2.2899e-02,\n",
            "         -7.1957e-02,  8.7795e-02,  8.7415e-02, -2.7466e-02, -1.8508e-02,\n",
            "         -2.1951e-02, -1.1080e-02,  2.0337e-02,  2.3308e-02,  3.8519e-02,\n",
            "         -5.8595e-02,  8.2474e-02, -8.8412e-03, -7.0876e-02, -2.6937e-02,\n",
            "         -5.2729e-02, -5.4346e-02,  7.2056e-02,  9.7597e-03, -4.4004e-02,\n",
            "          6.2021e-03, -8.7627e-02,  1.6852e-02, -3.7471e-03, -7.5077e-02,\n",
            "          4.0451e-03, -1.7805e-02,  2.8702e-02,  7.2293e-02,  8.2157e-02,\n",
            "         -1.8908e-02,  1.0051e-02,  4.7823e-02, -3.0886e-02,  5.1050e-02,\n",
            "          3.6312e-02],\n",
            "        [-5.7144e-02,  3.4281e-02, -8.6329e-02,  4.8481e-02, -4.1133e-02,\n",
            "          2.9113e-02, -3.6304e-02, -1.7978e-02,  1.7403e-02,  3.0578e-02,\n",
            "          3.0359e-02,  3.8693e-02, -8.0063e-02, -5.1436e-02, -3.3207e-02,\n",
            "          2.6747e-02,  2.5439e-02, -8.0042e-02, -3.8739e-02, -8.7677e-02,\n",
            "         -1.3903e-02, -7.8142e-02,  8.3540e-02, -7.1787e-02,  4.0562e-02,\n",
            "         -1.1081e-02,  6.9330e-02, -2.3679e-02, -4.7636e-02,  3.4743e-02,\n",
            "         -3.6013e-02,  4.5558e-02, -7.1722e-03, -5.4276e-02, -3.2716e-02,\n",
            "         -7.6719e-02,  6.1784e-02, -2.6468e-03, -7.7738e-02, -6.2321e-02,\n",
            "         -3.6316e-02, -6.9259e-02,  6.7739e-03, -8.6903e-02, -3.9693e-02,\n",
            "          7.4673e-02, -3.5395e-02,  8.3536e-02,  4.0391e-02,  1.0942e-02,\n",
            "          2.9790e-02, -7.7415e-03,  1.0033e-02, -5.9432e-02, -9.5923e-04,\n",
            "         -4.6171e-02,  3.2431e-02, -8.2057e-02,  4.4202e-02,  3.5981e-02,\n",
            "         -3.4269e-02, -5.2546e-02,  8.0271e-02,  5.1456e-02, -8.7168e-02,\n",
            "          4.2662e-02, -3.1432e-02, -6.1343e-02, -9.9696e-03, -2.5288e-02,\n",
            "         -8.2568e-02, -6.3773e-02, -3.0569e-02,  4.7176e-03, -6.4126e-02,\n",
            "          5.1852e-03,  6.5896e-02, -3.3688e-02, -6.9060e-03, -4.3799e-02,\n",
            "          4.4036e-02,  4.5729e-02, -6.9787e-02, -4.4349e-02, -1.7069e-02,\n",
            "          7.1994e-02,  8.4427e-03,  3.5309e-02,  1.1138e-04, -5.6334e-02,\n",
            "          4.5380e-02, -1.4051e-02,  8.1720e-02, -6.0112e-02,  2.0289e-02,\n",
            "          6.3552e-02,  5.0525e-02,  2.0779e-02,  1.5241e-02, -2.5856e-02,\n",
            "          8.7231e-02, -8.0644e-02, -3.4986e-02,  3.8335e-02,  4.8106e-02,\n",
            "          7.8928e-02, -9.6666e-03,  2.6525e-02,  1.0284e-02, -1.9498e-02,\n",
            "         -4.5111e-02, -4.1517e-02,  6.7388e-02,  4.2435e-04,  5.4074e-02,\n",
            "         -2.8588e-02,  9.1359e-03,  4.2894e-02,  6.2072e-03, -6.2497e-02,\n",
            "         -2.3800e-02, -3.2206e-02,  6.5356e-02, -1.6815e-02,  3.0253e-02,\n",
            "         -2.1834e-02,  8.7226e-03,  4.0274e-02, -6.4503e-02, -5.3234e-02,\n",
            "         -8.1506e-02, -5.7987e-02,  1.7803e-03,  2.6231e-02,  7.9987e-03,\n",
            "         -3.3418e-02, -7.2699e-02,  2.7418e-02, -4.7327e-02, -7.9165e-02,\n",
            "         -6.5577e-02,  5.9683e-02, -7.2359e-02,  3.5941e-02, -2.1014e-02,\n",
            "         -5.4606e-02,  5.4731e-02,  7.1030e-02, -7.7712e-02, -1.9689e-02,\n",
            "         -8.5431e-03,  8.1812e-02,  2.1256e-02, -4.8102e-03,  8.7648e-03,\n",
            "          7.2426e-02, -2.2524e-02,  8.5869e-02,  1.1130e-03, -7.9863e-02,\n",
            "         -5.3860e-03,  2.7676e-02,  6.1446e-02,  5.3277e-02,  2.8559e-02,\n",
            "          4.3419e-02,  1.8121e-02, -8.6221e-02, -7.7720e-02, -1.1238e-03,\n",
            "         -7.4676e-02,  6.5220e-02,  7.2021e-02,  2.9588e-02, -3.3373e-02,\n",
            "          3.6907e-02, -8.5049e-02,  2.4434e-02, -5.3937e-02, -5.0067e-02,\n",
            "          2.7197e-03, -2.8855e-02, -8.7911e-02, -6.2573e-02,  8.0165e-02,\n",
            "         -2.7096e-02, -6.5448e-02, -1.7686e-02,  5.9462e-03,  1.4047e-02,\n",
            "         -5.3214e-02,  6.9166e-02, -1.1357e-02, -4.8172e-02, -3.6398e-02,\n",
            "         -9.7634e-03, -8.4375e-02,  2.9087e-02,  2.2167e-02, -1.5761e-02,\n",
            "          4.7885e-02, -2.9472e-02, -5.8914e-02, -3.1150e-02,  3.1602e-02,\n",
            "          1.8669e-02,  1.4129e-02,  1.3042e-02,  7.5591e-02,  1.4982e-02,\n",
            "         -8.1355e-02, -8.3620e-02,  2.4056e-02,  8.6503e-02,  2.9737e-02,\n",
            "          4.4830e-02,  2.3551e-02, -7.1368e-02, -8.3579e-02, -3.1960e-02,\n",
            "          4.5624e-03,  7.5257e-02,  6.9864e-02,  3.2369e-02,  6.9692e-02,\n",
            "          4.2823e-02,  2.3921e-02, -1.8864e-02,  1.3953e-02,  1.9744e-02,\n",
            "          4.0259e-02,  3.7031e-02, -4.4272e-02,  4.8582e-02,  1.9609e-02,\n",
            "          4.8281e-02,  3.4386e-02, -3.5786e-03, -5.1081e-02, -2.3758e-02,\n",
            "          2.1968e-02,  7.5612e-02,  1.1745e-02, -4.7958e-02, -2.6958e-02,\n",
            "          4.8221e-02,  7.2980e-02, -4.7179e-02, -2.4815e-02,  7.5694e-02,\n",
            "          7.5621e-02,  8.6190e-02, -8.2636e-02, -1.4574e-02,  3.0894e-02,\n",
            "         -4.4747e-02]], grad_fn=<SliceBackward0>) \n",
            "\n",
            "Layer: module.0.module.0.params.4.weight | Size: torch.Size([2, 256, 128]) | Values : tensor([[[-0.0456,  0.0292, -0.0863,  ..., -0.0097,  0.0545,  0.0439],\n",
            "         [ 0.0327, -0.0473, -0.0513,  ...,  0.0697,  0.0232, -0.0452],\n",
            "         [ 0.0221, -0.0783, -0.0680,  ...,  0.0391,  0.0070,  0.0809],\n",
            "         ...,\n",
            "         [ 0.0288, -0.0195,  0.0841,  ...,  0.0063, -0.0656,  0.0401],\n",
            "         [-0.0288,  0.0321, -0.0664,  ..., -0.0186, -0.0683,  0.0683],\n",
            "         [ 0.0528, -0.0869, -0.0201,  ..., -0.0221,  0.0283, -0.0756]],\n",
            "\n",
            "        [[ 0.0097,  0.0689,  0.0870,  ...,  0.0092, -0.0539,  0.0816],\n",
            "         [ 0.0863, -0.0678,  0.0697,  ...,  0.0142, -0.0057, -0.0018],\n",
            "         [-0.0032,  0.0262, -0.0809,  ..., -0.0772, -0.0664, -0.0518],\n",
            "         ...,\n",
            "         [-0.0420,  0.0827,  0.0364,  ..., -0.0781,  0.0595, -0.0648],\n",
            "         [ 0.0374, -0.0259, -0.0658,  ..., -0.0555,  0.0038,  0.0370],\n",
            "         [ 0.0028,  0.0798, -0.0444,  ...,  0.0730, -0.0588,  0.0033]]],\n",
            "       grad_fn=<SliceBackward0>) \n",
            "\n",
            "Layer: module.0.module.0.params.6.bias | Size: torch.Size([2, 2]) | Values : tensor([[ 0.0239, -0.0011],\n",
            "        [-0.0102, -0.0269]], grad_fn=<SliceBackward0>) \n",
            "\n",
            "Layer: module.0.module.0.params.6.weight | Size: torch.Size([2, 2, 256]) | Values : tensor([[[-0.0568,  0.0190, -0.0088,  ...,  0.0619,  0.0258, -0.0489],\n",
            "         [-0.0592, -0.0043,  0.0223,  ..., -0.0126, -0.0049, -0.0022]],\n",
            "\n",
            "        [[-0.0166, -0.0181, -0.0126,  ...,  0.0183,  0.0129,  0.0564],\n",
            "         [-0.0562, -0.0242, -0.0546,  ...,  0.0262, -0.0112,  0.0398]]],\n",
            "       grad_fn=<SliceBackward0>) \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "6bFPCkHChQf3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Best hyperparameters:\", study.best_params)\n",
        "print(\"Best accuracy:\", study.best_value)"
      ],
      "metadata": {
        "id": "ibto-9Btijkf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "outputId": "28450ea5-dd0c-479a-c2bf-9d37747f7923"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "No trials are completed yet.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-100-e82546fa54b2>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Best hyperparameters:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Best accuracy:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/study.py\u001b[0m in \u001b[0;36mbest_params\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \"\"\"\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_trial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/study.py\u001b[0m in \u001b[0;36mbest_trial\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    160\u001b[0m             )\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m         \u001b[0mbest_trial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_best_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_study_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0;31m# If the trial with the best value is infeasible, select the best trial from all feasible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/storages/_in_memory.py\u001b[0m in \u001b[0;36mget_best_trial\u001b[0;34m(self, study_id)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbest_trial_id\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No trials are completed yet.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_studies\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstudy_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirections\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m                 raise RuntimeError(\n",
            "\u001b[0;31mValueError\u001b[0m: No trials are completed yet."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tqdm\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "HeuDXQSPOF1i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uo3djtViYhQ4"
      },
      "source": [
        "Training the best hyperparameter model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "\n",
        "def objective(trial):\n",
        "    # Suggest hyperparameters\n",
        "    learning_rate = trial.suggest_loguniform('learning_rate', 0.07048315134030513)\n",
        "    batch_size = trial.suggest_int('batch_size',  87)\n",
        "    num_epochs = trial.suggest_int('num_epochs', 46)\n",
        "    # Model training and evaluation logic here\n",
        "    logs = defaultdict(list)\n",
        "    pbar = tqdm(total=n_iters, desc=\"episode_reward_mean = 0\")\n",
        "    eval_str = \" \"\n",
        "    episode_reward_mean_list = []\n",
        "    accuracy = 0.0\n",
        "\n",
        "    for tensordict_data in collector:\n",
        "        tensordict_data.set(\n",
        "            (\"next\", \"agents\", \"done\"),\n",
        "            tensordict_data.get((\"next\", \"done\"))\n",
        "            .unsqueeze(-1)\n",
        "            .expand(tensordict_data.get_item_shape((\"next\", env.reward_key))),\n",
        "        )\n",
        "        tensordict_data.set(\n",
        "            (\"next\", \"agents\", \"terminated\"),\n",
        "            tensordict_data.get((\"next\", \"terminated\"))\n",
        "            .unsqueeze(-1)\n",
        "            .expand(tensordict_data.get_item_shape((\"next\", env.reward_key))),\n",
        "        )\n",
        "        # We need to expand the done and terminated to match the reward shape (this is expected by the value estimator)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            GAE(\n",
        "                tensordict_data,\n",
        "                params=loss_module.critic_network_params,\n",
        "                target_params=loss_module.target_critic_network_params,\n",
        "            )  # Compute GAE and add it to the data\n",
        "\n",
        "        data_view = tensordict_data.reshape(-1)  # Flatten the batch size to shuffle data\n",
        "        replay_buffer.extend(data_view)\n",
        "\n",
        "        accuracy = 0.0\n",
        "\n",
        "        for _ in range(num_epochs):\n",
        "            for _ in range(frames_per_batch // minibatch_size):\n",
        "                subdata = replay_buffer.sample()\n",
        "                loss_vals = loss_module(subdata)\n",
        "\n",
        "                loss_value = (\n",
        "                    loss_vals[\"loss_objective\"]\n",
        "                    + loss_vals[\"loss_critic\"]\n",
        "                    + loss_vals[\"loss_entropy\"]\n",
        "                )\n",
        "\n",
        "                loss_value.backward()\n",
        "\n",
        "                torch.nn.utils.clip_grad_norm_(\n",
        "                    loss_module.parameters(), max_grad_norm\n",
        "                )  # Optional\n",
        "\n",
        "                optim.step()\n",
        "                optim.zero_grad()\n",
        "\n",
        "        collector.update_policy_weights_()\n",
        "\n",
        "        # Logging\n",
        "        done = tensordict_data.get((\"next\", \"agents\", \"done\"))\n",
        "        episode_reward_mean = 0.0  # Initialize episode_reward_mean to a default value\n",
        "        if done.any():  # Check if any episodes are done\n",
        "            episode_reward_mean = (\n",
        "                tensordict_data.get((\"next\", \"agents\", \"episode_reward\"))[done].mean().item()\n",
        "            )\n",
        "            episode_reward_mean_list.append(episode_reward_mean)\n",
        "            accuracy = episode_reward_mean  # Assign accuracy here if done is True\n",
        "\n",
        "        pbar.set_description(f\"episode_reward_mean = {episode_reward_mean}\", refresh=False) # Now episode_reward_mean is always defined\n",
        "        pbar.update()\n",
        "\n",
        "    return accuracy  # Now accuracy will always have a value to return"
      ],
      "metadata": {
        "id": "Bik-63MuCw84"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bN34u6p4DCpW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ziRrLoXhYYo7"
      },
      "source": [
        "Results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZyaUl93Zxiz"
      },
      "source": [
        "Save Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xoHNdx9WZe87"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import datasets\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "PATH1 = '/content/drive/MyDrive/deep learning codes/EIAAPI_DOWNLOAD/solutions/mergedata/State_dict_model1.pt'\n",
        "PATH = '/content/drive/MyDrive/deep learning codes/EIAAPI_DOWNLOAD/solutions/mergedata/model.pt'\n",
        "torch.save({'actor_net_state_dict': policy_module.state_dict(),\n",
        "    'value_net_state_dict': critic_net.state_dict(),\n",
        "\n",
        "}, PATH1)\n",
        "\n",
        "torch.save({policy_module, critic_net}, PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IYIoeMCuaEIF"
      },
      "source": [
        "Load Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cw7-GBN-Z4Il"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Load\n",
        "PATH = '/content/drive/MyDrive/deep learning codes/EIAAPI_DOWNLOAD/solutions/mergedata/model.pt'\n",
        "critic_net, policy_module = torch.load(PATH,weights_only=False)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tOLuPecjm6_5"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qLEujdQSCQz0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGanWukPm9tV"
      },
      "source": [
        "PyTorch Model Updating"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HxExVuhvm6l6"
      },
      "outputs": [],
      "source": [
        "https://clear.ml/docs/latest/docs/guides/frameworks/pytorch/model_updating/#:~:text=To%20update%20a%20model%2C%20use,task%20as%20the%20output%20model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PHLvcRQGnJt7"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vZN0kyVOnKkl"
      },
      "outputs": [],
      "source": [
        "k=3\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import collections\n",
        "import numpy as np\n",
        "import torch\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "DDDDataDic =np.empty((8,7), dtype=np.float32)\n",
        "# We have 3 actions, corresponding to \"increase\", \"decrease\", \"no change \" in fuel price\n",
        "#self.action_space = spaces.Discrete(3)\n",
        "# Observations are dictionaries with the agent's Observation which are.\n",
        "# Forex, Crude oil pric, Fuel price, reward, action\n",
        "\n",
        "\n",
        "\n",
        "with open('/content/drive/MyDrive/deep learning codes/EIAAPI_DOWNLOAD/solutions/mergedata/DataDic.pt','rb') as rpp:\n",
        "  DataDic = torch.load(rpp)\n",
        "DDataDic=DataDic[0]\n",
        "DDDDataDic=DDataDic[:,:,k]\n",
        "print(DDDDataDic)\n",
        "\n",
        "DDDDataDic_array = DDDDataDic.numpy()\n",
        "DDDDataDic_df = pd.DataFrame(DDDDataDic_array)\n",
        "DDDDataDic_df.to_csv('/content/drive/MyDrive/deep learning codes/EIAAPI_DOWNLOAD/solutions/mergedata/MatlabARIMAXAData.csv')\n",
        "\n",
        "n = len(DDDDataDic_df)\n",
        "# Create a DatetimeIndex with 7795 dates\n",
        "iddx=pd.date_range(start='2003-01-02', periods=n, freq='D')\n",
        "# Assign the DatetimeIndex to the 'date' column of DDDDataDic_df\n",
        "# Set the 'date' column as the index of DDDDataDic_df\n",
        "DDDDataDic_df.index = iddx"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "########\n",
        "DDDDataDic_df\n",
        "DDDDataDic_df.columns = ['US$_SDR', 'Brent', 'WTI','OPEC','Fuelprice','Rewards','Actions']\n",
        "#Selected attribute and target variables\n",
        "x =DDDDataDic_df[['US$_SDR', 'Brent', 'WTI','OPEC']]\n",
        "y = DDDDataDic_df['Fuelprice']"
      ],
      "metadata": {
        "id": "fM0wORQGnvUJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the number of future time steps to forecast\n",
        "num_forecast_steps = 30\n",
        "import pandas as pd\n",
        "\n",
        "# Assuming DDDDataDic_df is a pandas DataFrame with a DatetimeIndex\n",
        "last_date_30_Daysb = DDDDataDic_df.index[-1] - pd.Timedelta(days=num_forecast_steps)\n",
        "historical_data=DDDDataDic_df\n",
        "historical_data = DDDDataDic_df.loc[last_date_30_Daysb:]\n",
        "# we use the observation data historical_data =[\"US$_SDR\", \"Brent\", \"WTI\",\"OPEC\", \"Fuelprice\"]for the forecasting\n",
        "historical_data_obs = historical_data.columns[0:5]\n",
        "#print(historical_data_obs)\n",
        "\n",
        "# Convert to NumPy and remove singleton dimensions\n",
        "#sequence_to_plot = X_test.squeeze().cpu().numpy()\n",
        "\n",
        "# Use the last 30 data points as the starting point\n",
        "#historical_data_obs= sequence_to_plot[-1]\n",
        "print(historical_data_obs.shape)\n",
        "\n",
        "# Initialize a list to store the forecasted values\n",
        "forecasted_values = []\n",
        "forecasted_actions = []\n",
        "\n",
        "# Use the trained model to forecast future values\n",
        "with torch.no_grad():\n",
        "\tfor _ in range(num_forecast_steps*2):\n",
        "\t\t# Prepare the historical_data tensor\n",
        "\t\thistorical_data_tensor = torch.as_tensor(historical_data_obs).view(1,5).float().to(device)\n",
        "\t\t# Use the model to predict the next value\n",
        "\t\tpredicted_value = value_module(historical_data_tensor)\n",
        "\t\tpredicted_actions =policy_module(historical_data_tensor)\n",
        "\n",
        "\t\t# Append the predicted value to the forecasted_values list\n",
        "\t\tforecasted_values.append(predicted_value[0])\n",
        "\t\tforecasted_actions.append(predicted_actions[0])\n",
        "\t\tforecasted_reward=predicted_value[Fuelprice]-historical_data_obs[Fuelprice]\n",
        "\n",
        "\t\tpredicted_valueful=concat([predicted_value,forecasted_reward,predicted_actions])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\t\t# Update the historical_data sequence by removing the oldest value and adding the predicted value\n",
        "\t\thistorical_data = np.roll(historical_data, shift=-1)\n",
        "\t\thistorical_data[-1] = predicted_valueful\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Generate futute date\n",
        "last_datea =historical_data.index[-1]\n",
        "\n",
        "# Generate the next 30 dates\n",
        "future_dates = pd.date_range(start=last_date + pd.DateOffset(1), periods=30)\n",
        "\n",
        "# Concatenate the original index with the future dates\n",
        "combined_index = historical_data.index.append(future_dates)\n"
      ],
      "metadata": {
        "id": "c0Vmgcxqn3KU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "57L7l5I5oN5m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import datasets\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "PATH = '/content/drive/MyDrive/deep learning codes/EIAAPI_DOWNLOAD/solutions/mergedata/model.pt'\n",
        "\n",
        "checkpoint = torch.load(PATH)\n",
        "\n",
        "new_actor_net_dict = model.state_dict()\n",
        "new_value_net_dict = model.state_dict()\n",
        "\n",
        "\n",
        "pretrained_weights_new_actor_net= {}\n",
        "pretrained_weights_new_value_net= {}\n",
        "\n",
        "\n",
        "for key, value in checkpoint['actor_net_state_dict'].items():\n",
        "    new_key = key.replace('module.', '')\n",
        "    pretrained_weights_new_actor_net[new_key] = value\n",
        "\n",
        "#new_value_net_state_dict = {}\n",
        "for key, value in checkpoint['value_net_state_dict'].items():\n",
        "    new_key1 = key.replace('module.', '')\n",
        "    pretrained_weights_new_value_net[new_key1] = value\n",
        "\n",
        "new_actor_net_dict.update(pretrained_weights_new_actor_net)\n",
        "new_value_net_dict.update(pretrained_weights_new_value_net)\n",
        "\n",
        "model.load_state_dict(pretrained_weights_new_actor_net, strict = False)\n",
        "model.load_state_dict(pretrained_weights_new_value_net, strict = False)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "N0W78NdToOSF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pretrained_path = torch.load(path to pretrained model)\n",
        "\n",
        "\n",
        "new_model_dict = model.state_dict()\n",
        "\n",
        "pretrained_weights = { k:v for k , v in pretrained_path.items() if k in new_model_dict}\n",
        "\n",
        "new_model_dict.update(pretrained_weights)\n",
        "\n",
        "model.load_state_dict(pretrained_weights, strict = False)"
      ],
      "metadata": {
        "id": "YHMreTLvoTjh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_model_dict.update(pretrained_weights)"
      ],
      "metadata": {
        "id": "BR3j0-feoZMP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_value_net.load_state_dict(new_value_net_state_dict)\n",
        "new_actor_net.load_state_dict(new_actor_net_state_dict)"
      ],
      "metadata": {
        "id": "1Aoli_DXokSb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_value_net.update(new_value_net_state_dict)\n",
        "new_actor_net.update(new_actor_net_state_dict)"
      ],
      "metadata": {
        "id": "oTB6JPtAopTr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(new_actor_net)"
      ],
      "metadata": {
        "id": "yAqL9LfDosBZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Forecasting With models"
      ],
      "metadata": {
        "id": "3FlFQZmTpObG"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "w25xP214pCED"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install graphviz\n",
        "!pip install torchviz"
      ],
      "metadata": {
        "id": "DmNPY0qopFkO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1822feb-188b-44e5-c7c7-627c45b61fba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (0.20.3)\n",
            "Requirement already satisfied: torchviz in /usr/local/lib/python3.10/dist-packages (0.0.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from torchviz) (2.4.0+cu121)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from torchviz) (0.20.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (2024.6.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->torchviz) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->torchviz) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchview"
      ],
      "metadata": {
        "id": "36buwjsdpUwn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a40f6b7-cc92-46d4-aae7-bd33423f3705"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchview in /usr/local/lib/python3.10/dist-packages (0.2.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchview import draw_graph\n",
        "batch_size = frames_per_batch\n",
        "\n",
        "model_graph = draw_graph(critic_net, input_size=(1, 6250, 2, 5), device=device)\n",
        "model_graph.visual_graph\n",
        "# device='meta' -> no memory is consumed for visualization\n",
        "#model_graph1 = draw_graph(value_net, input_size=(780,1,5), device=device)\n",
        "#model_graph1.visual_graph\n"
      ],
      "metadata": {
        "id": "0POnsdXLpeJD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 964
        },
        "outputId": "b7dc305c-efbd-4c38-8520-b1480d4085ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Failed to run torchgraph see error message",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchview/torchview.py\u001b[0m in \u001b[0;36mforward_prop\u001b[0;34m(model, x, device, model_graph, mode, **kwargs)\u001b[0m\n\u001b[1;32m    255\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m                     \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchview/recorder_tensor.py\u001b[0m in \u001b[0;36m_module_forward_wrapper\u001b[0;34m(mod, *args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0minput_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_nodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m         cur_node = ModuleNode(\n\u001b[0m\u001b[1;32m    116\u001b[0m             \u001b[0mmod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_depth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_nodes\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchview/computation_node/compute_node.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, module_unit, depth, parents, children, name, output_nodes)\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_activation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mis_generator_empty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_unit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_container\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_unit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensordict/base.py\u001b[0m in \u001b[0;36m__bool__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__bool__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Converting a tensordict to boolean value is not permitted\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Converting a tensordict to boolean value is not permitted",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-caec848245af>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mframes_per_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdraw_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcritic_net\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6250\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mmodel_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisual_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# device='meta' -> no memory is consumed for visualization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchview/torchview.py\u001b[0m in \u001b[0;36mdraw_graph\u001b[0;34m(model, input_data, input_size, graph_name, depth, device, dtypes, mode, strict, expand_nested, graph_dir, hide_module_functions, hide_inner_tensors, roll, show_shapes, save_graph, filename, directory, **kwargs)\u001b[0m\n\u001b[1;32m    218\u001b[0m     )\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m     forward_prop(\n\u001b[0m\u001b[1;32m    221\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_recorder_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0mmodel_mode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs_record_tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchview/torchview.py\u001b[0m in \u001b[0;36mforward_prop\u001b[0;34m(model, x, device, model_graph, mode, **kwargs)\u001b[0m\n\u001b[1;32m    262\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unknown input type\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m         raise RuntimeError(\n\u001b[0m\u001b[1;32m    265\u001b[0m             \u001b[0;34m\"Failed to run torchgraph see error message\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m         ) from e\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Failed to run torchgraph see error message"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import graphviz\n",
        "graphviz.set_jupyter_format('png')\n",
        "#graphviz.Source(model_graph1.visual_graph)\n",
        "graphviz.Source(model_graph.visual_graph)"
      ],
      "metadata": {
        "id": "SttuzUgrpkbz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_graph = draw_graph(actor_net, input_size=(7800,1,5), device=device)"
      ],
      "metadata": {
        "id": "miHsnWsNpzwT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model_graph.visual_graph)"
      ],
      "metadata": {
        "id": "OGUTeIFup34K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install skorch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LryNKEDKkrSv",
        "outputId": "6a0c2aba-cdeb-4044-e471-1f7076f9385f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: skorch in /usr/local/lib/python3.10/dist-packages (1.0.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.10/dist-packages (from skorch) (1.26.4)\n",
            "Requirement already satisfied: scikit-learn>=0.22.0 in /usr/local/lib/python3.10/dist-packages (from skorch) (1.3.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from skorch) (1.13.1)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from skorch) (0.9.0)\n",
            "Requirement already satisfied: tqdm>=4.14.0 in /usr/local/lib/python3.10/dist-packages (from skorch) (4.66.5)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22.0->skorch) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22.0->skorch) (3.5.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import make_classification\n",
        "from torch import nn\n",
        "from skorch import NeuralNetClassifier\n",
        "\n",
        "X, y = make_classification(1000, 20, n_informative=10, random_state=0)\n",
        "X = X.astype(np.float32)\n",
        "y = y.astype(np.int64)\n",
        "\n",
        "net = policy_net\n",
        "\n",
        "\n",
        "net.fit(X, y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oTdQ8wo7jfd2",
        "outputId": "90d600d6-c7c0-46eb-b162-f9b6173d8994"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1           nan       \u001b[32m0.4550\u001b[0m           nan  0.0774\n",
            "      2           nan       \u001b[32m0.4600\u001b[0m           nan  0.0386\n",
            "      3           nan       \u001b[32m0.4650\u001b[0m           nan  0.0368\n",
            "      4           nan       \u001b[32m0.4700\u001b[0m           nan  0.0373\n",
            "      5           nan       0.4700           nan  0.0351\n",
            "      6           nan       0.4650           nan  0.0337\n",
            "      7           nan       0.4550           nan  0.0408\n",
            "      8           nan       0.4700           nan  0.0513\n",
            "      9           nan       0.4700           nan  0.0914\n",
            "     10           nan       \u001b[32m0.4900\u001b[0m           nan  0.0368\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<class 'skorch.classifier.NeuralNetClassifier'>[initialized](\n",
              "  module_=Linear(in_features=20, out_features=2, bias=True),\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "pipe = Pipeline([\n",
        "    ('scale', StandardScaler()),\n",
        "    ('net', net),\n",
        "])\n",
        "\n",
        "pipe.fit(X, y)\n",
        "y_proba = pipe.predict_proba(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mf0Zo5BzjSBM",
        "outputId": "3f541ec1-75a2-4b34-f54c-01bca704950e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Re-initializing module because the following parameters were re-set: in_features, out_features.\n",
            "Re-initializing criterion.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1           nan       \u001b[32m0.3850\u001b[0m           nan  0.0353\n",
            "      2           nan       \u001b[32m0.4950\u001b[0m           nan  0.0407\n",
            "      3           nan       0.4300           nan  0.1160\n",
            "      4           nan       0.4250           nan  0.0768\n",
            "      5           nan       0.4300           nan  0.0426\n",
            "      6           nan       0.4300           nan  0.0351\n",
            "      7           nan       0.4350           nan  0.0649\n",
            "      8           nan       0.4300           nan  0.0398\n",
            "      9           nan       0.4300           nan  0.0342\n",
            "     10           nan       0.4300           nan  0.0418\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# deactivate skorch-internal train-valid split and verbose logging\n",
        "net.set_params(train_split=False, verbose=0)\n",
        "params = {\n",
        "    'lr': [0.01, 0.02,0.03],\n",
        "    'max_epochs': [10, 20,30],\n",
        "    'module__in_features': [10, 20],\n",
        "}\n",
        "gs = GridSearchCV(net, params, refit=False, cv=3, scoring='accuracy', verbose=2)\n",
        "\n",
        "gs.fit(X, y)\n",
        "print(\"best score: {:.3f}, best params: {}\".format(gs.best_score_, gs.best_params_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2TqnLW52jTKx",
        "outputId": "f3bd7165-3601-409d-b9d8-a33d1cfb934c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 18 candidates, totalling 54 fits\n",
            "[CV] END .....lr=0.01, max_epochs=10, module__in_features=10; total time=   0.0s\n",
            "[CV] END .....lr=0.01, max_epochs=10, module__in_features=10; total time=   0.0s\n",
            "[CV] END .....lr=0.01, max_epochs=10, module__in_features=10; total time=   0.0s\n",
            "[CV] END .....lr=0.01, max_epochs=10, module__in_features=20; total time=   0.4s\n",
            "[CV] END .....lr=0.01, max_epochs=10, module__in_features=20; total time=   1.0s\n",
            "[CV] END .....lr=0.01, max_epochs=10, module__in_features=20; total time=   0.8s\n",
            "[CV] END .....lr=0.01, max_epochs=20, module__in_features=10; total time=   0.0s\n",
            "[CV] END .....lr=0.01, max_epochs=20, module__in_features=10; total time=   0.0s\n",
            "[CV] END .....lr=0.01, max_epochs=20, module__in_features=10; total time=   0.0s\n",
            "[CV] END .....lr=0.01, max_epochs=20, module__in_features=20; total time=   2.1s\n",
            "[CV] END .....lr=0.01, max_epochs=20, module__in_features=20; total time=   2.5s\n",
            "[CV] END .....lr=0.01, max_epochs=20, module__in_features=20; total time=   1.7s\n",
            "[CV] END .....lr=0.01, max_epochs=30, module__in_features=10; total time=   0.0s\n",
            "[CV] END .....lr=0.01, max_epochs=30, module__in_features=10; total time=   0.0s\n",
            "[CV] END .....lr=0.01, max_epochs=30, module__in_features=10; total time=   0.0s\n",
            "[CV] END .....lr=0.01, max_epochs=30, module__in_features=20; total time=   2.0s\n",
            "[CV] END .....lr=0.01, max_epochs=30, module__in_features=20; total time=   1.8s\n",
            "[CV] END .....lr=0.01, max_epochs=30, module__in_features=20; total time=   2.0s\n",
            "[CV] END .....lr=0.02, max_epochs=10, module__in_features=10; total time=   0.0s\n",
            "[CV] END .....lr=0.02, max_epochs=10, module__in_features=10; total time=   0.0s\n",
            "[CV] END .....lr=0.02, max_epochs=10, module__in_features=10; total time=   0.0s\n",
            "[CV] END .....lr=0.02, max_epochs=10, module__in_features=20; total time=   0.9s\n",
            "[CV] END .....lr=0.02, max_epochs=10, module__in_features=20; total time=   0.6s\n",
            "[CV] END .....lr=0.02, max_epochs=10, module__in_features=20; total time=   0.9s\n",
            "[CV] END .....lr=0.02, max_epochs=20, module__in_features=10; total time=   0.0s\n",
            "[CV] END .....lr=0.02, max_epochs=20, module__in_features=10; total time=   0.0s\n",
            "[CV] END .....lr=0.02, max_epochs=20, module__in_features=10; total time=   0.0s\n",
            "[CV] END .....lr=0.02, max_epochs=20, module__in_features=20; total time=   0.7s\n",
            "[CV] END .....lr=0.02, max_epochs=20, module__in_features=20; total time=   1.3s\n",
            "[CV] END .....lr=0.02, max_epochs=20, module__in_features=20; total time=   0.9s\n",
            "[CV] END .....lr=0.02, max_epochs=30, module__in_features=10; total time=   0.0s\n",
            "[CV] END .....lr=0.02, max_epochs=30, module__in_features=10; total time=   0.0s\n",
            "[CV] END .....lr=0.02, max_epochs=30, module__in_features=10; total time=   0.0s\n",
            "[CV] END .....lr=0.02, max_epochs=30, module__in_features=20; total time=   2.0s\n",
            "[CV] END .....lr=0.02, max_epochs=30, module__in_features=20; total time=   2.1s\n",
            "[CV] END .....lr=0.02, max_epochs=30, module__in_features=20; total time=   1.2s\n",
            "[CV] END .....lr=0.03, max_epochs=10, module__in_features=10; total time=   0.0s\n",
            "[CV] END .....lr=0.03, max_epochs=10, module__in_features=10; total time=   0.0s\n",
            "[CV] END .....lr=0.03, max_epochs=10, module__in_features=10; total time=   0.0s\n",
            "[CV] END .....lr=0.03, max_epochs=10, module__in_features=20; total time=   0.3s\n",
            "[CV] END .....lr=0.03, max_epochs=10, module__in_features=20; total time=   0.3s\n",
            "[CV] END .....lr=0.03, max_epochs=10, module__in_features=20; total time=   0.4s\n",
            "[CV] END .....lr=0.03, max_epochs=20, module__in_features=10; total time=   0.0s\n",
            "[CV] END .....lr=0.03, max_epochs=20, module__in_features=10; total time=   0.0s\n",
            "[CV] END .....lr=0.03, max_epochs=20, module__in_features=10; total time=   0.0s\n",
            "[CV] END .....lr=0.03, max_epochs=20, module__in_features=20; total time=   0.6s\n",
            "[CV] END .....lr=0.03, max_epochs=20, module__in_features=20; total time=   0.6s\n",
            "[CV] END .....lr=0.03, max_epochs=20, module__in_features=20; total time=   0.7s\n",
            "[CV] END .....lr=0.03, max_epochs=30, module__in_features=10; total time=   0.0s\n",
            "[CV] END .....lr=0.03, max_epochs=30, module__in_features=10; total time=   0.0s\n",
            "[CV] END .....lr=0.03, max_epochs=30, module__in_features=10; total time=   0.0s\n",
            "[CV] END .....lr=0.03, max_epochs=30, module__in_features=20; total time=   1.4s\n",
            "[CV] END .....lr=0.03, max_epochs=30, module__in_features=20; total time=   1.1s\n",
            "[CV] END .....lr=0.03, max_epochs=30, module__in_features=20; total time=   0.8s\n",
            "best score: 0.602, best params: {'lr': 0.02, 'max_epochs': 20, 'module__in_features': 20}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning: \n",
            "27 fits failed out of a total of 54.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "27 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/skorch/classifier.py\", line 165, in fit\n",
            "    return super(NeuralNetClassifier, self).fit(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/skorch/net.py\", line 1319, in fit\n",
            "    self.partial_fit(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/skorch/net.py\", line 1278, in partial_fit\n",
            "    self.fit_loop(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/skorch/net.py\", line 1190, in fit_loop\n",
            "    self.run_single_epoch(iterator_train, training=True, prefix=\"train\",\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/skorch/net.py\", line 1226, in run_single_epoch\n",
            "    step = step_fn(batch, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/skorch/net.py\", line 1105, in train_step\n",
            "    self._step_optimizer(step_fn)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/skorch/net.py\", line 1060, in _step_optimizer\n",
            "    optimizer.step(step_fn)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\", line 484, in wrapper\n",
            "    out = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\", line 89, in _use_grad\n",
            "    ret = func(self, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/optim/sgd.py\", line 112, in step\n",
            "    loss = closure()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/skorch/net.py\", line 1094, in step_fn\n",
            "    step = self.train_step_single(batch, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/skorch/net.py\", line 993, in train_step_single\n",
            "    y_pred = self.infer(Xi, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/skorch/net.py\", line 1521, in infer\n",
            "    return self.module_(x, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\", line 117, in forward\n",
            "    return F.linear(input, self.weight, self.bias)\n",
            "RuntimeError: mat1 and mat2 shapes cannot be multiplied (128x20 and 10x2)\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:979: UserWarning: One or more of the test scores are non-finite: [       nan 0.53505901        nan 0.50090809        nan 0.53199906\n",
            "        nan 0.4740489         nan 0.60199721        nan 0.48703494\n",
            "        nan 0.48709488        nan 0.56309903        nan 0.510022  ]\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}